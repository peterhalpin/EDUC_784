<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EDUC 784 - 2&nbsp; Simple Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch1_review.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch2_simple_regression.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simple Regression</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">EDUC 784</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1_review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2_simple_regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simple Regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#example-2" id="toc-example-2" class="nav-link active" data-scroll-target="#example-2"><span class="header-section-number">2.1</span> An example from NELS</a></li>
  <li><a href="#regression-line-2" id="toc-regression-line-2" class="nav-link" data-scroll-target="#regression-line-2"><span class="header-section-number">2.2</span> The regression line</a></li>
  <li><a href="#ols-2" id="toc-ols-2" class="nav-link" data-scroll-target="#ols-2"><span class="header-section-number">2.3</span> OLS</a>
  <ul class="collapse">
  <li><a href="#correlation-and-regression" id="toc-correlation-and-regression" class="nav-link" data-scroll-target="#correlation-and-regression"><span class="header-section-number">2.3.1</span> Correlation and regression</a></li>
  </ul></li>
  <li><a href="#rsquared-2" id="toc-rsquared-2" class="nav-link" data-scroll-target="#rsquared-2"><span class="header-section-number">2.4</span> R-squared</a>
  <ul class="collapse">
  <li><a href="#derivation" id="toc-derivation" class="nav-link" data-scroll-target="#derivation"><span class="header-section-number">2.4.1</span> Derivation*</a></li>
  </ul></li>
  <li><a href="#population-model-2" id="toc-population-model-2" class="nav-link" data-scroll-target="#population-model-2"><span class="header-section-number">2.5</span> The population model</a></li>
  <li><a href="#notation-2" id="toc-notation-2" class="nav-link" data-scroll-target="#notation-2"><span class="header-section-number">2.6</span> Clarifying notation</a></li>
  <li><a href="#inference-for-slope-2" id="toc-inference-for-slope-2" class="nav-link" data-scroll-target="#inference-for-slope-2"><span class="header-section-number">2.7</span> Inference for the slope</a>
  <ul class="collapse">
  <li><a href="#t-tests" id="toc-t-tests" class="nav-link" data-scroll-target="#t-tests"><span class="header-section-number">2.7.1</span> t-tests</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">2.7.2</span> Confidence intervals</a></li>
  <li><a href="#the-nels-example" id="toc-the-nels-example" class="nav-link" data-scroll-target="#the-nels-example"><span class="header-section-number">2.7.3</span> The NELS example</a></li>
  </ul></li>
  <li><a href="#inference-for-intercept-2" id="toc-inference-for-intercept-2" class="nav-link" data-scroll-target="#inference-for-intercept-2"><span class="header-section-number">2.8</span> Inference for the intercept</a></li>
  <li><a href="#inference-for-rsquared-2" id="toc-inference-for-rsquared-2" class="nav-link" data-scroll-target="#inference-for-rsquared-2"><span class="header-section-number">2.9</span> Inference for R-squared</a>
  <ul class="collapse">
  <li><a href="#f-tests" id="toc-f-tests" class="nav-link" data-scroll-target="#f-tests"><span class="header-section-number">2.9.1</span> F-tests</a></li>
  </ul></li>
  <li><a href="#power-2" id="toc-power-2" class="nav-link" data-scroll-target="#power-2"><span class="header-section-number">2.10</span> Power analysis</a></li>
  <li><a href="#workbook-2" id="toc-workbook-2" class="nav-link" data-scroll-target="#workbook-2"><span class="header-section-number">2.11</span> Workbook</a></li>
  <li><a href="#exercises-2" id="toc-exercises-2" class="nav-link" data-scroll-target="#exercises-2"><span class="header-section-number">2.12</span> Exercises</a>
  <ul class="collapse">
  <li><a href="#the-lm-function" id="toc-the-lm-function" class="nav-link" data-scroll-target="#the-lm-function"><span class="header-section-number">2.12.1</span> The <code>lm</code> function</a></li>
  <li><a href="#variance-explained" id="toc-variance-explained" class="nav-link" data-scroll-target="#variance-explained"><span class="header-section-number">2.12.2</span> Variance explained</a></li>
  <li><a href="#predicted-values-and-residuals" id="toc-predicted-values-and-residuals" class="nav-link" data-scroll-target="#predicted-values-and-residuals"><span class="header-section-number">2.12.3</span> Predicted values and residuals</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference"><span class="header-section-number">2.12.4</span> Inference</a></li>
  <li><a href="#power-analysis" id="toc-power-analysis" class="nav-link" data-scroll-target="#power-analysis"><span class="header-section-number">2.12.5</span> Power analysis</a></li>
  <li><a href="#additional-exercises" id="toc-additional-exercises" class="nav-link" data-scroll-target="#additional-exercises"><span class="header-section-number">2.12.6</span> Additional exercises</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-chap-2" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simple Regression</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The focus of this course is linear regression with multiple predictors (AKA <em>multiple regression</em>), but we start by reviewing regression with one predictor (AKA <em>simple regression</em>).</p>
<section id="example-2" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="example-2"><span class="header-section-number">2.1</span> An example from NELS</h2>
<p>Figure @ref(fig:fig1) shows the relationship between Grade 8 Math Achievement (percent correct on a math test) and Socioeconomic Status (SES; a composite measure on a scale from 0-35). The data are a subsample of the 1988 National Educational Longitudinal Survey (NELS; see <a href="https://nces.ed.gov/surveys/nels88/" class="uri">https://nces.ed.gov/surveys/nels88/</a>).</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and attach the NELS88 data</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"NELS.RData"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(NELS)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression model</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch2_simple_regression_files/figure-html/fig1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Math Achievement and SES (NELS88).</figcaption>
</figure>
</div>
</div>
</div>
<p>The strength and direction of the linear relationship between the two variables is summarized by their correlation (specifically, the Pearson product moment correlation). In this sample, the correlation is</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3182</code></pre>
</div>
</div>
<p>This is a moderate, positive correlation between Math Achievement and SES. This correlation means that eighth graders from more well-off families (higher SES) also tended to do better in math (higher Math Achievement).</p>
<p>This relationship between SES and academic achievement has been widely documented and discussed in education research (e.g., <a href="https://www.apa.org/pi/ses/resources/publications/education" class="uri">https://www.apa.org/pi/ses/resources/publications/education</a>). <strong>Please look over this web page and be prepared to share your thoughts about this relationship.</strong></p>
</section>
<section id="regression-line-2" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="regression-line-2"><span class="header-section-number">2.2</span> The regression line</h2>
<p>The line in the Figure @ref(fig:fig1) can be represented mathematically as</p>
<p><span class="math display">\[
\widehat Y = a + b X
(\#eq:yhat)
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(Y\)</span> denotes Math Achievement</li>
<li><span class="math inline">\(X\)</span> denotes SES</li>
<li><span class="math inline">\(a\)</span> represents the regression intercept (the value of <span class="math inline">\(\widehat Y\)</span> when <span class="math inline">\(X = 0\)</span>)</li>
<li><span class="math inline">\(b\)</span> represents the regression slope (how much <span class="math inline">\(\widehat Y\)</span> increases for each unit of increase in <span class="math inline">\(X\)</span>)</li>
</ul>
<p>Note that <span class="math inline">\(Y\)</span> represents the values of Math Achievement in the data, whereas <span class="math inline">\(\widehat Y\)</span> represents the values computed from the regression equation (i.e., the values on the regression line). The difference <span class="math inline">\(e = Y - \widehat Y\)</span> is called a <em>residual</em>. The residuals for a subset of the data points in Figure @ref(fig:fig1) are shown in pink in Figure @ref(fig:fig2)</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted values from regression model</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> mod<span class="sc">$</span>fitted.values</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># select a subset of the data</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(<span class="dv">500</span>, <span class="dv">30</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># plot again</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add pink lines</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> ses[index], <span class="at">y0 =</span> yhat[index] , <span class="at">x1 =</span> ses[index], <span class="at">y1 =</span> achmat08[index], <span class="at">col =</span> <span class="dv">6</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Overwrite dots to make it look at bit better</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch2_simple_regression_files/figure-html/fig2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Residuals for a Subsample of the Example.</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice that <span class="math inline">\(Y = \widehat Y + e\)</span> by definition. So, we can use either Equation @ref(eq:yhat) or the equation below to write out a regression model:</p>
<span class="math display">\[\begin{align}
Y = a + bX + e.  
(\#eq:y)
\end{align}\]</span>
<p>Both equations say the same thing, but Equation @ref(eq:y) lets us talk about the values of <span class="math inline">\(Y\)</span> in the data, not just the predicted values.</p>
<p>Another way to write out the model is using the variable names (or abbreviations) in place of the more generic “X, Y” notation. For example,</p>
<span class="math display">\[\begin{align}
\widehat {MATH} = a + b(SES).
(\#eq:read)
\end{align}\]</span>
<p>This notation is more informative about the specific variables in the example. But it is also more clunky and doesn’t lend itself to other mathematical expressions. For example, <span class="math inline">\(r_{XY}\)</span> is much clearer than <span class="math inline">\(r_{SES, MATH}\)</span> – in general, we want most of the text on the “baseline”, not the subscripts or superscripts.</p>
<p>You should be familiar with all 3 ways of presenting regression equations and you are free to use whatever approach you like best in your own writing.</p>
</section>
<section id="ols-2" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="ols-2"><span class="header-section-number">2.3</span> OLS</h2>
<p>Intuitively, one approach to “fitting a line to the data” is to select the parameters of the line (its slope and intercept) to minimize the residuals. In ordinary least squares (OLS) regression, we minimize a related quantity, the sum of squared residuals:</p>
<p><span class="math display">\[
\begin{align}
SS_{\text{res}} &amp; = \sum_{i=1}^{N} e_i^2 \\
&amp; = \sum_{i=1}^{N} (Y_i - a - b X_i)^2
\end{align}
\]</span></p>
<p>where <span class="math inline">\(i = 1 \dots N\)</span> indexes the respondents in the sample. OLS regression is very widely used and is the main focus of this course, although we will visit some other approaches in the second half of the course.</p>
<p>Solving the minimization problem (setting derivatives to zero) gives the following equations for the regression parameters:</p>
<p><span class="math display">\[
a = \bar Y - b \bar X \quad \quad \quad \quad b = \frac{\text{Cov}(X, Y)}{s^2_X} = r_{XY} \frac{s_Y}{s_X}
\]</span></p>
<p>(If you aren’t familiar with the symbols in these equations, check out the review materials in Section @ref(review-2) for a refresher.)</p>
<p>For the NELS example, the regression intercept and slope are, respectively:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         ses 
    48.6780      0.4293 </code></pre>
</div>
</div>
<p><strong>Please write down an interpretation of these numbers in terms of the line in Figure</strong> @ref(fig:fig1)<strong>, and be prepared to share your answers in class!</strong></p>
<section id="correlation-and-regression" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="correlation-and-regression"><span class="header-section-number">2.3.1</span> Correlation and regression</h3>
<p>Note that if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are transformed to z-scores (i.e., to have mean of zero and variance of one), then</p>
<ul>
<li><span class="math inline">\(a = 0\)</span></li>
<li><span class="math inline">\(b = \text{Cov}(X, Y) = r_{XY}\)</span></li>
</ul>
<p>(You can check these results by plugging the value 0 for the means and the value 1 for the variance in the equations above.)</p>
<p>So, regression, correlation, and covariance are all very closely related when we consider only two variables at a time. This is why we didn’t make a big deal about simple regression in EDUC 710 – its basically just the same thing as correlation. But, when we get to multiple regression (i.e., more than one <span class="math inline">\(X\)</span> variable), we will see that relationship between regression and correlation (and covariance) gets more complicated.</p>
<!-- ## Residuals 
- show that Cor(\hatY e) = 0  and explain why that is important
- talk about standard error of estimate and how its used
-->
</section>
</section>
<section id="rsquared-2" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="rsquared-2"><span class="header-section-number">2.4</span> R-squared</h2>
<p>In the previous section we saw that the predicted value of Math Achievement increased by .43 units (about half a percentage point) for each unit of increase in SES. Another way to interpret this relationship is in terms of the proportion of variance in Math Achievement that is associated with SES – i.e., to what extent are individual differences in Math Achievement associated with, or explained by, individual differences in SES?</p>
<p>This question is represented graphically in Figure @ref(fig:rsquared). The horizontal line denotes the mean of Math Achievement. The difference between the indicated student’s Math Achievement score and the mean can be divided into two parts.</p>
<ul>
<li><p>The black dashed line shows how much closer we get to the student’s Math Achievement score (<span class="math inline">\(Y\)</span>) by considering the predicted values (<span class="math inline">\(\widehat Y\)</span>) instead of the overall mean (<span class="math inline">\(\bar Y\)</span>). This represents the extent to which this student’s Math Achievement is explained by the linear relationship with SES.</p></li>
<li><p>The pink dashed line is the regression residual, which was introduced in Section @ref(regression-line-2). This is the variation in Math Achievement that is “left over” after considering the linear relationship with SES.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch2_simple_regression_files/figure-html/rsquared-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">The Idea Behind R-squared.</figcaption>
</figure>
</div>
</div>
</div>
<p>The R-squared statistic averages the variation in Math Achievement associated with SES (i.e., the black dashed line) relative to the total variation in Math Achievement (i.e., black + pink) for all students in the sample. R-squared is a widely used statistic in regression analysis, so we will be seeing it a lot. Some authors call it the “coefficient of determination” instead of R-squared.</p>
<p>Using all of the cases from the example (Figure @ref(fig:fig1)), the R-squared statistic is:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">5</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.10128</code></pre>
</div>
</div>
<p><strong>Please write down an interpretation of this number and be prepared to share your answer in class.</strong></p>
<section id="derivation" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="derivation"><span class="header-section-number">2.4.1</span> Derivation*</h3>
<p>To derive the R-squared statistic we work the numerator of the variance, which is called the total sum of squares.</p>
<p><span class="math display">\[SS_{\text{total}} = \sum_{i = 1}^N (Y_i - \bar Y)^2. \]</span></p>
<p>It can be re-written using the predicted values <span class="math inline">\(\widehat Y\)</span>:</p>
<p><span class="math display">\[SS_{\text{total}} = \sum_{i = 1}^N [(Y_i - \widehat Y_i) + (\widehat Y_i - \bar Y)]^2. \]</span></p>
<p>The right hand side can be reduced to two other sums of squares using the rules of summation algebra (see the review in Section @ref(review-2)):</p>
<span class="math display">\[\begin{align}
SS_{\text{total}} &amp; = \sum_{i = 1}^N (Y_i - \widehat Y_i)^2 + \sum_{i = 1}^N (\widehat Y_i - \bar Y)^2 \\
\end{align}\]</span>
<p>The first part is just <span class="math inline">\(SS_\text{res}\)</span> from Section @ref(ols-2). The second part is called the regression sum of squares and denoted <span class="math inline">\(SS_\text{reg}\)</span>. Using this terminology we can re-write the above equation as</p>
<p><span class="math display">\[ SS_{\text{total}} = SS_\text{res} + SS_\text{reg} \]</span></p>
<p>The R-squared statistic is</p>
<p><span class="math display">\[R^2 = SS_{\text{reg}} / SS_{\text{total}}. \]</span></p>
<p>As discussed above, this is interpreted as the proportion of variance in <span class="math inline">\(Y\)</span> that is explained by its linear relationship with <span class="math inline">\(X\)</span>.</p>
<!--
### Additional details* 

Another way to get to $R^2$ is through the definition of $R$ as the correlation between $Y$ and $\widehat Y$. In simple regression, this is just equal to the regular correlation coefficient (Again, you can use the rules of summation algebra to show this). 

\[ R = \text{cor}(Y, \widehat Y) = \text{cor}(Y, a + bX) = \text{cor}(Y, X)\]


Consequently, in simple regression, $R^2 = r^2_{XY}$ -- i.e., the proportion of variance explained by the predictor is just the squared Person product moment correlation. When we add multiple predictors, this relationship between $R^2$ and $r^2_{XY}$ no longer holds. 

Still need to show the two definitions of R-squared are equivalent ;

\[ R^2 = SS_reg /SS_total = \text{var}(\hat Y) / \text{var}(Y) = \text{var}(a + bX) / \text{var}(Y)
= b^2 \text{var}(X) / \text{var}(Y)= \text{cov}(X, Y)^2 / \text{var}(X) \text{var}(Y)= r^2
\]
-->
</section>
</section>
<section id="population-model-2" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="population-model-2"><span class="header-section-number">2.5</span> The population model</h2>
<p>In the NELS example, the population of interest is U.S. eighth graders in 1988. We want to be able to draw conclusions about that population based on the sample of eighth graders that participated in NELS. In order to do that, we make some statistical assumptions about the population, which are collectively referred to as the population model. We talk about how to check the plausibility of these assumptions in Chapter @ref(chapter-8).</p>
<p>The regression population model has the following three assumptions, which are also depicted in the diagram below. Recall that the notation <span class="math inline">\(Y \sim N(\mu, \sigma)\)</span> means that a variable <span class="math inline">\(Y\)</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<ol type="1">
<li>Normality: The values of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(Y|X\)</span>, are normally distributed (the figure shows these distributions for three values of <span class="math inline">\(X\)</span>):</li>
</ol>
<p><span class="math display">\[Y | X \sim  N(\mu_{Y | X} , \sigma_{Y | X}) \]</span></p>
<ol start="2" type="1">
<li>Homoskedasticity: The conditional distributions have equal variances (also called homegeneity of variance).</li>
</ol>
<p><span class="math display">\[ \sigma_{Y| X} = \sigma \]</span></p>
<ol start="3" type="1">
<li>Linearity: The means of the conditional distributions are a linear function of <span class="math inline">\(X\)</span>.</li>
</ol>
<p><span class="math display">\[ \mu_{Y| Χ} = a + bX \]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="files/images/population_model.png" class="img-fluid figure-img" width="612"></p>
<figcaption class="figure-caption">The Regression Population Model.</figcaption>
</figure>
</div>
</div>
</div>
<p>These three assumptions are summarized by writing</p>
<p><span class="math display">\[ Y|X \sim N(a + bX, \sigma). \]</span></p>
<p>Sometimes it will be easier to state the assumptions in terms of the population residuals, <span class="math inline">\(\epsilon = Y - \mu_{Y|X}\)</span>, which subtracts off the regression line: <span class="math inline">\(\epsilon \sim N(0, \sigma)\)</span>.</p>
<p>An additional assumption is usually made about the data in the sample – that they were obtained as a simple random sample from the population. We will see some ways of dealing with other types of samples later on the course, but for now we can consider this a background assumption that applies to all of the procedures discussed in this course.</p>
</section>
<section id="notation-2" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="notation-2"><span class="header-section-number">2.6</span> Clarifying notation</h2>
<p>At this point we have used the mathematical symbols for regression (e.g., <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>) in two different ways:</p>
<ul>
<li>In Section @ref(regression-line-2) they denoted sample statistics.</li>
<li>In Section @ref(population-model-2) they denoted population parameters.</li>
</ul>
<p>The population versus sample notation for regression is a bit of a hot mess, but the following conventions are widely used.</p>
<table class="table">
<thead>
<tr class="header">
<th>Concept</th>
<th style="text-align: center;">Sample statistic</th>
<th style="text-align: center;">Population parameter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>regression line</td>
<td style="text-align: center;"><span class="math inline">\(\widehat Y\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mu_{Y|X}\)</span></td>
</tr>
<tr class="even">
<td>slope</td>
<td style="text-align: center;"><span class="math inline">\(\widehat b\)</span></td>
<td style="text-align: center;"><span class="math inline">\(b\)</span></td>
</tr>
<tr class="odd">
<td>intercept</td>
<td style="text-align: center;"><span class="math inline">\(\widehat a\)</span></td>
<td style="text-align: center;"><span class="math inline">\(a\)</span></td>
</tr>
<tr class="even">
<td>residual</td>
<td style="text-align: center;"><span class="math inline">\(e\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\epsilon\)</span></td>
</tr>
<tr class="odd">
<td>variance explained</td>
<td style="text-align: center;"><span class="math inline">\(\widehat R^2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(R^2\)</span></td>
</tr>
</tbody>
</table>
<p>The “hats” always denote sample quantities, and the Greek letters (in this table) always denote population quantities, but there is some lack of consistency. For example, why not use <span class="math inline">\(\beta\)</span> instead of <span class="math inline">\(b\)</span> for the population slope? Well, <span class="math inline">\(\beta\)</span> is conventionally used to denote standardized regression coefficients in the <em>sample</em>, so its already taken (more on this in the Chapter @ref(chapter-4) ).</p>
<p>One thing to note is that the hats are usually omitted from the statistics <span class="math inline">\(\widehat a\)</span>, <span class="math inline">\(\widehat b\)</span>, and <span class="math inline">\(\widehat R^2\)</span> if it is clear from context that we are talking about the sample rather than the population. This doesn’t apply to <span class="math inline">\(\widehat Y\)</span>, because the hat is required to distinguish the predicted values from the data points.</p>
<p>Another thing to note is that while <span class="math inline">\(\widehat Y\)</span> are often called the predicted values, <span class="math inline">\(\mu_{Y|X}\)</span> is not usually referred to this way. It is called the conditional mean function or the conditional expectation function. We will introduce some other notations for <span class="math inline">\(\widehat Y\)</span> and <span class="math inline">\(\mu_{Y|X}\)</span> later in the course.</p>
<p><strong>Please be prepared for a pop quiz on notation during class!</strong></p>
<!-- Finally, recall that the symbol $E(\cdot)$ denotes the expected value of whatever statistic appears in the place of the dot. The expected value is a way of referring to the mean of the sampling distribution of the statistic (otherwise we would have to say things like "the mean of the mean", which would be horrible). So $E(Y\mid X)$ is the expected value of $Y$ for a given value of $X$. The $\mu_{Y|X}$ is the the population conditional mean, $\mu_{Y|X}$ is equal to $E(Y\mid X)$ when the population model is true (i.e., OLS regression is an unbiased estimator of the population conditional mean function). So, the two symbols are used interchangeably. (Omit this paragraph?) -->
</section>
<section id="inference-for-slope-2" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="inference-for-slope-2"><span class="header-section-number">2.7</span> Inference for the slope</h2>
<p>When the population model is true, <span class="math inline">\(\widehat b\)</span> is an unbiased estimate of <span class="math inline">\(b\)</span>. We also know the standard error of <span class="math inline">\(\widehat b\)</span>, which is equal to (cite:fox)</p>
<p><span class="math display">\[ s_{\widehat b} = \frac{s_Y}{s_X} \sqrt{\frac{1-R^2}{N-2}} . \]</span></p>
<p>Using these two results, we can compute t-tests and confidence intervals for the regression slope in the usual way. These are summarized below. See the review in Section @ref(review-2) for background information on bias, standard errors, t-tests, and confidence intervals.</p>
<section id="t-tests" class="level3" data-number="2.7.1">
<h3 data-number="2.7.1" class="anchored" data-anchor-id="t-tests"><span class="header-section-number">2.7.1</span> t-tests</h3>
<p>The null hypothesis <span class="math inline">\(H_0: \widehat b = b_0\)</span> can be tested against the alternative <span class="math inline">\(H_A: \widehat b \neq b_0\)</span> using the test statistic:</p>
<p><span class="math display">\[ t = \frac{\widehat b - b_0}{s_{\widehat b}} \]</span></p>
<p>which has a t-distribution on <span class="math inline">\(N-2\)</span> degrees of freedom when the null hypothesis is true.</p>
<p>The test assumes that the population model is correct. The null hypothesis value of the parameter is usually chosen to be <span class="math inline">\(b_0 = 0\)</span>, in which case the test is interpreted in terms of the “statistical significance” of the regression slope.</p>
</section>
<section id="confidence-intervals" class="level3" data-number="2.7.2">
<h3 data-number="2.7.2" class="anchored" data-anchor-id="confidence-intervals"><span class="header-section-number">2.7.2</span> Confidence intervals</h3>
<p>For a given Type I Error rate, <span class="math inline">\(\alpha\)</span>, the corresponding <span class="math inline">\((1-\alpha) \times 100\%\)</span> confidence interval is</p>
<p><span class="math display">\[ b_0 = \widehat b \pm t_{\alpha/2} \times s_{\widehat b} \]</span></p>
<p>where <span class="math inline">\(t_{\alpha/2}\)</span> denotes the <span class="math inline">\(\alpha/2\)</span> quantile of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(N-2\)</span> degrees of freedom.</p>
<p>For example, if <span class="math inline">\(\alpha\)</span> is chosen to be <span class="math inline">\(.05\)</span>, the corresponding <span class="math inline">\(95\%\)</span> confidence interval uses <span class="math inline">\(t_{.025}\)</span>, or the 2.5-th percentile of the t-distribution.</p>
</section>
<section id="the-nels-example" class="level3" data-number="2.7.3">
<h3 data-number="2.7.3" class="anchored" data-anchor-id="the-nels-example"><span class="header-section-number">2.7.3</span> The NELS example</h3>
<p>For the NELS example, the t-test of the regression slope is shown in the second row of the table below (we cover the rest of the output in the next few sections):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat08 ~ ses)

Residuals:
    Min      1Q  Median      3Q     Max 
-20.600  -6.552  -0.148   6.023  27.663 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  48.6780     1.1282   43.15  &lt; 2e-16 ***
ses           0.4293     0.0573    7.49  3.1e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.86 on 498 degrees of freedom
Multiple R-squared:  0.101, Adjusted R-squared:  0.0995 
F-statistic: 56.1 on 1 and 498 DF,  p-value: 3.13e-13</code></pre>
</div>
</div>
<p>The corresponding <span class="math inline">\(95\%\)</span> confidence interval is</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               2.5 %   97.5 %
(Intercept) 46.46146 50.89461
ses          0.31668  0.54184</code></pre>
</div>
</div>
<p><strong>Please write down an interpretation of the t-test and confidence interval of the regression slope, and be prepared to share your answers in class!</strong></p>
</section>
</section>
<section id="inference-for-intercept-2" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="inference-for-intercept-2"><span class="header-section-number">2.8</span> Inference for the intercept</h2>
<p>The situation for the regression intercept is similar to that for the slope: the OLS estimate is unbiased and its standard error is (cite:fox)</p>
<!--- check this and get source -->
<p><span class="math display">\[
s_{\widehat a} = \sqrt{\frac{SS_{\text{res}}}{N-2} \left(\frac{1}{N} + \frac{\bar X^2}{(N-1)s^2_X}\right)}.
\]</span></p>
<p>The t-tests and confidence intervals are constructed in the way same as for the slope, just by <span class="math inline">\(a\)</span> replacing <span class="math inline">\(b\)</span> in the notation of the previous slide. The t-distribution also has <span class="math inline">\(N-2\)</span> degrees of freedom for the intercept.</p>
<p>It is not usually the case that the regression intercept is of interest in simple regression. Recall that the intercept is the value of <span class="math inline">\(\widehat Y\)</span> when <span class="math inline">\(X = 0\)</span>. So, unless you have a hypothesis or research question about this particular value of <span class="math inline">\(X\)</span> (e.g., eighth graders with <span class="math inline">\(SES = 0\)</span>), you won’t be interested in this test (even though R always provides it).</p>
<p>When we get to multiple regression, we will see some examples of regression models where the intercept is meaningful, especially when we talk about categorical predictors in Chapter @ref(chapter-5) and interactions in Chapter @ref(chapter-6). But, for now, we can put it on the back burner.</p>
</section>
<section id="inference-for-rsquared-2" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="inference-for-rsquared-2"><span class="header-section-number">2.9</span> Inference for R-squared</h2>
<p>Inference for R-squared is quite a bit different than for the regression parameters. As we saw in section @ref(rsquared-2), R-squared is a ratio of two sums of squares. We know from our study of ANOVA last semester that ratios of sums of squares are tested using an F-test, rather than a t-test. The F-test for (the population) R-squared is summarized below.</p>
<section id="f-tests" class="level3" data-number="2.9.1">
<h3 data-number="2.9.1" class="anchored" data-anchor-id="f-tests"><span class="header-section-number">2.9.1</span> F-tests</h3>
<p>The null hypothesis <span class="math inline">\(H_0: R^2 = 0\)</span> can be tested against the alternative <span class="math inline">\(H_A: R^2 \neq 0\)</span> using the test statistic:</p>
<p><span class="math display">\[ F = (N-2) \frac{\widehat R^2}{1-\widehat R^2} \]</span></p>
<p>which has a F-distribution on <span class="math inline">\(1\)</span> and <span class="math inline">\(N – 2\)</span> degrees of freedom when the null is true. The test assumes that the population model is true. Confidence intervals for R-squared are generally not reported.</p>
<p>The R output from Section @ref(inference-for-slope-2) is presented again below. <strong>Please write down an interpretation of the F-test of R-squared and be prepared to share your answers in class!</strong> Note that the output uses the terminology “multiple R-squared” to refer to R-squared.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat08 ~ ses)

Residuals:
    Min      1Q  Median      3Q     Max 
-20.600  -6.552  -0.148   6.023  27.663 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  48.6780     1.1282   43.15  &lt; 2e-16 ***
ses           0.4293     0.0573    7.49  3.1e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.86 on 498 degrees of freedom
Multiple R-squared:  0.101, Adjusted R-squared:  0.0995 
F-statistic: 56.1 on 1 and 498 DF,  p-value: 3.13e-13</code></pre>
</div>
</div>
</section>
</section>
<section id="power-2" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="power-2"><span class="header-section-number">2.10</span> Power analysis</h2>
<p>Statistical power is the probability of rejecting the null hypothesis, when it is indeed false. Rejecting the null hypothesis when it is false is sometimes called a “true positive”, meaning we have correctly inferred that a parameter of interest is not zero. Power analysis is useful for designing studies so that the statistical power / true positive rate is satisfactory. In practice, this comes down to having a large enough sample size.</p>
<p>Power analysis in regression is very similar to power analysis for the tests we studied last semester. There are four ingredients that go into a power analysis:</p>
<ul>
<li>The desired Type I Error rate, <span class="math inline">\(\alpha\)</span>.</li>
<li>The desired level of statistical power.</li>
<li>The sample size, <span class="math inline">\(N\)</span>.</li>
<li>The effect size, which for regression is Cohen’s f-squared statistic (AKA the signal to noise ratio):</li>
</ul>
<p><span class="math display">\[ f^2 = {\frac{R^2}{1-R^2}}. \]</span></p>
<p>In principal, we can plug-in values for any three of these ingredients and then solve for the fourth. But, as mentioned, power analysis is most useful when we solve for <span class="math inline">\(N\)</span> while planning a study. When solving for <span class="math inline">\(N\)</span> “prospectively,” the effect size <span class="math inline">\(f^2\)</span> should be based on reports of R-squared in past research. Power and <span class="math inline">\(\alpha\)</span> are usually chosen to be .8 and .05, respectively.</p>
<p>When doing secondary data analysis (as in this class) there is not much point in solving for the sample size, since we already have the data. Instead, we can solve for the effect size. In the NELS example we have <span class="math inline">\(N=500\)</span> observations. The output below reports the smallest effect size we can detect with a power of .8 and <span class="math inline">\(\alpha = .05\)</span>. This is sometimes called the “minimum detectable effect size” (MDES). Note that the output <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> denote the degrees of freedom in the numerator and denominator of the F-test of R-squared, respectively.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">v =</span> <span class="dv">498</span>, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
     Multiple regression power calculation 

              u = 1
              v = 498
             f2 = 0.015754
      sig.level = 0.05
          power = 0.8</code></pre>
</div>
</div>
<p><strong>What is the MDES for the NELS example? Please be prepared to share your answer in class.</strong></p>
</section>
<section id="workbook-2" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="workbook-2"><span class="header-section-number">2.11</span> Workbook</h2>
<p>This section collects the questions asked in this chapter. We will discuss these questions in class. If you haven’t written down / thought about the answers to these questions before class, the lesson will not be very useful for you! So, please engage with each question by writing down one or more answers, asking clarifying questions, posing follow up questions, etc.</p>
<p><strong>Section</strong> @ref(example-2)</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression model</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch2_simple_regression_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Math Achievement and SES (NELS88).</figcaption>
</figure>
</div>
</div>
</div>
<p>The strength and direction of the linear relationship between the two variables is summarized by their correlation (specifically, the Pearson product moment correlation). In the plot above, the correlation is</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3182</code></pre>
</div>
</div>
<p>This correlation means that eighth graders from more well-off families (higher SES) also tended to do better in Math (higher Math Achievement).</p>
<p>This relationship between SES and academic achievement has been widely documented and discussed in education research (e.g., <a href="https://www.apa.org/pi/ses/resources/publications/education" class="uri">https://www.apa.org/pi/ses/resources/publications/education</a>). Please look over this web page and be prepared to share your thoughts about this relationship.</p>
<p><strong>Section</strong> @ref(ols-2)</p>
<p>For the NELS example, the regression intercept and slope are, respectively:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         ses 
    48.6780      0.4293 </code></pre>
</div>
</div>
<p>Please write down an interpretation of these numbers in terms of the line in Figure @ref(fig:fig1), and be prepared to share your answers in class.</p>
<p><strong>Section</strong> @ref(rsquared-2)</p>
<p>Using all of the cases from the example (Figure @ref(fig:fig1)), the R-squared statistic is:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">5</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.10128</code></pre>
</div>
</div>
<p>Please write down an interpretation of this number and be prepared to share your answer in class.</p>
<p><strong>Section</strong> @ref(notation-2)</p>
<p>Please be prepared for a pop quiz on notation during class!</p>
<table class="table">
<thead>
<tr class="header">
<th>Concept</th>
<th style="text-align: center;">Sample statistic</th>
<th style="text-align: center;">Population parameter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>regression line</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>slope</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>intercept</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>residual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>variance explained</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p><strong>Section</strong> @ref(inference-for-slope-2)</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat08 ~ ses)

Residuals:
    Min      1Q  Median      3Q     Max 
-20.600  -6.552  -0.148   6.023  27.663 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  48.6780     1.1282   43.15  &lt; 2e-16 ***
ses           0.4293     0.0573    7.49  3.1e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.86 on 498 degrees of freedom
Multiple R-squared:  0.101, Adjusted R-squared:  0.0995 
F-statistic: 56.1 on 1 and 498 DF,  p-value: 3.13e-13</code></pre>
</div>
</div>
<p>The corresponding <span class="math inline">\(95\%\)</span> confidence interval is</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               2.5 %   97.5 %
(Intercept) 46.46146 50.89461
ses          0.31668  0.54184</code></pre>
</div>
</div>
<p>Please write down an interpretation of the t-test and confidence interval of the regression slope, and be prepared to share your answers in class!</p>
<p><strong>Section</strong> @ref(inference-for-rsquared-2)</p>
<p>Using the same output as above, please write down an interpretation of the F-test of R-squared and be prepared to share your answers in class. Note that the output uses the terminology “multiple R-squared” to refer to R-squared.</p>
<p><strong>Section</strong> @ref(power-2)</p>
<p>When doing secondary data analysis (as in this class) there is not much point in solving for the sample size, since we already have the data. Instead, we can solve for the effect size. In the NELS example we have <span class="math inline">\(N=500\)</span> observations. The output below reports the smallest effect size we can detect with a power of .8 and <span class="math inline">\(\alpha = .05\)</span>. This is sometimes called the “minimum detectable effect size” (MDES). Note that the output $u $ and <span class="math inline">\(v\)</span> denote the degrees of freedom in the numerator and denominator of the F-test of R-squared, respectively.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">v =</span> <span class="dv">498</span>, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
     Multiple regression power calculation 

              u = 1
              v = 498
             f2 = 0.015754
      sig.level = 0.05
          power = 0.8</code></pre>
</div>
</div>
<p>What is the MDES for the NELS example? Please be prepared to share your answer in class.</p>
</section>
<section id="exercises-2" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="exercises-2"><span class="header-section-number">2.12</span> Exercises</h2>
<p>These exercises collect all of the R input used in this chapter into a single step-by-step analysis. It explains how the R input works, and provides some additional exercises. We will go through this material in class together, so you don’t need to work on it before class (but you can if you want.)</p>
<section id="the-lm-function" class="level3" data-number="2.12.1">
<h3 data-number="2.12.1" class="anchored" data-anchor-id="the-lm-function"><span class="header-section-number">2.12.1</span> The <code>lm</code> function</h3>
<p>The function<code>lm</code>, short for “linear model”, is used to estimate linear regressions using OLS. It also provides a lot of useful output.</p>
<p>The main argument that the user provides to the <code>lm</code> function is a formula. For the simple regression of Y on X, a formula has the syntax:</p>
<p><code>Y ~ X</code></p>
<p>Here <code>Y</code> denotes the outcome variable and <code>X</code> is the predictor variable. The tilde <code>~</code> just means “equals”, but the equals sign <code>=</code> is already used to assign values in R, so <code>~</code> is used in its place when writing a formula. We will see more complicated formulas as we go through the course. For more information on R’s formula syntax, see <code>help(formula)</code>.</p>
<p>Let’s take a closer look using the following two variables from the NELS data.</p>
<ul>
<li><p><code>achmat08</code>: eighth grade math achievement (percent correct on a math test)</p></li>
<li><p><code>ses</code>: a composite measure of socio-economic status, on a scale from 0-35</p></li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data. Note that you can click on the .RData file and RStudio will load it</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># load("NELS.RData") #Un-comment this line to run</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Attach the data: will dicuss this in class</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(NELS) #Un-comment this line to run!</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of math achievment against SES</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Regress math achievement on SES; save output as "mod"</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch2_simple_regression_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out the regression coefficients</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         ses 
   48.67803     0.42926 </code></pre>
</div>
</div>
<p>Let’s do some quick calculations to check that the <code>lm</code> output corresponds the formulas for the slope and intercept in Section @ref(ols-2):</p>
<p><span class="math display">\[ a = \bar Y - b \bar X \quad \text{and} \quad b = \frac{\text{Cov}(X, Y)}{s_X^2} \]</span> We won’t usually do these kind of “manual” calculations, but it is a good way consolidate knowledge presented in the readings with the output presented by R. It is also useful to refresh our memory about some useful R functions and how the R language works.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm that the slope from lm is equal to the covariance divided by the variance of X</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>cov_xy <span class="ot">&lt;-</span> <span class="fu">cov</span>(achmat08, ses)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>s_x <span class="ot">&lt;-</span> <span class="fu">var</span>(ses)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> cov_xy <span class="sc">/</span> s_x</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>b</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.42926</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm that the y-intercept is obtained from the two means and the slope</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(achmat08)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> ybar <span class="sc">-</span> b <span class="sc">*</span> xbar</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 48.678</code></pre>
</div>
</div>
<p>Let’s also check our interpretation of the parameters. If the answers to these questions are not clear, please make sure to ask in class!</p>
<ul>
<li><p>What is the predicted value of <code>achmat08</code> when <code>ses</code> is equal to zero?</p></li>
<li><p>How much does the predicted value of <code>achmat08</code> increase for each unit of increase in <code>ses</code>?</p></li>
</ul>
</section>
<section id="variance-explained" class="level3" data-number="2.12.2">
<h3 data-number="2.12.2" class="anchored" data-anchor-id="variance-explained"><span class="header-section-number">2.12.2</span> Variance explained</h3>
<p>Above we found out that the regression coefficient was 0.4-ish. Another way to describe the relationships is by considering the amount of variation in <span class="math inline">\(Y\)</span> that is associated with (or explained by) its relationship with <span class="math inline">\(X\)</span>. Recall that one way to do this is via the variance decomposition</p>
<p><span class="math display">\[ SS_{\text{total}} = SS_{\text{res}} + SS_{\text{reg}}\]</span></p>
<p>from which we can compute the proportion of variation in Y that is associated with the regression model</p>
<p><span class="math display">\[R^2 = \frac{SS_{\text{reg}}}{SS_{\text{total}}}\]</span></p>
<p>The R-squared for the example is presented in the output below. You should be able to provide an interpretation of this number, so if it’s not clear make sure to ask in class!</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared from the example</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.10128</code></pre>
</div>
</div>
<p>As above, let’s compute <span class="math inline">\(R^2\)</span> “by hand” for our example.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the sums of squares</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(achmat08)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>ss_total <span class="ot">&lt;-</span> <span class="fu">sum</span>((achmat08 <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>ss_reg <span class="ot">&lt;-</span> <span class="fu">sum</span>((yhat <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>ss_res <span class="ot">&lt;-</span>  <span class="fu">sum</span>((achmat08 <span class="sc">-</span> yhat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that SS_total = SS_reg + SS_res</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>ss_total</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 43527</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>ss_reg <span class="sc">+</span> ss_res</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 43527</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute R-squared</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>ss_reg<span class="sc">/</span>ss_total</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.10128</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that R-squared is really equal to the square of the PPMC</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)<span class="sc">^</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.10128</code></pre>
</div>
</div>
</section>
<section id="predicted-values-and-residuals" class="level3" data-number="2.12.3">
<h3 data-number="2.12.3" class="anchored" data-anchor-id="predicted-values-and-residuals"><span class="header-section-number">2.12.3</span> Predicted values and residuals</h3>
<p>The <code>lm</code> function also returns the residuals <span class="math inline">\(e_i\)</span> and the predicted values <span class="math inline">\(\widehat{Y_i}\)</span>, which we can access using the <code>$</code> operator. These are useful for various reasons, especially model diagnostics which we discuss later in the course. For now, lets just take a look at the residual vs fitted plot to illustrate the code.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> mod<span class="sc">$</span>fitted.values</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> mod<span class="sc">$</span>resid</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, res, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch2_simple_regression_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(yhat, res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] -2.9515e-16</code></pre>
</div>
</div>
<p>Note that the predicted values are uncorrelated with the residuals – this is always the case in OLS.</p>
</section>
<section id="inference" class="level3" data-number="2.12.4">
<h3 data-number="2.12.4" class="anchored" data-anchor-id="inference"><span class="header-section-number">2.12.4</span> Inference</h3>
<p>Next let’s talk about statistical inference, or how we can make conclusions about a population based on a sample from that population.</p>
<p>We can use the <code>summary</code> function to test the coefficients in our model.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat08 ~ ses)

Residuals:
    Min      1Q  Median      3Q     Max 
-20.600  -6.552  -0.148   6.023  27.663 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  48.6780     1.1282   43.15  &lt; 2e-16 ***
ses           0.4293     0.0573    7.49  3.1e-13 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.86 on 498 degrees of freedom
Multiple R-squared:  0.101, Adjusted R-squared:  0.0995 
F-statistic: 56.1 on 1 and 498 DF,  p-value: 3.13e-13</code></pre>
</div>
</div>
<p>In the table, the t-test and p-values are for the null hypothesis that the corresponding coefficient is zero in the population. We can see that the intercept and slope are both significantly different from zero at the .05 level. However, the test of the intercept is not very meaningful (why?).</p>
<p>The text below the table summarizes the output for R-squared, including its F-test, it’s degrees of freedom, and the p-value. (We will talk about adjusted R-square in Chapter 4)</p>
<p>We can also use the <code>confint</code> function to obtain confidence intervals for the regression coefficients. Use <code>help</code> to find out more about the <code>confint</code> function.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>               2.5 %   97.5 %
(Intercept) 46.46146 50.89461
ses          0.31668  0.54184</code></pre>
</div>
</div>
<p>Be sure to remember the correct interpretation of confidence intervals: <em>there is a 95% chance that the interval includes the true parameter value</em> (not: there is a 95% chance that the parameter falls in the interval). For example, there is a 95% chance that the interval [.31, .54] includes the true regression coefficient for SES.</p>
</section>
<section id="power-analysis" class="level3" data-number="2.12.5">
<h3 data-number="2.12.5" class="anchored" data-anchor-id="power-analysis"><span class="header-section-number">2.12.5</span> Power analysis</h3>
<p>Power analyses should ideally be done before the data are collected. Since this class will work with secondary data analyses, most of our analyses will be retrospective. But don’t let this mislead you about the importance of statistical power – you should always do a power analysis before collecting data!!</p>
<p>To do a power analsyis in R, we can install and load the <code>pwr</code> package. If you haven’t installed an R package before, it’s pretty straight forward – but just ask the instructor or a fellow student if you run into any issues.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package </span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"pwr"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package by using the library command</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"pwr"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the help menu to see what the package does</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(<span class="st">"pwr-package"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To do a power analysis for linear regression, it is common to use Cohen’s <span class="math inline">\(f^2\)</span> as the effect size:</p>
<p><span class="math display">\[f^2 = \frac{R^2}{1-R^2}.\]</span></p>
<p>Recall that <span class="math inline">\(R^2\)</span> is the proportion of variance in <span class="math inline">\(Y\)</span> explained by the model, and so <span class="math inline">\(1 - R^2\)</span> is the proportion of variance not explained by the model. Thus, <span class="math inline">\(f^2\)</span> can be interpreted as a signal to noise ratio.</p>
<p>In addition to the effect size, we need to know the degrees of freedom for the F-test of R-square. The <code>pwr</code> functions use the following notation:</p>
<ul>
<li><code>u</code> is the degrees of freedom in the numerator of an F-test.</li>
<li><code>v</code> is the degrees of freedom in the denominator of an F-test.</li>
</ul>
<p>In simple regression, <code>u = 1</code> and <code>v = N - 2</code>.</p>
<p>As an example of (prospective) power analysis, let’s find out many observations would be required to detect an effet size of R-square = .1, using <span class="math inline">\(\alpha = .05\)</span> and power = .8. To find the answer, enter the provided information into the <code>pwr.f2.test</code> function, and the function will solve for the “missing piece” – in this case <span class="math inline">\(v = N - 2\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the provided values of R2, alpha, power (and u = 1) to solve for v = N - 2</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> .<span class="dv">1</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> R2<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>R2)</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">f2 =</span> f2, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
     Multiple regression power calculation 

              u = 1
              v = 70.611
             f2 = 0.11111
      sig.level = 0.05
          power = 0.8</code></pre>
</div>
</div>
<p>In this example we find that <span class="math inline">\(v = 70.6\)</span>. Since <span class="math inline">\(v = N - 2\)</span>, so we know that a sample size of <span class="math inline">\(N = 72.6\)</span> (rounded up to 73) is required to reject the null hypothesis that <span class="math inline">\(R^2 = 0\)</span>, when the true population value is <span class="math inline">\(R^2 = .1\)</span>, with a power of .8 and using a significance level of .05.</p>
</section>
<section id="additional-exercises" class="level3" data-number="2.12.6">
<h3 data-number="2.12.6" class="anchored" data-anchor-id="additional-exercises"><span class="header-section-number">2.12.6</span> Additional exercises</h3>
<p>If time permits, we will address these additional exercises in class.</p>
<p>These exercises replace <code>achmat08</code> with</p>
<ul>
<li><code>achrdg08</code>: eighth grade Reading Achievement (percent correct on a reading test)</li>
</ul>
<p>Please answer the following questions using R.</p>
<ul>
<li><p>Plot <code>achrdg08</code> against <code>ses</code>. Is there any evidence of nonlinearity in the relationship?</p></li>
<li><p>What is the correlation between <code>achrdg08</code> and <code>ses</code>? How does it compare to the correlation with Math and SES?</p></li>
<li><p>How much variation in Reading is explained by SES? Is this more or less than for Math? Is the proportion of variance explained significant at the .05 level?</p></li>
<li><p>How much do predicted Reading scores increase for a one unit of increase in SES? Is this a statistically significant at the .05 level?</p></li>
<li><p>What are your overall conclusions about the relationship between Academic Achievement and SES in the NELS data?</p></li>
</ul>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch1_review.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Review</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb59" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> true</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: 72</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simple Regression {#sec-chap-2}</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a>The focus of this course is linear regression with multiple predictors (AKA *multiple regression*), but we start by reviewing regression with one predictor (AKA *simple regression*).</span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## An example from NELS {#example-2}</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a>Figure \@ref(fig:fig1) shows the relationship between Grade 8 Math Achievement (percent correct on a math test) and Socioeconomic Status (SES; a composite measure on a scale from 0-35). The data are a subsample of the 1988 National Educational Longitudinal Survey (NELS; see <span class="ot">&lt;https://nces.ed.gov/surveys/nels88/&gt;</span>).</span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig1, fig.cap = 'Math Achievement and SES (NELS88).', fig.align = 'center'}</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and attach the NELS88 data</span></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"NELS.RData"</span>)</span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(NELS)</span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression model</span></span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb59-28"><a href="#cb59-28" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod) </span>
<span id="cb59-29"><a href="#cb59-29" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-30"><a href="#cb59-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-31"><a href="#cb59-31" aria-hidden="true" tabindex="-1"></a>The strength and direction of the linear relationship between the two variables is summarized by their correlation (specifically, the Pearson product moment correlation). In this sample, the correlation is</span>
<span id="cb59-32"><a href="#cb59-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-35"><a href="#cb59-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-36"><a href="#cb59-36" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb59-37"><a href="#cb59-37" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)</span>
<span id="cb59-38"><a href="#cb59-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-39"><a href="#cb59-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-40"><a href="#cb59-40" aria-hidden="true" tabindex="-1"></a>This is a moderate, positive correlation between Math Achievement and SES. This correlation means that eighth graders from more well-off families (higher SES) also tended to do better in math (higher Math Achievement).</span>
<span id="cb59-41"><a href="#cb59-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-42"><a href="#cb59-42" aria-hidden="true" tabindex="-1"></a>This relationship between SES and academic achievement has been widely documented and discussed in education research (e.g., <span class="ot">&lt;https://www.apa.org/pi/ses/resources/publications/education&gt;</span>). **Please look over this web page and be prepared to share your thoughts about this relationship.**</span>
<span id="cb59-43"><a href="#cb59-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-44"><a href="#cb59-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## The regression line {#regression-line-2}</span></span>
<span id="cb59-45"><a href="#cb59-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-46"><a href="#cb59-46" aria-hidden="true" tabindex="-1"></a>The line in the Figure \@ref(fig:fig1) can be represented mathematically as</span>
<span id="cb59-47"><a href="#cb59-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-48"><a href="#cb59-48" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb59-49"><a href="#cb59-49" aria-hidden="true" tabindex="-1"></a>\widehat Y = a + b X</span>
<span id="cb59-50"><a href="#cb59-50" aria-hidden="true" tabindex="-1"></a>(<span class="sc">\#</span>eq:yhat)</span>
<span id="cb59-51"><a href="#cb59-51" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb59-52"><a href="#cb59-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-53"><a href="#cb59-53" aria-hidden="true" tabindex="-1"></a>where</span>
<span id="cb59-54"><a href="#cb59-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-55"><a href="#cb59-55" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$Y$ denotes Math Achievement</span>
<span id="cb59-56"><a href="#cb59-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$X$ denotes SES</span>
<span id="cb59-57"><a href="#cb59-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$a$ represents the regression intercept (the value of $\widehat Y$ when $X = 0$)</span>
<span id="cb59-58"><a href="#cb59-58" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$b$ represents the regression slope (how much $\widehat Y$ increases for each unit of increase in $X$)</span>
<span id="cb59-59"><a href="#cb59-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-60"><a href="#cb59-60" aria-hidden="true" tabindex="-1"></a>Note that $Y$ represents the values of Math Achievement in the data, whereas $\widehat Y$ represents the values computed from the regression equation (i.e., the values on the regression line). The difference $e = Y - \widehat Y$ is called a *residual*. The residuals for a subset of the data points in Figure \@ref(fig:fig1) are shown in pink in Figure \@ref(fig:fig2)</span>
<span id="cb59-61"><a href="#cb59-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-62"><a href="#cb59-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig2, fig.cap = 'Residuals for a Subsample of the Example.', fig.align = 'center'}</span></span>
<span id="cb59-63"><a href="#cb59-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Get predicted values from regression model</span></span>
<span id="cb59-64"><a href="#cb59-64" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> mod<span class="sc">$</span>fitted.values</span>
<span id="cb59-65"><a href="#cb59-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-66"><a href="#cb59-66" aria-hidden="true" tabindex="-1"></a><span class="co"># select a subset of the data</span></span>
<span id="cb59-67"><a href="#cb59-67" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb59-68"><a href="#cb59-68" aria-hidden="true" tabindex="-1"></a>index <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(<span class="dv">500</span>, <span class="dv">30</span>)</span>
<span id="cb59-69"><a href="#cb59-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-70"><a href="#cb59-70" aria-hidden="true" tabindex="-1"></a><span class="co"># plot again</span></span>
<span id="cb59-71"><a href="#cb59-71" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb59-72"><a href="#cb59-72" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb59-73"><a href="#cb59-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-74"><a href="#cb59-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Add pink lines</span></span>
<span id="cb59-75"><a href="#cb59-75" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> ses[index], <span class="at">y0 =</span> yhat[index] , <span class="at">x1 =</span> ses[index], <span class="at">y1 =</span> achmat08[index], <span class="at">col =</span> <span class="dv">6</span>, <span class="at">lty =</span> <span class="dv">3</span>)</span>
<span id="cb59-76"><a href="#cb59-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-77"><a href="#cb59-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Overwrite dots to make it look at bit better</span></span>
<span id="cb59-78"><a href="#cb59-78" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb59-79"><a href="#cb59-79" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-80"><a href="#cb59-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-81"><a href="#cb59-81" aria-hidden="true" tabindex="-1"></a>Notice that $Y = \widehat Y + e$ by definition. So, we can use either Equation \@ref(eq:yhat) or the equation below to write out a regression model:</span>
<span id="cb59-82"><a href="#cb59-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-83"><a href="#cb59-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb59-84"><a href="#cb59-84" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align} </span></span>
<span id="cb59-85"><a href="#cb59-85" aria-hidden="true" tabindex="-1"></a><span class="in">Y = a + bX + e.  </span></span>
<span id="cb59-86"><a href="#cb59-86" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:y)</span></span>
<span id="cb59-87"><a href="#cb59-87" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb59-88"><a href="#cb59-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-89"><a href="#cb59-89" aria-hidden="true" tabindex="-1"></a>Both equations say the same thing, but Equation \@ref(eq:y) lets us talk about the values of $Y$ in the data, not just the predicted values.</span>
<span id="cb59-90"><a href="#cb59-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-91"><a href="#cb59-91" aria-hidden="true" tabindex="-1"></a>Another way to write out the model is using the variable names (or abbreviations) in place of the more generic "X, Y" notation. For example,</span>
<span id="cb59-92"><a href="#cb59-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-93"><a href="#cb59-93" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb59-94"><a href="#cb59-94" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align} </span></span>
<span id="cb59-95"><a href="#cb59-95" aria-hidden="true" tabindex="-1"></a><span class="in">\widehat {MATH} = a + b(SES). </span></span>
<span id="cb59-96"><a href="#cb59-96" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:read)</span></span>
<span id="cb59-97"><a href="#cb59-97" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb59-98"><a href="#cb59-98" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-99"><a href="#cb59-99" aria-hidden="true" tabindex="-1"></a>This notation is more informative about the specific variables in the example. But it is also more clunky and doesn't lend itself to other mathematical expressions. For example, $r_{XY}$ is much clearer than $r_{SES, MATH}$ -- in general, we want most of the text on the "baseline", not the subscripts or superscripts.</span>
<span id="cb59-100"><a href="#cb59-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-101"><a href="#cb59-101" aria-hidden="true" tabindex="-1"></a>You should be familiar with all 3 ways of presenting regression equations and you are free to use whatever approach you like best in your own writing.</span>
<span id="cb59-102"><a href="#cb59-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-103"><a href="#cb59-103" aria-hidden="true" tabindex="-1"></a><span class="fu">## OLS {#ols-2}</span></span>
<span id="cb59-104"><a href="#cb59-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-105"><a href="#cb59-105" aria-hidden="true" tabindex="-1"></a>Intuitively, one approach to “fitting a line to the data” is to select the parameters of the line (its slope and intercept) to minimize the residuals. In ordinary least squares (OLS) regression, we minimize a related quantity, the sum of squared residuals:</span>
<span id="cb59-106"><a href="#cb59-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-107"><a href="#cb59-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb59-108"><a href="#cb59-108" aria-hidden="true" tabindex="-1"></a>\begin{align} </span>
<span id="cb59-109"><a href="#cb59-109" aria-hidden="true" tabindex="-1"></a>SS_{\text{res}} &amp; = \sum_{i=1}^{N} e_i^2 <span class="sc">\\</span> </span>
<span id="cb59-110"><a href="#cb59-110" aria-hidden="true" tabindex="-1"></a>&amp; = \sum_{i=1}^{N} (Y_i - a - b X_i)^2 </span>
<span id="cb59-111"><a href="#cb59-111" aria-hidden="true" tabindex="-1"></a>\end{align} </span>
<span id="cb59-112"><a href="#cb59-112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb59-113"><a href="#cb59-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-114"><a href="#cb59-114" aria-hidden="true" tabindex="-1"></a>where $i = 1 \dots N$ indexes the respondents in the sample. OLS regression is very widely used and is the main focus of this course, although we will visit some other approaches in the second half of the course.</span>
<span id="cb59-115"><a href="#cb59-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-116"><a href="#cb59-116" aria-hidden="true" tabindex="-1"></a>Solving the minimization problem (setting derivatives to zero) gives the following equations for the regression parameters:</span>
<span id="cb59-117"><a href="#cb59-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-118"><a href="#cb59-118" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb59-119"><a href="#cb59-119" aria-hidden="true" tabindex="-1"></a>a = \bar Y - b \bar X \quad \quad \quad \quad b = \frac{\text{Cov}(X, Y)}{s^2_X} = r_{XY} \frac{s_Y}{s_X}</span>
<span id="cb59-120"><a href="#cb59-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb59-121"><a href="#cb59-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-122"><a href="#cb59-122" aria-hidden="true" tabindex="-1"></a>(If you aren't familiar with the symbols in these equations, check out the review materials in Section \@ref(review-2) for a refresher.)</span>
<span id="cb59-123"><a href="#cb59-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-124"><a href="#cb59-124" aria-hidden="true" tabindex="-1"></a>For the NELS example, the regression intercept and slope are, respectively:</span>
<span id="cb59-125"><a href="#cb59-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-128"><a href="#cb59-128" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-129"><a href="#cb59-129" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span>
<span id="cb59-130"><a href="#cb59-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-131"><a href="#cb59-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-132"><a href="#cb59-132" aria-hidden="true" tabindex="-1"></a>**Please write down an interpretation of these numbers in terms of the line in Figure** \@ref(fig:fig1)**, and be prepared to share your answers in class!**</span>
<span id="cb59-133"><a href="#cb59-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-134"><a href="#cb59-134" aria-hidden="true" tabindex="-1"></a><span class="fu">### Correlation and regression</span></span>
<span id="cb59-135"><a href="#cb59-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-136"><a href="#cb59-136" aria-hidden="true" tabindex="-1"></a>Note that if $X$ and $Y$ are transformed to z-scores (i.e., to have mean of zero and variance of one), then</span>
<span id="cb59-137"><a href="#cb59-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-138"><a href="#cb59-138" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$a = 0$</span>
<span id="cb59-139"><a href="#cb59-139" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>$b = \text{Cov}(X, Y) = r_{XY}$</span>
<span id="cb59-140"><a href="#cb59-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-141"><a href="#cb59-141" aria-hidden="true" tabindex="-1"></a>(You can check these results by plugging the value 0 for the means and the value 1 for the variance in the equations above.)</span>
<span id="cb59-142"><a href="#cb59-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-143"><a href="#cb59-143" aria-hidden="true" tabindex="-1"></a>So, regression, correlation, and covariance are all very closely related when we consider only two variables at a time. This is why we didn't make a big deal about simple regression in EDUC 710 -- its basically just the same thing as correlation. But, when we get to multiple regression (i.e., more than one $X$ variable), we will see that relationship between regression and correlation (and covariance) gets more complicated.</span>
<span id="cb59-144"><a href="#cb59-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-145"><a href="#cb59-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb59-146"><a href="#cb59-146" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;!-- ## Residuals </span></span>
<span id="cb59-147"><a href="#cb59-147" aria-hidden="true" tabindex="-1"></a><span class="in">- show that Cor(\hatY e) = 0  and explain why that is important</span></span>
<span id="cb59-148"><a href="#cb59-148" aria-hidden="true" tabindex="-1"></a><span class="in">- talk about standard error of estimate and how its used</span></span>
<span id="cb59-149"><a href="#cb59-149" aria-hidden="true" tabindex="-1"></a><span class="in">--&gt;</span></span>
<span id="cb59-150"><a href="#cb59-150" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-151"><a href="#cb59-151" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-squared {#rsquared-2}</span></span>
<span id="cb59-152"><a href="#cb59-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-153"><a href="#cb59-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-154"><a href="#cb59-154" aria-hidden="true" tabindex="-1"></a>In the previous section we saw that the predicted value of Math Achievement increased by .43 units (about half a percentage point) for each unit of increase in SES. Another way to interpret this relationship is in terms of the proportion of variance in Math Achievement that is associated with SES -- i.e., to what extent are individual differences in Math Achievement associated with, or explained by, individual differences in SES?</span>
<span id="cb59-155"><a href="#cb59-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-156"><a href="#cb59-156" aria-hidden="true" tabindex="-1"></a>This question is represented graphically in Figure \@ref(fig:rsquared). The horizontal line denotes the mean of Math Achievement. The difference between the indicated student's Math Achievement score and the mean can be divided into two parts.</span>
<span id="cb59-157"><a href="#cb59-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-158"><a href="#cb59-158" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The black dashed line shows how much closer we get to the student's Math Achievement score ($Y$) by considering the predicted values ($\widehat Y$) instead of the overall mean ($\bar Y$). This represents the extent to which this student's Math Achievement is explained by the linear relationship with SES.</span>
<span id="cb59-159"><a href="#cb59-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-160"><a href="#cb59-160" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The pink dashed line is the regression residual, which was introduced in Section \@ref(regression-line-2). This is the variation in Math Achievement that is "left over" after considering the linear relationship with SES.</span>
<span id="cb59-161"><a href="#cb59-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-162"><a href="#cb59-162" aria-hidden="true" tabindex="-1"></a><span class="in">```{r rsquared, fig.cap = 'The Idea Behind R-squared.', fig.align = 'center', echo = F}</span></span>
<span id="cb59-163"><a href="#cb59-163" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb59-164"><a href="#cb59-164" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb59-165"><a href="#cb59-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-166"><a href="#cb59-166" aria-hidden="true" tabindex="-1"></a>ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(achmat08)</span>
<span id="cb59-167"><a href="#cb59-167" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> ybar, <span class="at">col =</span> <span class="st">"gray"</span>)</span>
<span id="cb59-168"><a href="#cb59-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-169"><a href="#cb59-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Add pink lines for case 6</span></span>
<span id="cb59-170"><a href="#cb59-170" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> ses[index[<span class="dv">22</span>]], <span class="at">y0 =</span> yhat[index[<span class="dv">22</span>]] , <span class="at">x1 =</span> ses[index[<span class="dv">22</span>]], <span class="at">y1 =</span> achmat08[index[<span class="dv">22</span>]], <span class="at">col =</span> <span class="dv">6</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb59-171"><a href="#cb59-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-172"><a href="#cb59-172" aria-hidden="true" tabindex="-1"></a><span class="co"># Add black lines </span></span>
<span id="cb59-173"><a href="#cb59-173" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> ses[index[<span class="dv">22</span>]], <span class="at">y0 =</span> yhat[index[<span class="dv">22</span>]] , <span class="at">x1 =</span> ses[index[<span class="dv">22</span>]], <span class="at">y1 =</span> ybar, <span class="at">col =</span> <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb59-174"><a href="#cb59-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-175"><a href="#cb59-175" aria-hidden="true" tabindex="-1"></a><span class="co"># Overwrite dots to make it look at bit better</span></span>
<span id="cb59-176"><a href="#cb59-176" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x =</span> ses[index], <span class="at">y =</span> achmat08[index], <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb59-177"><a href="#cb59-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-178"><a href="#cb59-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-179"><a href="#cb59-179" aria-hidden="true" tabindex="-1"></a>The R-squared statistic averages the variation in Math Achievement associated with SES (i.e., the black dashed line) relative to the total variation in Math Achievement (i.e., black + pink) for all students in the sample. R-squared is a widely used statistic in regression analysis, so we will be seeing it a lot. Some authors call it the "coefficient of determination" instead of R-squared.</span>
<span id="cb59-180"><a href="#cb59-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-181"><a href="#cb59-181" aria-hidden="true" tabindex="-1"></a>Using all of the cases from the example (Figure \@ref(fig:fig1)), the R-squared statistic is:</span>
<span id="cb59-182"><a href="#cb59-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-185"><a href="#cb59-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-186"><a href="#cb59-186" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">5</span>)</span>
<span id="cb59-187"><a href="#cb59-187" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span>
<span id="cb59-188"><a href="#cb59-188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-189"><a href="#cb59-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-190"><a href="#cb59-190" aria-hidden="true" tabindex="-1"></a>**Please write down an interpretation of this number and be prepared to share your answer in class.**</span>
<span id="cb59-191"><a href="#cb59-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-192"><a href="#cb59-192" aria-hidden="true" tabindex="-1"></a><span class="fu">### Derivation\*</span></span>
<span id="cb59-193"><a href="#cb59-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-194"><a href="#cb59-194" aria-hidden="true" tabindex="-1"></a>To derive the R-squared statistic we work the numerator of the variance, which is called the total sum of squares.</span>
<span id="cb59-195"><a href="#cb59-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-196"><a href="#cb59-196" aria-hidden="true" tabindex="-1"></a>$$SS_{\text{total}} = \sum_{i = 1}^N (Y_i - \bar Y)^2. $$</span>
<span id="cb59-197"><a href="#cb59-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-198"><a href="#cb59-198" aria-hidden="true" tabindex="-1"></a>It can be re-written using the predicted values $\widehat Y$:</span>
<span id="cb59-199"><a href="#cb59-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-200"><a href="#cb59-200" aria-hidden="true" tabindex="-1"></a>$$SS_{\text{total}} = \sum_{i = 1}^N <span class="co">[</span><span class="ot">(Y_i - \widehat Y_i) + (\widehat Y_i - \bar Y)</span><span class="co">]</span>^2. $$</span>
<span id="cb59-201"><a href="#cb59-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-202"><a href="#cb59-202" aria-hidden="true" tabindex="-1"></a>The right hand side can be reduced to two other sums of squares using the rules of summation algebra (see the review in Section \@ref(review-2)):</span>
<span id="cb59-203"><a href="#cb59-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-204"><a href="#cb59-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb59-205"><a href="#cb59-205" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align} </span></span>
<span id="cb59-206"><a href="#cb59-206" aria-hidden="true" tabindex="-1"></a><span class="in">SS_{\text{total}} &amp; = \sum_{i = 1}^N (Y_i - \widehat Y_i)^2 + \sum_{i = 1}^N (\widehat Y_i - \bar Y)^2 \\</span></span>
<span id="cb59-207"><a href="#cb59-207" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb59-208"><a href="#cb59-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-209"><a href="#cb59-209" aria-hidden="true" tabindex="-1"></a>The first part is just $SS_\text{res}$ from Section \@ref(ols-2). The second part is called the regression sum of squares and denoted $SS_\text{reg}$. Using this terminology we can re-write the above equation as</span>
<span id="cb59-210"><a href="#cb59-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-211"><a href="#cb59-211" aria-hidden="true" tabindex="-1"></a>$$ SS_{\text{total}} = SS_\text{res} + SS_\text{reg} $$</span>
<span id="cb59-212"><a href="#cb59-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-213"><a href="#cb59-213" aria-hidden="true" tabindex="-1"></a>The R-squared statistic is</span>
<span id="cb59-214"><a href="#cb59-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-215"><a href="#cb59-215" aria-hidden="true" tabindex="-1"></a>$$R^2 = SS_{\text{reg}} / SS_{\text{total}}. $$</span>
<span id="cb59-216"><a href="#cb59-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-217"><a href="#cb59-217" aria-hidden="true" tabindex="-1"></a>As discussed above, this is interpreted as the proportion of variance in $Y$ that is explained by its linear relationship with $X$.</span>
<span id="cb59-218"><a href="#cb59-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-219"><a href="#cb59-219" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb59-220"><a href="#cb59-220" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;!--</span></span>
<span id="cb59-221"><a href="#cb59-221" aria-hidden="true" tabindex="-1"></a><span class="in">### Additional details* </span></span>
<span id="cb59-222"><a href="#cb59-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-223"><a href="#cb59-223" aria-hidden="true" tabindex="-1"></a><span class="in">Another way to get to $R^2$ is through the definition of $R$ as the correlation between $Y$ and $\widehat Y$. In simple regression, this is just equal to the regular correlation coefficient (Again, you can use the rules of summation algebra to show this). </span></span>
<span id="cb59-224"><a href="#cb59-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-225"><a href="#cb59-225" aria-hidden="true" tabindex="-1"></a><span class="in">\[ R = \text{cor}(Y, \widehat Y) = \text{cor}(Y, a + bX) = \text{cor}(Y, X)\]</span></span>
<span id="cb59-226"><a href="#cb59-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-227"><a href="#cb59-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-228"><a href="#cb59-228" aria-hidden="true" tabindex="-1"></a><span class="in">Consequently, in simple regression, $R^2 = r^2_{XY}$ -- i.e., the proportion of variance explained by the predictor is just the squared Person product moment correlation. When we add multiple predictors, this relationship between $R^2$ and $r^2_{XY}$ no longer holds. </span></span>
<span id="cb59-229"><a href="#cb59-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-230"><a href="#cb59-230" aria-hidden="true" tabindex="-1"></a><span class="in">Still need to show the two definitions of R-squared are equivalent ;</span></span>
<span id="cb59-231"><a href="#cb59-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-232"><a href="#cb59-232" aria-hidden="true" tabindex="-1"></a><span class="in">\[ R^2 = SS_reg /SS_total = \text{var}(\hat Y) / \text{var}(Y) = \text{var}(a + bX) / \text{var}(Y)</span></span>
<span id="cb59-233"><a href="#cb59-233" aria-hidden="true" tabindex="-1"></a><span class="in">= b^2 \text{var}(X) / \text{var}(Y)= \text{cov}(X, Y)^2 / \text{var}(X) \text{var}(Y)= r^2</span></span>
<span id="cb59-234"><a href="#cb59-234" aria-hidden="true" tabindex="-1"></a><span class="in">\]</span></span>
<span id="cb59-235"><a href="#cb59-235" aria-hidden="true" tabindex="-1"></a><span class="in">--&gt;</span></span>
<span id="cb59-236"><a href="#cb59-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-237"><a href="#cb59-237" aria-hidden="true" tabindex="-1"></a><span class="fu">## The population model {#population-model-2}</span></span>
<span id="cb59-238"><a href="#cb59-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-239"><a href="#cb59-239" aria-hidden="true" tabindex="-1"></a>In the NELS example, the population of interest is U.S. eighth graders in 1988. We want to be able to draw conclusions about that population based on the sample of eighth graders that participated in NELS. In order to do that, we make some statistical assumptions about the population, which are collectively referred to as the population model. We talk about how to check the plausibility of these assumptions in Chapter \@ref(chapter-8).</span>
<span id="cb59-240"><a href="#cb59-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-241"><a href="#cb59-241" aria-hidden="true" tabindex="-1"></a>The regression population model has the following three assumptions, which are also depicted in the diagram below. Recall that the notation $Y \sim N(\mu, \sigma)$ means that a variable $Y$ has a normal distribution with mean $\mu$ and standard deviation $\sigma$.</span>
<span id="cb59-242"><a href="#cb59-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-243"><a href="#cb59-243" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Normality: The values of $Y$ conditional on $X$, denoted $Y|X$, are normally distributed (the figure shows these distributions for three values of $X$):</span>
<span id="cb59-244"><a href="#cb59-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-245"><a href="#cb59-245" aria-hidden="true" tabindex="-1"></a>$$Y | X \sim  N(\mu_{Y | X} , \sigma_{Y | X}) $$</span>
<span id="cb59-246"><a href="#cb59-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-247"><a href="#cb59-247" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>Homoskedasticity: The conditional distributions have equal variances (also called homegeneity of variance).</span>
<span id="cb59-248"><a href="#cb59-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-249"><a href="#cb59-249" aria-hidden="true" tabindex="-1"></a>$$ \sigma_{Y| X} = \sigma $$</span>
<span id="cb59-250"><a href="#cb59-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-251"><a href="#cb59-251" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Linearity: The means of the conditional distributions are a linear function of $X$.</span>
<span id="cb59-252"><a href="#cb59-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-253"><a href="#cb59-253" aria-hidden="true" tabindex="-1"></a>$$ \mu_{Y| Χ} = a + bX $$</span>
<span id="cb59-254"><a href="#cb59-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-255"><a href="#cb59-255" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, pop-model, echo = F, fig.cap = "The Regression Population Model.", fig.align = 'center'}</span></span>
<span id="cb59-256"><a href="#cb59-256" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"files/images/population_model.png"</span>)</span>
<span id="cb59-257"><a href="#cb59-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-258"><a href="#cb59-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-259"><a href="#cb59-259" aria-hidden="true" tabindex="-1"></a>These three assumptions are summarized by writing</span>
<span id="cb59-260"><a href="#cb59-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-261"><a href="#cb59-261" aria-hidden="true" tabindex="-1"></a>$$ Y|X \sim N(a + bX, \sigma). $$</span>
<span id="cb59-262"><a href="#cb59-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-263"><a href="#cb59-263" aria-hidden="true" tabindex="-1"></a>Sometimes it will be easier to state the assumptions in terms of the population residuals, $\epsilon = Y - \mu_{Y|X}$, which subtracts off the regression line: $\epsilon \sim N(0, \sigma)$.</span>
<span id="cb59-264"><a href="#cb59-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-265"><a href="#cb59-265" aria-hidden="true" tabindex="-1"></a>An additional assumption is usually made about the data in the sample -- that they were obtained as a simple random sample from the population. We will see some ways of dealing with other types of samples later on the course, but for now we can consider this a background assumption that applies to all of the procedures discussed in this course.</span>
<span id="cb59-266"><a href="#cb59-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-267"><a href="#cb59-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clarifying notation {#notation-2}</span></span>
<span id="cb59-268"><a href="#cb59-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-269"><a href="#cb59-269" aria-hidden="true" tabindex="-1"></a>At this point we have used the mathematical symbols for regression (e.g., $a$, $b$) in two different ways:</span>
<span id="cb59-270"><a href="#cb59-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-271"><a href="#cb59-271" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In Section \@ref(regression-line-2) they denoted sample statistics.</span>
<span id="cb59-272"><a href="#cb59-272" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>In Section \@ref(population-model-2) they denoted population parameters.</span>
<span id="cb59-273"><a href="#cb59-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-274"><a href="#cb59-274" aria-hidden="true" tabindex="-1"></a>The population versus sample notation for regression is a bit of a hot mess, but the following conventions are widely used.</span>
<span id="cb59-275"><a href="#cb59-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-276"><a href="#cb59-276" aria-hidden="true" tabindex="-1"></a>| Concept            | Sample statistic | Population parameter |</span>
<span id="cb59-277"><a href="#cb59-277" aria-hidden="true" tabindex="-1"></a>|--------------------|:----------------:|:--------------------:|</span>
<span id="cb59-278"><a href="#cb59-278" aria-hidden="true" tabindex="-1"></a>| regression line    |   $\widehat Y$   |     $\mu_{Y|X}$      |</span>
<span id="cb59-279"><a href="#cb59-279" aria-hidden="true" tabindex="-1"></a>| slope              |   $\widehat b$   |         $b$          |</span>
<span id="cb59-280"><a href="#cb59-280" aria-hidden="true" tabindex="-1"></a>| intercept          |   $\widehat a$   |         $a$          |</span>
<span id="cb59-281"><a href="#cb59-281" aria-hidden="true" tabindex="-1"></a>| residual           |       $e$        |      $\epsilon$      |</span>
<span id="cb59-282"><a href="#cb59-282" aria-hidden="true" tabindex="-1"></a>| variance explained |  $\widehat R^2$  |        $R^2$         |</span>
<span id="cb59-283"><a href="#cb59-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-284"><a href="#cb59-284" aria-hidden="true" tabindex="-1"></a>The "hats" always denote sample quantities, and the Greek letters (in this table) always denote population quantities, but there is some lack of consistency. For example, why not use $\beta$ instead of $b$ for the population slope? Well, $\beta$ is conventionally used to denote standardized regression coefficients in the *sample*, so its already taken (more on this in the Chapter \@ref(chapter-4) ).</span>
<span id="cb59-285"><a href="#cb59-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-286"><a href="#cb59-286" aria-hidden="true" tabindex="-1"></a>One thing to note is that the hats are usually omitted from the statistics $\widehat a$, $\widehat b$, and $\widehat R^2$ if it is clear from context that we are talking about the sample rather than the population. This doesn't apply to $\widehat Y$, because the hat is required to distinguish the predicted values from the data points.</span>
<span id="cb59-287"><a href="#cb59-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-288"><a href="#cb59-288" aria-hidden="true" tabindex="-1"></a>Another thing to note is that while $\widehat Y$ are often called the predicted values, $\mu_{Y|X}$ is not usually referred to this way. It is called the conditional mean function or the conditional expectation function. We will introduce some other notations for $\widehat Y$ and $\mu_{Y|X}$ later in the course.</span>
<span id="cb59-289"><a href="#cb59-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-290"><a href="#cb59-290" aria-hidden="true" tabindex="-1"></a>**Please be prepared for a pop quiz on notation during class!**</span>
<span id="cb59-291"><a href="#cb59-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-292"><a href="#cb59-292" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Finally, recall that the symbol $E(\cdot)$ denotes the expected value of whatever statistic appears in the place of the dot. The expected value is a way of referring to the mean of the sampling distribution of the statistic (otherwise we would have to say things like "the mean of the mean", which would be horrible). So $E(Y\mid X)$ is the expected value of $Y$ for a given value of $X$. The $\mu_{Y|X}$ is the the population conditional mean, $\mu_{Y|X}$ is equal to $E(Y\mid X)$ when the population model is true (i.e., OLS regression is an unbiased estimator of the population conditional mean function). So, the two symbols are used interchangeably. (Omit this paragraph?) --&gt;</span></span>
<span id="cb59-293"><a href="#cb59-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-294"><a href="#cb59-294" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference for the slope {#inference-for-slope-2}</span></span>
<span id="cb59-295"><a href="#cb59-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-296"><a href="#cb59-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-297"><a href="#cb59-297" aria-hidden="true" tabindex="-1"></a>When the population model is true, $\widehat b$ is an unbiased estimate of $b$. We also know the standard error of $\widehat b$, which is equal to (cite:fox)</span>
<span id="cb59-298"><a href="#cb59-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-299"><a href="#cb59-299" aria-hidden="true" tabindex="-1"></a>$$ s_{\widehat b} = \frac{s_Y}{s_X} \sqrt{\frac{1-R^2}{N-2}} . $$</span>
<span id="cb59-300"><a href="#cb59-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-301"><a href="#cb59-301" aria-hidden="true" tabindex="-1"></a>Using these two results, we can compute t-tests and confidence intervals for the regression slope in the usual way. These are summarized below. See the review in Section \@ref(review-2) for background information on bias, standard errors, t-tests, and confidence intervals.</span>
<span id="cb59-302"><a href="#cb59-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-303"><a href="#cb59-303" aria-hidden="true" tabindex="-1"></a><span class="fu">### t-tests</span></span>
<span id="cb59-304"><a href="#cb59-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-305"><a href="#cb59-305" aria-hidden="true" tabindex="-1"></a>The null hypothesis $H_0: \widehat b = b_0$ can be tested against the alternative $H_A: \widehat b \neq b_0$ using the test statistic:</span>
<span id="cb59-306"><a href="#cb59-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-307"><a href="#cb59-307" aria-hidden="true" tabindex="-1"></a>$$ t = \frac{\widehat b - b_0}{s_{\widehat b}} $$</span>
<span id="cb59-308"><a href="#cb59-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-309"><a href="#cb59-309" aria-hidden="true" tabindex="-1"></a>which has a t-distribution on $N-2$ degrees of freedom when the null hypothesis is true.</span>
<span id="cb59-310"><a href="#cb59-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-311"><a href="#cb59-311" aria-hidden="true" tabindex="-1"></a>The test assumes that the population model is correct. The null hypothesis value of the parameter is usually chosen to be $b_0 = 0$, in which case the test is interpreted in terms of the "statistical significance" of the regression slope.</span>
<span id="cb59-312"><a href="#cb59-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-313"><a href="#cb59-313" aria-hidden="true" tabindex="-1"></a><span class="fu">### Confidence intervals</span></span>
<span id="cb59-314"><a href="#cb59-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-315"><a href="#cb59-315" aria-hidden="true" tabindex="-1"></a>For a given Type I Error rate, $\alpha$, the corresponding $(1-\alpha) \times 100\%$ confidence interval is</span>
<span id="cb59-316"><a href="#cb59-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-317"><a href="#cb59-317" aria-hidden="true" tabindex="-1"></a>$$ b_0 = \widehat b \pm t_{\alpha/2} \times s_{\widehat b} $$</span>
<span id="cb59-318"><a href="#cb59-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-319"><a href="#cb59-319" aria-hidden="true" tabindex="-1"></a>where $t_{\alpha/2}$ denotes the $\alpha/2$ quantile of the $t$-distribution with $N-2$ degrees of freedom.</span>
<span id="cb59-320"><a href="#cb59-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-321"><a href="#cb59-321" aria-hidden="true" tabindex="-1"></a>For example, if $\alpha$ is chosen to be $.05$, the corresponding $95\%$ confidence interval uses $t_{.025}$, or the 2.5-th percentile of the t-distribution.</span>
<span id="cb59-322"><a href="#cb59-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-323"><a href="#cb59-323" aria-hidden="true" tabindex="-1"></a><span class="fu">### The NELS example</span></span>
<span id="cb59-324"><a href="#cb59-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-325"><a href="#cb59-325" aria-hidden="true" tabindex="-1"></a>For the NELS example, the t-test of the regression slope is shown in the second row of the table below (we cover the rest of the output in the next few sections):</span>
<span id="cb59-326"><a href="#cb59-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-329"><a href="#cb59-329" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-330"><a href="#cb59-330" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb59-331"><a href="#cb59-331" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-332"><a href="#cb59-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-333"><a href="#cb59-333" aria-hidden="true" tabindex="-1"></a>The corresponding $95\%$ confidence interval is</span>
<span id="cb59-334"><a href="#cb59-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-337"><a href="#cb59-337" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-338"><a href="#cb59-338" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span>
<span id="cb59-339"><a href="#cb59-339" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-340"><a href="#cb59-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-341"><a href="#cb59-341" aria-hidden="true" tabindex="-1"></a>**Please write down an interpretation of the t-test and confidence interval of the regression slope, and be prepared to share your answers in class!**</span>
<span id="cb59-342"><a href="#cb59-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-343"><a href="#cb59-343" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference for the intercept {#inference-for-intercept-2}</span></span>
<span id="cb59-344"><a href="#cb59-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-345"><a href="#cb59-345" aria-hidden="true" tabindex="-1"></a>The situation for the regression intercept is similar to that for the slope: the OLS estimate is unbiased and its standard error is (cite:fox)</span>
<span id="cb59-346"><a href="#cb59-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-347"><a href="#cb59-347" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--- check this and get source --&gt;</span></span>
<span id="cb59-348"><a href="#cb59-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-349"><a href="#cb59-349" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb59-350"><a href="#cb59-350" aria-hidden="true" tabindex="-1"></a>s_{\widehat a} = \sqrt{\frac{SS_{\text{res}}}{N-2} \left(\frac{1}{N} + \frac{\bar X^2}{(N-1)s^2_X}\right)}.</span>
<span id="cb59-351"><a href="#cb59-351" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb59-352"><a href="#cb59-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-353"><a href="#cb59-353" aria-hidden="true" tabindex="-1"></a>The t-tests and confidence intervals are constructed in the way same as for the slope, just by $a$ replacing $b$ in the notation of the previous slide. The t-distribution also has $N-2$ degrees of freedom for the intercept.</span>
<span id="cb59-354"><a href="#cb59-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-355"><a href="#cb59-355" aria-hidden="true" tabindex="-1"></a>It is not usually the case that the regression intercept is of interest in simple regression. Recall that the intercept is the value of $\widehat Y$ when $X = 0$. So, unless you have a hypothesis or research question about this particular value of $X$ (e.g., eighth graders with $SES = 0$), you won't be interested in this test (even though R always provides it).</span>
<span id="cb59-356"><a href="#cb59-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-357"><a href="#cb59-357" aria-hidden="true" tabindex="-1"></a>When we get to multiple regression, we will see some examples of regression models where the intercept is meaningful, especially when we talk about categorical predictors in Chapter \@ref(chapter-5) and interactions in Chapter \@ref(chapter-6). But, for now, we can put it on the back burner.</span>
<span id="cb59-358"><a href="#cb59-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-359"><a href="#cb59-359" aria-hidden="true" tabindex="-1"></a><span class="fu">## Inference for R-squared {#inference-for-rsquared-2}</span></span>
<span id="cb59-360"><a href="#cb59-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-361"><a href="#cb59-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-362"><a href="#cb59-362" aria-hidden="true" tabindex="-1"></a>Inference for R-squared is quite a bit different than for the regression parameters. As we saw in section \@ref(rsquared-2), R-squared is a ratio of two sums of squares. We know from our study of ANOVA last semester that ratios of sums of squares are tested using an F-test, rather than a t-test. The F-test for (the population) R-squared is summarized below.</span>
<span id="cb59-363"><a href="#cb59-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-364"><a href="#cb59-364" aria-hidden="true" tabindex="-1"></a><span class="fu">### F-tests</span></span>
<span id="cb59-365"><a href="#cb59-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-366"><a href="#cb59-366" aria-hidden="true" tabindex="-1"></a>The null hypothesis $H_0: R^2 = 0$ can be tested against the alternative $H_A: R^2 \neq 0$ using the test statistic:</span>
<span id="cb59-367"><a href="#cb59-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-368"><a href="#cb59-368" aria-hidden="true" tabindex="-1"></a>$$ F = (N-2) \frac{\widehat R^2}{1-\widehat R^2} $$</span>
<span id="cb59-369"><a href="#cb59-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-370"><a href="#cb59-370" aria-hidden="true" tabindex="-1"></a>which has a F-distribution on $1$ and $N – 2$ degrees of freedom when the null is true. The test assumes that the population model is true. Confidence intervals for R-squared are generally not reported.</span>
<span id="cb59-371"><a href="#cb59-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-372"><a href="#cb59-372" aria-hidden="true" tabindex="-1"></a>The R output from Section \@ref(inference-for-slope-2) is presented again below. **Please write down an interpretation of the F-test of R-squared and be prepared to share your answers in class!** Note that the output uses the terminology "multiple R-squared" to refer to R-squared.</span>
<span id="cb59-373"><a href="#cb59-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-376"><a href="#cb59-376" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-377"><a href="#cb59-377" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb59-378"><a href="#cb59-378" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-379"><a href="#cb59-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-380"><a href="#cb59-380" aria-hidden="true" tabindex="-1"></a><span class="fu">## Power analysis {#power-2}</span></span>
<span id="cb59-381"><a href="#cb59-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-382"><a href="#cb59-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-383"><a href="#cb59-383" aria-hidden="true" tabindex="-1"></a>Statistical power is the probability of rejecting the null hypothesis, when it is indeed false. Rejecting the null hypothesis when it is false is sometimes called a "true positive", meaning we have correctly inferred that a parameter of interest is not zero. Power analysis is useful for designing studies so that the statistical power / true positive rate is satisfactory. In practice, this comes down to having a large enough sample size.</span>
<span id="cb59-384"><a href="#cb59-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-385"><a href="#cb59-385" aria-hidden="true" tabindex="-1"></a>Power analysis in regression is very similar to power analysis for the tests we studied last semester. There are four ingredients that go into a power analysis:</span>
<span id="cb59-386"><a href="#cb59-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-387"><a href="#cb59-387" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The desired Type I Error rate, $\alpha$.</span>
<span id="cb59-388"><a href="#cb59-388" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The desired level of statistical power.</span>
<span id="cb59-389"><a href="#cb59-389" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The sample size, $N$.</span>
<span id="cb59-390"><a href="#cb59-390" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>The effect size, which for regression is Cohen's f-squared statistic (AKA the signal to noise ratio):</span>
<span id="cb59-391"><a href="#cb59-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-392"><a href="#cb59-392" aria-hidden="true" tabindex="-1"></a>$$ f^2 = {\frac{R^2}{1-R^2}}. $$</span>
<span id="cb59-393"><a href="#cb59-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-394"><a href="#cb59-394" aria-hidden="true" tabindex="-1"></a>In principal, we can plug-in values for any three of these ingredients and then solve for the fourth. But, as mentioned, power analysis is most useful when we solve for $N$ while planning a study. When solving for $N$ "prospectively," the effect size $f^2$ should be based on reports of R-squared in past research. Power and $\alpha$ are usually chosen to be .8 and .05, respectively.</span>
<span id="cb59-395"><a href="#cb59-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-396"><a href="#cb59-396" aria-hidden="true" tabindex="-1"></a>When doing secondary data analysis (as in this class) there is not much point in solving for the sample size, since we already have the data. Instead, we can solve for the effect size. In the NELS example we have $N=500$ observations. The output below reports the smallest effect size we can detect with a power of .8 and $\alpha = .05$. This is sometimes called the "minimum detectable effect size" (MDES). Note that the output $u$ and $v$ denote the degrees of freedom in the numerator and denominator of the F-test of R-squared, respectively.</span>
<span id="cb59-397"><a href="#cb59-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-400"><a href="#cb59-400" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-401"><a href="#cb59-401" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)</span>
<span id="cb59-402"><a href="#cb59-402" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">v =</span> <span class="dv">498</span>, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span>
<span id="cb59-403"><a href="#cb59-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-404"><a href="#cb59-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-405"><a href="#cb59-405" aria-hidden="true" tabindex="-1"></a>**What is the MDES for the NELS example? Please be prepared to share your answer in class.**</span>
<span id="cb59-406"><a href="#cb59-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-407"><a href="#cb59-407" aria-hidden="true" tabindex="-1"></a><span class="fu">## Workbook {#workbook-2}</span></span>
<span id="cb59-408"><a href="#cb59-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-409"><a href="#cb59-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-410"><a href="#cb59-410" aria-hidden="true" tabindex="-1"></a>This section collects the questions asked in this chapter. We will discuss these questions in class. If you haven't written down / thought about the answers to these questions before class, the lesson will not be very useful for you! So, please engage with each question by writing down one or more answers, asking clarifying questions, posing follow up questions, etc.</span>
<span id="cb59-411"><a href="#cb59-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-412"><a href="#cb59-412" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(example-2)</span>
<span id="cb59-413"><a href="#cb59-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-414"><a href="#cb59-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.cap = 'Math Achievement and SES (NELS88).', fig.align = 'center'}</span></span>
<span id="cb59-415"><a href="#cb59-415" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot</span></span>
<span id="cb59-416"><a href="#cb59-416" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">ylab =</span> <span class="st">"Math Achievement (Grade 8)"</span>, <span class="at">xlab =</span> <span class="st">"SES"</span>)</span>
<span id="cb59-417"><a href="#cb59-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-418"><a href="#cb59-418" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression model</span></span>
<span id="cb59-419"><a href="#cb59-419" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb59-420"><a href="#cb59-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-421"><a href="#cb59-421" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb59-422"><a href="#cb59-422" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod) </span>
<span id="cb59-423"><a href="#cb59-423" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-424"><a href="#cb59-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-425"><a href="#cb59-425" aria-hidden="true" tabindex="-1"></a>The strength and direction of the linear relationship between the two variables is summarized by their correlation (specifically, the Pearson product moment correlation). In the plot above, the correlation is</span>
<span id="cb59-426"><a href="#cb59-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-429"><a href="#cb59-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-430"><a href="#cb59-430" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb59-431"><a href="#cb59-431" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)</span>
<span id="cb59-432"><a href="#cb59-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-433"><a href="#cb59-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-434"><a href="#cb59-434" aria-hidden="true" tabindex="-1"></a>This correlation means that eighth graders from more well-off families (higher SES) also tended to do better in Math (higher Math Achievement).</span>
<span id="cb59-435"><a href="#cb59-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-436"><a href="#cb59-436" aria-hidden="true" tabindex="-1"></a>This relationship between SES and academic achievement has been widely documented and discussed in education research (e.g., <span class="ot">&lt;https://www.apa.org/pi/ses/resources/publications/education&gt;</span>). Please look over this web page and be prepared to share your thoughts about this relationship.</span>
<span id="cb59-437"><a href="#cb59-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-438"><a href="#cb59-438" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(ols-2)</span>
<span id="cb59-439"><a href="#cb59-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-440"><a href="#cb59-440" aria-hidden="true" tabindex="-1"></a>For the NELS example, the regression intercept and slope are, respectively:</span>
<span id="cb59-441"><a href="#cb59-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-444"><a href="#cb59-444" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-445"><a href="#cb59-445" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span>
<span id="cb59-446"><a href="#cb59-446" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-447"><a href="#cb59-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-448"><a href="#cb59-448" aria-hidden="true" tabindex="-1"></a>Please write down an interpretation of these numbers in terms of the line in Figure \@ref(fig:fig1), and be prepared to share your answers in class.</span>
<span id="cb59-449"><a href="#cb59-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-450"><a href="#cb59-450" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(rsquared-2)</span>
<span id="cb59-451"><a href="#cb59-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-452"><a href="#cb59-452" aria-hidden="true" tabindex="-1"></a>Using all of the cases from the example (Figure \@ref(fig:fig1)), the R-squared statistic is:</span>
<span id="cb59-453"><a href="#cb59-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-456"><a href="#cb59-456" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-457"><a href="#cb59-457" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">5</span>)</span>
<span id="cb59-458"><a href="#cb59-458" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span>
<span id="cb59-459"><a href="#cb59-459" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-460"><a href="#cb59-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-461"><a href="#cb59-461" aria-hidden="true" tabindex="-1"></a>Please write down an interpretation of this number and be prepared to share your answer in class.</span>
<span id="cb59-462"><a href="#cb59-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-463"><a href="#cb59-463" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(notation-2)</span>
<span id="cb59-464"><a href="#cb59-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-465"><a href="#cb59-465" aria-hidden="true" tabindex="-1"></a>Please be prepared for a pop quiz on notation during class!</span>
<span id="cb59-466"><a href="#cb59-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-467"><a href="#cb59-467" aria-hidden="true" tabindex="-1"></a>| Concept            | Sample statistic | Population parameter |</span>
<span id="cb59-468"><a href="#cb59-468" aria-hidden="true" tabindex="-1"></a>|--------------------|:----------------:|:--------------------:|</span>
<span id="cb59-469"><a href="#cb59-469" aria-hidden="true" tabindex="-1"></a>| regression line    |                  |                      |</span>
<span id="cb59-470"><a href="#cb59-470" aria-hidden="true" tabindex="-1"></a>| slope              |                  |                      |</span>
<span id="cb59-471"><a href="#cb59-471" aria-hidden="true" tabindex="-1"></a>| intercept          |                  |                      |</span>
<span id="cb59-472"><a href="#cb59-472" aria-hidden="true" tabindex="-1"></a>| residual           |                  |                      |</span>
<span id="cb59-473"><a href="#cb59-473" aria-hidden="true" tabindex="-1"></a>| variance explained |                  |                      |</span>
<span id="cb59-474"><a href="#cb59-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-475"><a href="#cb59-475" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(inference-for-slope-2)</span>
<span id="cb59-476"><a href="#cb59-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-479"><a href="#cb59-479" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-480"><a href="#cb59-480" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb59-481"><a href="#cb59-481" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-482"><a href="#cb59-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-483"><a href="#cb59-483" aria-hidden="true" tabindex="-1"></a>The corresponding $95\%$ confidence interval is</span>
<span id="cb59-484"><a href="#cb59-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-487"><a href="#cb59-487" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-488"><a href="#cb59-488" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span>
<span id="cb59-489"><a href="#cb59-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-490"><a href="#cb59-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-491"><a href="#cb59-491" aria-hidden="true" tabindex="-1"></a>Please write down an interpretation of the t-test and confidence interval of the regression slope, and be prepared to share your answers in class!</span>
<span id="cb59-492"><a href="#cb59-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-493"><a href="#cb59-493" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(inference-for-rsquared-2)</span>
<span id="cb59-494"><a href="#cb59-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-495"><a href="#cb59-495" aria-hidden="true" tabindex="-1"></a>Using the same output as above, please write down an interpretation of the F-test of R-squared and be prepared to share your answers in class. Note that the output uses the terminology "multiple R-squared" to refer to R-squared.</span>
<span id="cb59-496"><a href="#cb59-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-497"><a href="#cb59-497" aria-hidden="true" tabindex="-1"></a>**Section** \@ref(power-2)</span>
<span id="cb59-498"><a href="#cb59-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-499"><a href="#cb59-499" aria-hidden="true" tabindex="-1"></a>When doing secondary data analysis (as in this class) there is not much point in solving for the sample size, since we already have the data. Instead, we can solve for the effect size. In the NELS example we have $N=500$ observations. The output below reports the smallest effect size we can detect with a power of .8 and $\alpha = .05$. This is sometimes called the "minimum detectable effect size" (MDES). Note that the output \$u \$ and $v$ denote the degrees of freedom in the numerator and denominator of the F-test of R-squared, respectively.</span>
<span id="cb59-500"><a href="#cb59-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-503"><a href="#cb59-503" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-504"><a href="#cb59-504" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pwr)</span>
<span id="cb59-505"><a href="#cb59-505" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">v =</span> <span class="dv">498</span>, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span>
<span id="cb59-506"><a href="#cb59-506" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-507"><a href="#cb59-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-508"><a href="#cb59-508" aria-hidden="true" tabindex="-1"></a>What is the MDES for the NELS example? Please be prepared to share your answer in class.</span>
<span id="cb59-509"><a href="#cb59-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-510"><a href="#cb59-510" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises {#exercises-2}</span></span>
<span id="cb59-511"><a href="#cb59-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-512"><a href="#cb59-512" aria-hidden="true" tabindex="-1"></a>These exercises collect all of the R input used in this chapter into a single step-by-step analysis. It explains how the R input works, and provides some additional exercises. We will go through this material in class together, so you don't need to work on it before class (but you can if you want.)</span>
<span id="cb59-513"><a href="#cb59-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-514"><a href="#cb59-514" aria-hidden="true" tabindex="-1"></a><span class="fu">### The `lm` function</span></span>
<span id="cb59-515"><a href="#cb59-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-516"><a href="#cb59-516" aria-hidden="true" tabindex="-1"></a>The function<span class="in">`lm`</span>, short for "linear model", is used to estimate linear regressions using OLS. It also provides a lot of useful output.</span>
<span id="cb59-517"><a href="#cb59-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-518"><a href="#cb59-518" aria-hidden="true" tabindex="-1"></a>The main argument that the user provides to the <span class="in">`lm`</span> function is a formula. For the simple regression of Y on X, a formula has the syntax:</span>
<span id="cb59-519"><a href="#cb59-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-520"><a href="#cb59-520" aria-hidden="true" tabindex="-1"></a><span class="in">`Y ~ X`</span></span>
<span id="cb59-521"><a href="#cb59-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-522"><a href="#cb59-522" aria-hidden="true" tabindex="-1"></a>Here <span class="in">`Y`</span> denotes the outcome variable and <span class="in">`X`</span> is the predictor variable. The tilde <span class="in">`~`</span> just means "equals", but the equals sign <span class="in">`=`</span> is already used to assign values in R, so <span class="in">`~`</span> is used in its place when writing a formula. We will see more complicated formulas as we go through the course. For more information on R's formula syntax, see <span class="in">`help(formula)`</span>.</span>
<span id="cb59-523"><a href="#cb59-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-524"><a href="#cb59-524" aria-hidden="true" tabindex="-1"></a>Let's take a closer look using the following two variables from the NELS data.</span>
<span id="cb59-525"><a href="#cb59-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-526"><a href="#cb59-526" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`achmat08`</span>: eighth grade math achievement (percent correct on a math test)</span>
<span id="cb59-527"><a href="#cb59-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-528"><a href="#cb59-528" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`ses`</span>: a composite measure of socio-economic status, on a scale from 0-35</span>
<span id="cb59-529"><a href="#cb59-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-532"><a href="#cb59-532" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-533"><a href="#cb59-533" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data. Note that you can click on the .RData file and RStudio will load it</span></span>
<span id="cb59-534"><a href="#cb59-534" aria-hidden="true" tabindex="-1"></a><span class="co"># load("NELS.RData") #Un-comment this line to run</span></span>
<span id="cb59-535"><a href="#cb59-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-536"><a href="#cb59-536" aria-hidden="true" tabindex="-1"></a><span class="co"># Attach the data: will dicuss this in class</span></span>
<span id="cb59-537"><a href="#cb59-537" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(NELS) #Un-comment this line to run!</span></span>
<span id="cb59-538"><a href="#cb59-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-539"><a href="#cb59-539" aria-hidden="true" tabindex="-1"></a><span class="co"># Scatter plot of math achievment against SES</span></span>
<span id="cb59-540"><a href="#cb59-540" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x =</span> ses, <span class="at">y =</span> achmat08, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb59-541"><a href="#cb59-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-542"><a href="#cb59-542" aria-hidden="true" tabindex="-1"></a><span class="co"># Regress math achievement on SES; save output as "mod"</span></span>
<span id="cb59-543"><a href="#cb59-543" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat08 <span class="sc">~</span> ses)</span>
<span id="cb59-544"><a href="#cb59-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-545"><a href="#cb59-545" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the regression line to the plot</span></span>
<span id="cb59-546"><a href="#cb59-546" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb59-547"><a href="#cb59-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-548"><a href="#cb59-548" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out the regression coefficients</span></span>
<span id="cb59-549"><a href="#cb59-549" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod)</span>
<span id="cb59-550"><a href="#cb59-550" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-551"><a href="#cb59-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-552"><a href="#cb59-552" aria-hidden="true" tabindex="-1"></a>Let's do some quick calculations to check that the <span class="in">`lm`</span> output corresponds the formulas for the slope and intercept in Section \@ref(ols-2):</span>
<span id="cb59-553"><a href="#cb59-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-554"><a href="#cb59-554" aria-hidden="true" tabindex="-1"></a>$$ a = \bar Y - b \bar X \quad \text{and} \quad b = \frac{\text{Cov}(X, Y)}{s_X^2} $$ We won't usually do these kind of "manual" calculations, but it is a good way consolidate knowledge presented in the readings with the output presented by R. It is also useful to refresh our memory about some useful R functions and how the R language works.</span>
<span id="cb59-555"><a href="#cb59-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-558"><a href="#cb59-558" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-559"><a href="#cb59-559" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm that the slope from lm is equal to the covariance divided by the variance of X</span></span>
<span id="cb59-560"><a href="#cb59-560" aria-hidden="true" tabindex="-1"></a>cov_xy <span class="ot">&lt;-</span> <span class="fu">cov</span>(achmat08, ses)</span>
<span id="cb59-561"><a href="#cb59-561" aria-hidden="true" tabindex="-1"></a>s_x <span class="ot">&lt;-</span> <span class="fu">var</span>(ses)</span>
<span id="cb59-562"><a href="#cb59-562" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> cov_xy <span class="sc">/</span> s_x</span>
<span id="cb59-563"><a href="#cb59-563" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb59-564"><a href="#cb59-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-565"><a href="#cb59-565" aria-hidden="true" tabindex="-1"></a><span class="co"># Confirm that the y-intercept is obtained from the two means and the slope</span></span>
<span id="cb59-566"><a href="#cb59-566" aria-hidden="true" tabindex="-1"></a>xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb59-567"><a href="#cb59-567" aria-hidden="true" tabindex="-1"></a>ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(achmat08)</span>
<span id="cb59-568"><a href="#cb59-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-569"><a href="#cb59-569" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> ybar <span class="sc">-</span> b <span class="sc">*</span> xbar</span>
<span id="cb59-570"><a href="#cb59-570" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb59-571"><a href="#cb59-571" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-572"><a href="#cb59-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-573"><a href="#cb59-573" aria-hidden="true" tabindex="-1"></a>Let's also check our interpretation of the parameters. If the answers to these questions are not clear, please make sure to ask in class!</span>
<span id="cb59-574"><a href="#cb59-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-575"><a href="#cb59-575" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>What is the predicted value of <span class="in">`achmat08`</span> when <span class="in">`ses`</span> is equal to zero?</span>
<span id="cb59-576"><a href="#cb59-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-577"><a href="#cb59-577" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>How much does the predicted value of <span class="in">`achmat08`</span> increase for each unit of increase in <span class="in">`ses`</span>?</span>
<span id="cb59-578"><a href="#cb59-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-579"><a href="#cb59-579" aria-hidden="true" tabindex="-1"></a><span class="fu">### Variance explained</span></span>
<span id="cb59-580"><a href="#cb59-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-581"><a href="#cb59-581" aria-hidden="true" tabindex="-1"></a>Above we found out that the regression coefficient was 0.4-ish. Another way to describe the relationships is by considering the amount of variation in $Y$ that is associated with (or explained by) its relationship with $X$. Recall that one way to do this is via the variance decomposition</span>
<span id="cb59-582"><a href="#cb59-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-583"><a href="#cb59-583" aria-hidden="true" tabindex="-1"></a>$$ SS_{\text{total}} = SS_{\text{res}} + SS_{\text{reg}}$$</span>
<span id="cb59-584"><a href="#cb59-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-585"><a href="#cb59-585" aria-hidden="true" tabindex="-1"></a>from which we can compute the proportion of variation in Y that is associated with the regression model</span>
<span id="cb59-586"><a href="#cb59-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-587"><a href="#cb59-587" aria-hidden="true" tabindex="-1"></a>$$R^2 = \frac{SS_{\text{reg}}}{SS_{\text{total}}}$$</span>
<span id="cb59-588"><a href="#cb59-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-589"><a href="#cb59-589" aria-hidden="true" tabindex="-1"></a>The R-squared for the example is presented in the output below. You should be able to provide an interpretation of this number, so if it's not clear make sure to ask in class!</span>
<span id="cb59-590"><a href="#cb59-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-593"><a href="#cb59-593" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-594"><a href="#cb59-594" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared from the example</span></span>
<span id="cb59-595"><a href="#cb59-595" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>r.squared</span>
<span id="cb59-596"><a href="#cb59-596" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-597"><a href="#cb59-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-598"><a href="#cb59-598" aria-hidden="true" tabindex="-1"></a>As above, let's compute $R^2$ "by hand" for our example.</span>
<span id="cb59-599"><a href="#cb59-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-602"><a href="#cb59-602" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-603"><a href="#cb59-603" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the sums of squares</span></span>
<span id="cb59-604"><a href="#cb59-604" aria-hidden="true" tabindex="-1"></a>ybar <span class="ot">&lt;-</span> <span class="fu">mean</span>(achmat08)</span>
<span id="cb59-605"><a href="#cb59-605" aria-hidden="true" tabindex="-1"></a>ss_total <span class="ot">&lt;-</span> <span class="fu">sum</span>((achmat08 <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb59-606"><a href="#cb59-606" aria-hidden="true" tabindex="-1"></a>ss_reg <span class="ot">&lt;-</span> <span class="fu">sum</span>((yhat <span class="sc">-</span> ybar)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb59-607"><a href="#cb59-607" aria-hidden="true" tabindex="-1"></a>ss_res <span class="ot">&lt;-</span>  <span class="fu">sum</span>((achmat08 <span class="sc">-</span> yhat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb59-608"><a href="#cb59-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-609"><a href="#cb59-609" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that SS_total = SS_reg + SS_res</span></span>
<span id="cb59-610"><a href="#cb59-610" aria-hidden="true" tabindex="-1"></a>ss_total</span>
<span id="cb59-611"><a href="#cb59-611" aria-hidden="true" tabindex="-1"></a>ss_reg <span class="sc">+</span> ss_res</span>
<span id="cb59-612"><a href="#cb59-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-613"><a href="#cb59-613" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute R-squared</span></span>
<span id="cb59-614"><a href="#cb59-614" aria-hidden="true" tabindex="-1"></a>ss_reg<span class="sc">/</span>ss_total</span>
<span id="cb59-615"><a href="#cb59-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-616"><a href="#cb59-616" aria-hidden="true" tabindex="-1"></a><span class="co"># Check that R-squared is really equal to the square of the PPMC</span></span>
<span id="cb59-617"><a href="#cb59-617" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(achmat08, ses)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb59-618"><a href="#cb59-618" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-619"><a href="#cb59-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-620"><a href="#cb59-620" aria-hidden="true" tabindex="-1"></a><span class="fu">### Predicted values and residuals</span></span>
<span id="cb59-621"><a href="#cb59-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-622"><a href="#cb59-622" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lm`</span> function also returns the residuals $e_i$ and the predicted values $\widehat{Y_i}$, which we can access using the <span class="in">`$`</span> operator. These are useful for various reasons, especially model diagnostics which we discuss later in the course. For now, lets just take a look at the residual vs fitted plot to illustrate the code.</span>
<span id="cb59-623"><a href="#cb59-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-626"><a href="#cb59-626" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-627"><a href="#cb59-627" aria-hidden="true" tabindex="-1"></a>yhat <span class="ot">&lt;-</span> mod<span class="sc">$</span>fitted.values</span>
<span id="cb59-628"><a href="#cb59-628" aria-hidden="true" tabindex="-1"></a>res <span class="ot">&lt;-</span> mod<span class="sc">$</span>resid</span>
<span id="cb59-629"><a href="#cb59-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-630"><a href="#cb59-630" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(yhat, res, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb59-631"><a href="#cb59-631" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(yhat, res)</span>
<span id="cb59-632"><a href="#cb59-632" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-633"><a href="#cb59-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-634"><a href="#cb59-634" aria-hidden="true" tabindex="-1"></a>Note that the predicted values are uncorrelated with the residuals -- this is always the case in OLS.</span>
<span id="cb59-635"><a href="#cb59-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-636"><a href="#cb59-636" aria-hidden="true" tabindex="-1"></a><span class="fu">### Inference</span></span>
<span id="cb59-637"><a href="#cb59-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-638"><a href="#cb59-638" aria-hidden="true" tabindex="-1"></a>Next let's talk about statistical inference, or how we can make conclusions about a population based on a sample from that population.</span>
<span id="cb59-639"><a href="#cb59-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-640"><a href="#cb59-640" aria-hidden="true" tabindex="-1"></a>We can use the <span class="in">`summary`</span> function to test the coefficients in our model.</span>
<span id="cb59-641"><a href="#cb59-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-644"><a href="#cb59-644" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-645"><a href="#cb59-645" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb59-646"><a href="#cb59-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-647"><a href="#cb59-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-648"><a href="#cb59-648" aria-hidden="true" tabindex="-1"></a>In the table, the t-test and p-values are for the null hypothesis that the corresponding coefficient is zero in the population. We can see that the intercept and slope are both significantly different from zero at the .05 level. However, the test of the intercept is not very meaningful (why?).</span>
<span id="cb59-649"><a href="#cb59-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-650"><a href="#cb59-650" aria-hidden="true" tabindex="-1"></a>The text below the table summarizes the output for R-squared, including its F-test, it's degrees of freedom, and the p-value. (We will talk about adjusted R-square in Chapter 4)</span>
<span id="cb59-651"><a href="#cb59-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-652"><a href="#cb59-652" aria-hidden="true" tabindex="-1"></a>We can also use the <span class="in">`confint`</span> function to obtain confidence intervals for the regression coefficients. Use <span class="in">`help`</span> to find out more about the <span class="in">`confint`</span> function.</span>
<span id="cb59-653"><a href="#cb59-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-656"><a href="#cb59-656" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-657"><a href="#cb59-657" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span>
<span id="cb59-658"><a href="#cb59-658" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-659"><a href="#cb59-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-660"><a href="#cb59-660" aria-hidden="true" tabindex="-1"></a>Be sure to remember the correct interpretation of confidence intervals: *there is a 95% chance that the interval includes the true parameter value* (not: there is a 95% chance that the parameter falls in the interval). For example, there is a 95% chance that the interval <span class="co">[</span><span class="ot">.31, .54</span><span class="co">]</span> includes the true regression coefficient for SES.</span>
<span id="cb59-661"><a href="#cb59-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-662"><a href="#cb59-662" aria-hidden="true" tabindex="-1"></a><span class="fu">### Power analysis</span></span>
<span id="cb59-663"><a href="#cb59-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-664"><a href="#cb59-664" aria-hidden="true" tabindex="-1"></a>Power analyses should ideally be done before the data are collected. Since this class will work with secondary data analyses, most of our analyses will be retrospective. But don't let this mislead you about the importance of statistical power -- you should always do a power analysis before collecting data!!</span>
<span id="cb59-665"><a href="#cb59-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-666"><a href="#cb59-666" aria-hidden="true" tabindex="-1"></a>To do a power analsyis in R, we can install and load the <span class="in">`pwr`</span> package. If you haven't installed an R package before, it's pretty straight forward -- but just ask the instructor or a fellow student if you run into any issues.</span>
<span id="cb59-667"><a href="#cb59-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-668"><a href="#cb59-668" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval = F}</span></span>
<span id="cb59-669"><a href="#cb59-669" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package </span></span>
<span id="cb59-670"><a href="#cb59-670" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"pwr"</span>)</span>
<span id="cb59-671"><a href="#cb59-671" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-672"><a href="#cb59-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-675"><a href="#cb59-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-676"><a href="#cb59-676" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package by using the library command</span></span>
<span id="cb59-677"><a href="#cb59-677" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"pwr"</span>)</span>
<span id="cb59-678"><a href="#cb59-678" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-679"><a href="#cb59-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-682"><a href="#cb59-682" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-683"><a href="#cb59-683" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the help menu to see what the package does</span></span>
<span id="cb59-684"><a href="#cb59-684" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(<span class="st">"pwr-package"</span>)</span>
<span id="cb59-685"><a href="#cb59-685" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-686"><a href="#cb59-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-687"><a href="#cb59-687" aria-hidden="true" tabindex="-1"></a>To do a power analysis for linear regression, it is common to use Cohen's $f^2$ as the effect size:</span>
<span id="cb59-688"><a href="#cb59-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-689"><a href="#cb59-689" aria-hidden="true" tabindex="-1"></a>$$f^2 = \frac{R^2}{1-R^2}.$$</span>
<span id="cb59-690"><a href="#cb59-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-691"><a href="#cb59-691" aria-hidden="true" tabindex="-1"></a>Recall that $R^2$ is the proportion of variance in $Y$ explained by the model, and so $1 - R^2$ is the proportion of variance not explained by the model. Thus, $f^2$ can be interpreted as a signal to noise ratio.</span>
<span id="cb59-692"><a href="#cb59-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-693"><a href="#cb59-693" aria-hidden="true" tabindex="-1"></a>In addition to the effect size, we need to know the degrees of freedom for the F-test of R-square. The <span class="in">`pwr`</span> functions use the following notation:</span>
<span id="cb59-694"><a href="#cb59-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-695"><a href="#cb59-695" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`u`</span> is the degrees of freedom in the numerator of an F-test.</span>
<span id="cb59-696"><a href="#cb59-696" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`v`</span> is the degrees of freedom in the denominator of an F-test.</span>
<span id="cb59-697"><a href="#cb59-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-698"><a href="#cb59-698" aria-hidden="true" tabindex="-1"></a>In simple regression, <span class="in">`u = 1`</span> and <span class="in">`v = N - 2`</span>.</span>
<span id="cb59-699"><a href="#cb59-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-700"><a href="#cb59-700" aria-hidden="true" tabindex="-1"></a>As an example of (prospective) power analysis, let's find out many observations would be required to detect an effet size of R-square = .1, using $\alpha = .05$ and power = .8. To find the answer, enter the provided information into the <span class="in">`pwr.f2.test`</span> function, and the function will solve for the "missing piece" -- in this case $v = N - 2$.</span>
<span id="cb59-701"><a href="#cb59-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-704"><a href="#cb59-704" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb59-705"><a href="#cb59-705" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the provided values of R2, alpha, power (and u = 1) to solve for v = N - 2</span></span>
<span id="cb59-706"><a href="#cb59-706" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> .<span class="dv">1</span></span>
<span id="cb59-707"><a href="#cb59-707" aria-hidden="true" tabindex="-1"></a>f2 <span class="ot">&lt;-</span> R2<span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span>R2)</span>
<span id="cb59-708"><a href="#cb59-708" aria-hidden="true" tabindex="-1"></a><span class="fu">pwr.f2.test</span>(<span class="at">u =</span> <span class="dv">1</span>, <span class="at">f2 =</span> f2, <span class="at">sig.level =</span> .<span class="dv">05</span>, <span class="at">power =</span> .<span class="dv">8</span>)</span>
<span id="cb59-709"><a href="#cb59-709" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb59-710"><a href="#cb59-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-711"><a href="#cb59-711" aria-hidden="true" tabindex="-1"></a>In this example we find that $v = 70.6$. Since $v = N - 2$, so we know that a sample size of $N = 72.6$ (rounded up to 73) is required to reject the null hypothesis that $R^2 = 0$, when the true population value is $R^2 = .1$, with a power of .8 and using a significance level of .05.</span>
<span id="cb59-712"><a href="#cb59-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-713"><a href="#cb59-713" aria-hidden="true" tabindex="-1"></a><span class="fu">### Additional exercises</span></span>
<span id="cb59-714"><a href="#cb59-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-715"><a href="#cb59-715" aria-hidden="true" tabindex="-1"></a>If time permits, we will address these additional exercises in class.</span>
<span id="cb59-716"><a href="#cb59-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-717"><a href="#cb59-717" aria-hidden="true" tabindex="-1"></a>These exercises replace <span class="in">`achmat08`</span> with</span>
<span id="cb59-718"><a href="#cb59-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-719"><a href="#cb59-719" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span><span class="in">`achrdg08`</span>: eighth grade Reading Achievement (percent correct on a reading test)</span>
<span id="cb59-720"><a href="#cb59-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-721"><a href="#cb59-721" aria-hidden="true" tabindex="-1"></a>Please answer the following questions using R.</span>
<span id="cb59-722"><a href="#cb59-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-723"><a href="#cb59-723" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Plot <span class="in">`achrdg08`</span> against <span class="in">`ses`</span>. Is there any evidence of nonlinearity in the relationship?</span>
<span id="cb59-724"><a href="#cb59-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-725"><a href="#cb59-725" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>What is the correlation between <span class="in">`achrdg08`</span> and <span class="in">`ses`</span>? How does it compare to the correlation with Math and SES?</span>
<span id="cb59-726"><a href="#cb59-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-727"><a href="#cb59-727" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>How much variation in Reading is explained by SES? Is this more or less than for Math? Is the proportion of variance explained significant at the .05 level?</span>
<span id="cb59-728"><a href="#cb59-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-729"><a href="#cb59-729" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>How much do predicted Reading scores increase for a one unit of increase in SES? Is this a statistically significant at the .05 level?</span>
<span id="cb59-730"><a href="#cb59-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-731"><a href="#cb59-731" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>What are your overall conclusions about the relationship between Academic Achievement and SES in the NELS data?</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>
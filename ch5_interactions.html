<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EDUC 784 - 5&nbsp; Interactions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch6_model_building.html" rel="next">
<link href="./ch4_categorical_predictors.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch5_interactions.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Interactions</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">EDUC 784</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1_review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2_simple_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simple regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3_two_predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Two predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch4_categorical_predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Categorical predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch5_interactions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Interactions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch6_model_building.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model building</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch7_assumption_checking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assumption checking</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch8_loglinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Log-linear regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch9_polynomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Polynomial regression, etc</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-example-5" id="toc-sec-example-5" class="nav-link active" data-scroll-target="#sec-example-5"><span class="header-section-number">5.1</span> An example from NELS</a></li>
  <li><a href="#sec-binary-continuous-5" id="toc-sec-binary-continuous-5" class="nav-link" data-scroll-target="#sec-binary-continuous-5"><span class="header-section-number">5.2</span> Binary + continuous</a>
  <ul class="collapse">
  <li><a href="#marginal-means" id="toc-marginal-means" class="nav-link" data-scroll-target="#marginal-means"><span class="header-section-number">5.2.1</span> Marginal means</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">5.2.2</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-binary-continuous-interaction-5" id="toc-sec-binary-continuous-interaction-5" class="nav-link" data-scroll-target="#sec-binary-continuous-interaction-5"><span class="header-section-number">5.3</span> Binary + continuous + interaction</a>
  <ul class="collapse">
  <li><a href="#choosing-the-moderator" id="toc-choosing-the-moderator" class="nav-link" data-scroll-target="#choosing-the-moderator"><span class="header-section-number">5.3.1</span> Choosing the moderator</a></li>
  <li><a href="#back-to-the-example" id="toc-back-to-the-example" class="nav-link" data-scroll-target="#back-to-the-example"><span class="header-section-number">5.3.2</span> Back to the example</a></li>
  <li><a href="#centering-the-continuous-predictor" id="toc-centering-the-continuous-predictor" class="nav-link" data-scroll-target="#centering-the-continuous-predictor"><span class="header-section-number">5.3.3</span> Centering the continuous predictor</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1"><span class="header-section-number">5.3.4</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-inference-for-interactions-5" id="toc-sec-inference-for-interactions-5" class="nav-link" data-scroll-target="#sec-inference-for-interactions-5"><span class="header-section-number">5.4</span> Following-up an interaction</a>
  <ul class="collapse">
  <li><a href="#marginal-effects" id="toc-marginal-effects" class="nav-link" data-scroll-target="#marginal-effects"><span class="header-section-number">5.4.1</span> Marginal effects</a></li>
  <li><a href="#simple-trends" id="toc-simple-trends" class="nav-link" data-scroll-target="#simple-trends"><span class="header-section-number">5.4.2</span> Simple trends</a></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2"><span class="header-section-number">5.4.3</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-two-continuous-predictors-5" id="toc-sec-two-continuous-predictors-5" class="nav-link" data-scroll-target="#sec-two-continuous-predictors-5"><span class="header-section-number">5.5</span> Two continuous predictors</a>
  <ul class="collapse">
  <li><a href="#another-nels-example" id="toc-another-nels-example" class="nav-link" data-scroll-target="#another-nels-example"><span class="header-section-number">5.5.1</span> Another NELS example</a></li>
  <li><a href="#centering-the-predictors" id="toc-centering-the-predictors" class="nav-link" data-scroll-target="#centering-the-predictors"><span class="header-section-number">5.5.2</span> Centering the predictors</a></li>
  <li><a href="#simple-trends-1" id="toc-simple-trends-1" class="nav-link" data-scroll-target="#simple-trends-1"><span class="header-section-number">5.5.3</span> Simple trends</a></li>
  <li><a href="#summary-3" id="toc-summary-3" class="nav-link" data-scroll-target="#summary-3"><span class="header-section-number">5.5.4</span> Summary</a></li>
  <li><a href="#sec-how-centering-works-5" id="toc-sec-how-centering-works-5" class="nav-link" data-scroll-target="#sec-how-centering-works-5"><span class="header-section-number">5.5.5</span> Extra: How centering works*</a></li>
  </ul></li>
  <li><a href="#sec-two-categorical-predictors-5" id="toc-sec-two-categorical-predictors-5" class="nav-link" data-scroll-target="#sec-two-categorical-predictors-5"><span class="header-section-number">5.6</span> Two categorical predictors</a>
  <ul class="collapse">
  <li><a href="#an-example-from-ecls" id="toc-an-example-from-ecls" class="nav-link" data-scroll-target="#an-example-from-ecls"><span class="header-section-number">5.6.1</span> An example from ECLS</a></li>
  <li><a href="#the-no-interaction-model" id="toc-the-no-interaction-model" class="nav-link" data-scroll-target="#the-no-interaction-model"><span class="header-section-number">5.6.2</span> The “no-interaction” model</a></li>
  <li><a href="#adding-the-interactions" id="toc-adding-the-interactions" class="nav-link" data-scroll-target="#adding-the-interactions"><span class="header-section-number">5.6.3</span> Adding the interaction(s)</a></li>
  <li><a href="#back-to-the-example-1" id="toc-back-to-the-example-1" class="nav-link" data-scroll-target="#back-to-the-example-1"><span class="header-section-number">5.6.4</span> Back to the example</a></li>
  <li><a href="#the-anova-approach" id="toc-the-anova-approach" class="nav-link" data-scroll-target="#the-anova-approach"><span class="header-section-number">5.6.5</span> The ANOVA approach</a></li>
  </ul></li>
  <li><a href="#workbook" id="toc-workbook" class="nav-link" data-scroll-target="#workbook"><span class="header-section-number">5.7</span> Workbook</a></li>
  <li><a href="#sec-exercises-5" id="toc-sec-exercises-5" class="nav-link" data-scroll-target="#sec-exercises-5"><span class="header-section-number">5.8</span> Exercises</a>
  <ul class="collapse">
  <li><a href="#binary-continuous-interaction" id="toc-binary-continuous-interaction" class="nav-link" data-scroll-target="#binary-continuous-interaction"><span class="header-section-number">5.8.1</span> Binary + continuous + interaction</a></li>
  <li><a href="#centering-continuous-predictors" id="toc-centering-continuous-predictors" class="nav-link" data-scroll-target="#centering-continuous-predictors"><span class="header-section-number">5.8.2</span> Centering continuous predictors</a></li>
  <li><a href="#breaking-down-a-significant-interaction" id="toc-breaking-down-a-significant-interaction" class="nav-link" data-scroll-target="#breaking-down-a-significant-interaction"><span class="header-section-number">5.8.3</span> Breaking down a significant interaction</a></li>
  <li><a href="#marginal-effects-1" id="toc-marginal-effects-1" class="nav-link" data-scroll-target="#marginal-effects-1"><span class="header-section-number">5.8.4</span> Marginal effects</a></li>
  <li><a href="#simple-trends-2" id="toc-simple-trends-2" class="nav-link" data-scroll-target="#simple-trends-2"><span class="header-section-number">5.8.5</span> Simple trends</a></li>
  <li><a href="#two-continuous-predictors" id="toc-two-continuous-predictors" class="nav-link" data-scroll-target="#two-continuous-predictors"><span class="header-section-number">5.8.6</span> Two continuous predictors</a></li>
  <li><a href="#two-categorical-predictors" id="toc-two-categorical-predictors" class="nav-link" data-scroll-target="#two-categorical-predictors"><span class="header-section-number">5.8.7</span> Two categorical predictors</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-chap-5" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Interactions</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In statistics, the term <em>interaction</em> means that the relationship between two variables depends on a third variable. In the context of regression, we are usually interested in the situation where the relationship between the outcome <span class="math inline">\(Y\)</span> and a predictor <span class="math inline">\(X_1\)</span> depends on another predictor <span class="math inline">\(X_2\)</span>. This situation is also referred to as <em>moderation</em> or sometimes as <em>effect heterogeneity</em>.</p>
<p>Interactions are a big-picture idea with a lot conceptual power, especially when describing topics related to social inequality or “gaps”. Some examples of interactions are:</p>
<ul>
<li><p>The relationship between wages and years of education depends on gender. This has been called the gender pay gap and it is considered a pretty important issue for gender equality (e.g., <a href="https://en.wikipedia.org/wiki/Gender_pay_gap">https://en.wikipedia.org/wiki/Gender_pay_gap</a>).</p></li>
<li><p>The relationship between reading achievement and age depends on race. This has been interpreted in terms of racial inequality in educational outcomes (e.g., <a href="https://cepa.stanford.edu/educational-opportunity-monitoring-project/achievement-gaps/race/">https://cepa.stanford.edu/educational-opportunity-monitoring-project/achievement-gaps/race/</a>).</p></li>
<li><p>The effect of COVID-19 school shutdowns on academic achievement depended on SES. This has been interpreted in terms of social inequality in access to educational resources outside of schools (e.g., <a href="https://www.mckinsey.com/industries/education/our-insights/covid-19-and-student-learning-in-the-united-states-the-hurt-could-last-a-lifetime">https://www.mckinsey.com/industries/education/our-insights/covid-19-and-student-learning-in-the-united-states-the-hurt-could-last-a-lifetime</a>).</p></li>
</ul>
<p>I hope these examples convince you that some of the big issues facing education and society at large are actually about interactions – how the relationship between two variables depends on a third variable. In this chapter we are going to talk about how you can use regression to conduct research on these types of topics.</p>
<p>Some terminology: When we talk about statistical interactions, we often leave the outcome variable implicit and focus on the predictors. For example, the gender pay gap can be described as an interaction between gender and years of education. The outcome variable (wages) is implicit in this description. Throughout this chapter we are exclusively interested in interactions between two predictors at a time, which are called <em>two-way interactions</em>. There are actually three variables involved, because a two-way interaction also requires an outcome variable. It is possible to consider “higher-order” interactions (e.g., interactions among three predictors or <em>three-way interactions</em>) but we aren’t going to do that here. Sometimes we will use the terminology <em>main effect</em> to describe the relationship between each individual predictor and the outcome variable, as distinct from the interactions among the predictors. Up to now, we have be working with main effects only.</p>
<p>We start by considering what happens when both categorical and continuous predictors are used together in a multiple regression model. We use this combination of predictors as bridge from the previous chapter and as a way of digging into the math behind interactions. Later sections will consider what happens when we have interactions between two continuous predictors, or two categorical predictors.</p>
<p>It might be helpful to mention that this chapter gets pretty complicated and is very long (sorry!). It is definitely the hardest material we have covered so far, because we are drawing on everything we have done up to now and adding even more stuff into the mix. So, if these readings feel daunting at moments, that is to be expected. You might consider taking a break and doing the readings in smaller chunks. Also keep in mind that we are going to discuss all of this in class together, so just get what you can from these notes, provide some initial responses to the Workbook questions, and press on. This is where regression starts to get really interesting – you got this!</p>
<section id="sec-example-5" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-example-5"><span class="header-section-number">5.1</span> An example from NELS</h2>
<p>For the first few sections of this chapter, we will focus on the gender gap in Math Achievement as our example (e.g., <a href="https://www.nctm.org/Publications/TCM-blog/Blog/Current-Research-on-Gender-Differences-in-Math/">https://www.nctm.org/Publications/TCM-blog/Blog/Current-Research-on-Gender-Differences-in-Math/</a>). The t-test reported below uses the NELS data to illustrate the gender gap in Math Achievement in 12th grade. The output shows that, on average, males scored about 3.18 percentage points higher than females on a Grade 12 Math test. This gap isn’t very big. However, it tends to grow rather than get smaller as students progress to higher grades, and it has implications for gender equality in STEM education and STEM professions.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"NELS.RData"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(NELS)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(achmat12 <span class="sc">~</span> gender, <span class="at">var.equal =</span> T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  achmat12 by gender
t = -4.5529, df = 498, p-value = 6.658e-06
alternative hypothesis: true difference in means between group Female and group Male is not equal to 0
95 percent confidence interval:
 -4.527002 -1.797687
sample estimates:
mean in group Female   mean in group Male 
            55.47092             58.63326 </code></pre>
</div>
</div>
<p>In this chapter, our goal is to use linear regression to better understand the gender gap in Math Achievement. To help us do this, we will also consider a third variable, Reading Achievement. The plot below shows the relationship between Math Achievement and Reading Achievement estimated just for males (Blue), and the same relationship estimated just for females (Black).</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create indicators for females and males</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>females <span class="ot">&lt;-</span> gender <span class="sc">==</span> <span class="st">"Female"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>males <span class="ot">&lt;-</span> gender <span class="sc">==</span> <span class="st">"Male"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Regress math on reading, for each group separately</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[females] <span class="sc">~</span> achrdg12[females])</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[males] <span class="sc">~</span> achrdg12[males])</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod1, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Add again for males</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-math-reading-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-math-reading-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.1: Math Achievement, Reading Achievement, and Gender.</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Please take a minute to think about what this plot is telling us about the relationships among the three variables. In particular: </strong></p>
<ul>
<li><strong>Does the gender gap in Math Achievement change as a function of Reading Achievement?</strong><br>
</li>
<li><strong>Is the relationship between Math Achievement and Reading Achievement the the same for males and females?</strong></li>
<li><strong>What do the results mean for gender equality in Math and STEM education?</strong></li>
</ul>
<p>Note that in <a href="#fig-math-reading-1">Figure&nbsp;<span>5.1</span></a>, we estimated two separate simple regression models, one just for males and one just for females. In the next few sections, we will work our way towards a single multiple regression model that can be used to represent the relationships among these three variables.</p>
</section>
<section id="sec-binary-continuous-5" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-binary-continuous-5"><span class="header-section-number">5.2</span> Binary + continuous</h2>
<p>Let’s start by considering what happens when we include both Gender and Reading Achievement as predictors of Math Achievement in our usual multiple regression equation:</p>
<p><span id="eq-yhat-5a"><span class="math display">\[\widehat Y = b_0 + b_1X_1 + b_2 X_2 \tag{5.1}\]</span></span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(Y\)</span> is Math Achievement in grade 12</li>
<li><span class="math inline">\(X_1\)</span> is Reading Achievement in grade 12</li>
<li><span class="math inline">\(X_2\)</span> is Gender (binary, with female = 0 and male = 1)</li>
</ul>
<p>Note that this model does <strong>not</strong> include an interaction between the two predictors – we are first going to consider what is “missing” from the usual regression model, and then use this to motivate inclusion of another predictor that represents the interaction. To get an initial sense of what is missing, the model in <a href="#eq-yhat-5a">Equation&nbsp;<span>5.1</span></a> is plotted in <a href="#fig-math-reading-2">Figure&nbsp;<span>5.2</span></a> using the NELS data – can you spot the difference with <a href="#fig-math-reading-1">Figure&nbsp;<span>5.1</span></a>?</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender, <span class="at">data =</span> NELS)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>a_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod3)[<span class="dv">1</span>]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>b_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod3)[<span class="dv">2</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the slope and intercept for males</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>a_males <span class="ot">&lt;-</span> a_females <span class="sc">+</span> <span class="fu">coef</span>(mod3)[<span class="dv">3</span>]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>b_males <span class="ot">&lt;-</span> b_females </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_females, b_females, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_males, b_males, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-math-reading-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-math-reading-2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.2: Math Achievement, Reading Achievement, and Gender (No Interaction).</figcaption>
</figure>
</div>
</div>
</div>
<p>In order to interpret our multiple regression model, we can use the same overall approach as we used to interpret categorical predictors in <a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>. If we plug-in values for the categorical predictor, we get:</p>
<p><span id="eq-females1-5"><span class="math display">\[
\begin{align}
\text{Simple trend for females:   } \widehat Y (Female) &amp; = b_0 + b_1X_1 + b_2 (0) \\ &amp; = b_0 + b_1X_1
\end{align}
\tag{5.2}\]</span></span></p>
<p><span id="eq-males1-5"><span class="math display">\[
\begin{align}
\text{Simple trend for males:   } \widehat Y (Male) &amp; = b_0 + b_1X_1 + b_2 (1) \\ &amp; = (b_0 + b_2) + b_1 X_1
\end{align}
\tag{5.3}\]</span></span></p>
<p><span id="eq-gap1-5"><span class="math display">\[
\begin{align}
\text{Predicted gender gap:   } \widehat Y (Male) - \widehat Y (Female) &amp; = b_2
\end{align}
\tag{5.4}\]</span></span></p>
<p>The equations for <span class="math inline">\(\widehat Y (Female)\)</span> and <span class="math inline">\(\widehat Y (Male)\)</span> are referred to as <em>simple trends</em> or <em>simple slopes</em>. These describe the regression of Math on Reading, simply for females, or simply for males. The difference between the two simple regression equations is the predicted gender gap in Math Achievement.</p>
<p>Based on these equations we can interpret regression coefficients as follows</p>
<ul>
<li><p>The regression intercept, <span class="math inline">\(b_0\)</span>, is the intercept of the simple trend for the group coded “0” (i.e., the intercept of the regression of Math on Reading, simply for females; see <a href="#eq-females1-5">Equation&nbsp;<span>5.2</span></a>).</p></li>
<li><p>The regression slope for the continuous predictor, <span class="math inline">\(b_1\)</span>, is the slope of both of the simple trends (see <a href="#eq-females1-5">Equation&nbsp;<span>5.2</span></a> and <a href="#eq-males1-5">Equation&nbsp;<span>5.3</span></a>)</p></li>
<li><p>The regression slope for the binary predictor, <span class="math inline">\(b_2\)</span>, is the difference between the intercepts of the simple trends (i.e., we add <span class="math inline">\(b_2\)</span> to <span class="math inline">\(b_0\)</span> to get the intercept of the regression of Math on Reading, simply for males; see <a href="#eq-males1-5">Equation&nbsp;<span>5.3</span></a>).</p></li>
<li><p>In this model, <span class="math inline">\(b_2\)</span> is the also the predicted gender gap in Math Achievement (see <a href="#eq-gap1-5">Equation&nbsp;<span>5.4</span></a>).</p></li>
</ul>
<p>The regression coefficients for the example data are shown below. <strong>Please use these numbers to provide an interpretation of the simple trends and the gender gap in Math Achievement for the NELS example. (Don’t worry about statistical significance, just focus on the meaning of the coefficients reported in the “Estimate” column.)</strong></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender, data = NELS)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.2448  -3.6075   0.3968   3.9836  15.5606 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 19.98122    1.86278  10.727  &lt; 2e-16 ***
achrdg12     0.63551    0.03275  19.404  &lt; 2e-16 ***
genderMale   3.50166    0.52473   6.673 6.69e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.839 on 497 degrees of freedom
Multiple R-squared:  0.4538,    Adjusted R-squared:  0.4516 
F-statistic: 206.4 on 2 and 497 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Here is an example to help you get started:</p>
<ul>
<li><p>Simply for females, the regression of Math Achievement on Reading Achievement has an intercept equal to 19.98 and a slope equal to 0.64. The intercept tells us that a female student with Reading Achievement score of 0% is expected to have a Math Achievement score of 19.98% (the units of the two tests are percent correct). Since the lowest value of Reading Achievement in our example is about 35%, the intercept is not very meaningful for these data. The regression slope tells us that, for females, a 1 unit increase in Reading Achievement is associated with a .64 unit increase in Math Achievement.</p></li>
<li><p>Simply for males, ….</p></li>
<li><p>The gender gap in Math Achievement was equal to …</p></li>
</ul>
<section id="marginal-means" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="marginal-means"><span class="header-section-number">5.2.1</span> Marginal means</h3>
<p>Before moving on to consider interactions, let’s revisit a topic from the previous chapter. In <a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>, we noted that the regression coefficients for categorical predictors (dummy variables) can be interpreted in terms of the group means of the outcome variable. However, when additional predictors are included in the regression model, this interpretation no longer holds. This section explains why.</p>
<p>To see what the issue is, let’s compare the output of the t-test in <a href="#sec-example-5"><span>Section&nbsp;5.1</span></a> with the regression output shown above. In the t-test, the mean Math Achievement for females was 55.47, and for males it was 58.63. The mean difference was</p>
<p><span class="math display">\[58.63 - 55.47 = 3.16\]</span></p>
<p>However, the regression coefficient on Gender in the multiple regression model above is equal to <span class="math inline">\(3.50\)</span>. Thus, unlike <a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>, the regression coefficient on Gender is no longer equal to the group-mean difference in Math Achievement. But why?</p>
<p>Remember that in the multiple regression model, the regression coefficient on Gender is interpreted as the relationship between Math Achievement and Gender, <em>holding Reading Achievement constant</em>. So, the regression coefficient on Gender is still interpreted as a mean difference, but now it is a <em>predicted</em> mean difference that represents the gender gap in Math Achievement after controlling for Reading Achievement. The t-test doesn’t control for Reading.</p>
<p>In order to emphasize the distinction between “raw” group means computed from the data and the predicted group means obtained from a multiple regression model, the latter are referred to as <em>marginal means</em>, or sometimes as <em>adjusted means</em> or <em>least squares means</em>. I think they should be called <em>predicted means</em>, but, alas.</p>
</section>
<section id="summary" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="summary"><span class="header-section-number">5.2.2</span> Summary</h3>
<p>In a regression model with one continuous predictor and one binary predictor (and no interaction):</p>
<ul>
<li><p>The model results in two regression lines, one for each value of the binary predictor. These are called the simple trends.</p></li>
<li><p>The simple trends are parallel but can have different intercepts; the difference between the intercepts is equal to regression coefficient of the binary variable.</p></li>
<li><p>The difference between the simple trends is often called a “gap”, and the gap is also equal to the regression coefficient of the binary variable.</p></li>
<li><p>It is important to note that the predicted group means for the binary variable are no longer equal to the “raw” group means computed directly from the data, because the predicted group means control for the correlation between the predictors. The predicted group means are called marginal means to emphasize this distinction.</p></li>
</ul>
<p>Keep in mind that this summary applies to the multiple regression model <strong>without an interaction</strong>. In the next section we improve our model by adding an interaction.</p>
</section>
</section>
<section id="sec-binary-continuous-interaction-5" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="sec-binary-continuous-interaction-5"><span class="header-section-number">5.3</span> Binary + continuous + interaction</h2>
<p>In this section, we discuss what was missing from the multiple regression model in the previous section: The interaction between Gender and Reading.</p>
<p>Mathematically, an interaction is just the product between two variables. <a href="#eq-yhat-5b">Equation&nbsp;<span>5.5</span></a> shows how to include this product in our multiple regression model – we just take the product of the two predictors and add it into the model as a third predictor:</p>
<p><span id="eq-yhat-5b"><span class="math display">\[\hat Y = b_0 + b_1X_1 + b_2 X_2 + b_3 (X_1 \times X_2).  \tag{5.5}\]</span></span></p>
<p>In terms of computation, we would literally take the product of our two predictors and save it as a new variable in our data set, then add the new variable in to the regression model. In practice, R will do all of this for us behind the scenes, so we don’t actually need to “hard code” new variables.</p>
<p>For the NELS example, the regression model with the interaction is depicted in <a href="#fig-math-reading-3">Figure&nbsp;<span>5.3</span></a>. Note the the simple trends are no longer parallel and the regression lines agree exactly with what we had in <a href="#sec-example-5"><span>Section&nbsp;5.1</span></a>. So, as promised, we have now arrived at a single multiple regression model that captures the relationships among Math Achievement, Reading Achievement, and Gender.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via hard coding</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>genderXachrdg12 <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXachrdg12)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for females</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>a_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod4)[<span class="dv">1</span>]</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>b_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod4)[<span class="dv">2</span>]</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for males</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>a_males <span class="ot">&lt;-</span> a_females <span class="sc">+</span> <span class="fu">coef</span>(mod4)[<span class="dv">3</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>b_males <span class="ot">&lt;-</span> b_females <span class="sc">+</span> <span class="fu">coef</span>(mod4)[<span class="dv">4</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_females, b_females, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>       achmat12[males],</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_males, b_males, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>,</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-math-reading-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-math-reading-3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.3: Math Achievement, Reading Achievement, and Gender (No Interaction).</figcaption>
</figure>
</div>
</div>
</div>
<p>To see how to interpret the coefficients in this model, let’s work through the model equations using our two-step procedure. As before, we first plug-in values for the categorical predictor, then we use the resulting equations solve for the simple trends and the gender gap in Math.</p>
<p><span id="eq-females2-5"><span class="math display">\[\begin{align}
\widehat Y (Female) &amp; = b_0 + b_1X_1 + b_2 (0) + b_3(X_1 \times 0) \\ &amp; = b_0 + b_1X_1
\end{align} \tag{5.6}\]</span></span></p>
<p><span id="eq-males2-5"><span class="math display">\[\begin{align}
\widehat Y (Male) &amp; = b_0 + b_1X_1 + b_2 (1) +  b_3(X_1 \times 1)\\ &amp; = (b_0 + b_2) + (b_1 + b_3) X_1 \end{align} \tag{5.7}\]</span></span></p>
<p><span id="eq-gap2-5"><span class="math display">\[\begin{align}
\widehat Y (Male) - \widehat Y (Female) &amp; = b_2 + b_3 X_1
\end{align} \tag{5.8}\]</span></span></p>
<p>These equations are summarized graphically below in <a href="#fig-interactions">Figure&nbsp;<span>5.4</span></a>.</p>
<div id="fig-interactions" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="files/images/Interaction.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;5.4: Interaction between a categorical and a continuous predictor. Image credit: Daniela Rodriguez-Mincey, Spring 2023</figcaption>
</figure>
</div>
<p>Based on the equations and figure, we can interpret regression coefficients as follows. Some of these interpretations are the same as in the previous section, but some are different.</p>
<ul>
<li><p>The regression intercept, <span class="math inline">\(b_0\)</span>, is the intercept of the simple trend for the group coded “0” (i.e., the intercept of the regression of Math on Reading, simply for females; see <a href="#eq-females2-5">Equation&nbsp;<span>5.6</span></a>). This is the <strong>same</strong> interpretation as for the model without the interaction discussed in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a>.</p></li>
<li><p>The regression slope for the continuous predictor, <span class="math inline">\(b_1\)</span>, is the slope of the simple trend for the group coded “0” (females; see <a href="#eq-females2-5">Equation&nbsp;<span>5.6</span></a>). This is <strong>different</strong> from the interpretation of the model in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a> – in that model, <span class="math inline">\(b_1\)</span> was the slope of both simple trends, not just the trend for females.</p></li>
<li><p>The regression slope for the binary predictor, <span class="math inline">\(b_2\)</span>, is the difference between the intercepts of the simple trends (i.e., we add <span class="math inline">\(b_2\)</span> to <span class="math inline">\(b_0\)</span> to get the intercept of the regression of Math on Reading, simply for males; see <a href="#eq-males2-5">Equation&nbsp;<span>5.7</span></a>). This is the <strong>same</strong> interpretation as for the model without the interaction discussed in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a>.</p></li>
<li><p>The regression slope for the interaction term (or simply, the interaction), <span class="math inline">\(b_3\)</span>, is the difference between the slopes of the simple trends (i.e., we add <span class="math inline">\(b_3\)</span> to <span class="math inline">\(b_1\)</span> to get the slope of the regression of Math on Reading, simply for males; see <a href="#eq-males2-5">Equation&nbsp;<span>5.7</span></a>). This is <strong>different</strong> from the interpretation of the model in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a> – in that model, <span class="math inline">\(b_1\)</span> was the slope of both simple trends.</p></li>
<li><p>The difference between the predicted values (i.e., the predicted gender gap in Math Achievement) is no longer constant, but is instead a function of <span class="math inline">\(X_1\)</span> (see <a href="#eq-gap2-5">Equation&nbsp;<span>5.8</span></a>). In particular, the predicted gender gap in Math changes by <span class="math inline">\(b_3\)</span> units for each unit of increase in Reading. This is <strong>different</strong> from the interpretation of the model in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a> – in that model, the predicted gender gap was constant over Reading and equal to <span class="math inline">\(b_2\)</span>.</p></li>
</ul>
<p>This last point is especially important in the context of our example. The gender gap in Math Achievement is a function of Reading Achievement. This is the mathematical meaning behind the concept of an interaction – the relationship between two variables (Math and Gender) is changing as a function of a third variable (Reading).</p>
<section id="choosing-the-moderator" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="choosing-the-moderator"><span class="header-section-number">5.3.1</span> Choosing the moderator</h3>
<p>Interpreting interactions can feel a bit unwieldy at first. This section introduces some additional terminology that helps better align the mathematical results with the kinds of research scenarios we considered in the introduction to this chapter.</p>
<p>First, note that it is equally valid to say</p>
<ul>
<li>the relationship between Math and Gender depends on Reading, or</li>
<li>the relationship between Math and Reading depends on Gender.</li>
</ul>
<p>In other words, it is equally valid to interpret our interaction in terms of the gender gap (i.e., the relationship between Math and Gender) or in terms of the simple trends (the relationship between Math and Reading).</p>
<p>Although both interpretations are equally valid, in most research settings we will be more interested in one of them rather than the other. For example, our research interest in <a href="#sec-example-5"><span>Section&nbsp;5.1</span></a> was about the gender gap in Math Achievement. So, we can simplify our lives by focusing the gender gap (i.e., the relationship between Math and Gender). For the purpose of our example, the simple trends are an equivalent but less interesting way of interpreting the interaction. The point is: we don’t have to report both the simple trends and the gender gap – we usually just choose one.</p>
<p>In the two bullet points above, whichever variable appears in the “depends on” clause is called the <em>moderator</em>, and the other two variables are called the focal variables. The researcher chooses which variable to treat as the moderator when interpreting an interaction. The overall idea here is to “break down” the interaction in the way that is most compatible with your research question(s).</p>
<p>Since our focus is the gender gap in Math (i.e., the relationship is between Math and Gender), Reading is our moderator. In particular, we might interpret the interaction as follows</p>
<ul>
<li>The predicted gender gap in Math changes by <span class="math inline">\(b_3\)</span> units for each unit of increase in Reading.</li>
</ul>
<p>By contrast, if we were mainly interested in the relationship between Math and Reading (i.e., the simple trends), then we could treat Gender as the moderator. For example, we might say:</p>
<ul>
<li>For females, predicted Math Achievement changed by <span class="math inline">\(b_1\)</span> units for each unit of increase in Reading, whereas for males, the predicted change was (<span class="math inline">\(b_1 + b_3\)</span>) units for each unit of increase in Reading.</li>
</ul>
<p>The simple trends might feel less intuitive than the gender gap, but the two interpretations are mathematically equivalent. It is just a matter of whether you want to interpret the interaction with reference to the gender gap, or with reference to the simple trends. When writing up your research, you don’t need to do both. But I am going to make you do both in the next section for practice.</p>
</section>
<section id="back-to-the-example" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="back-to-the-example"><span class="header-section-number">5.3.2</span> Back to the example</h3>
<p>The regression coefficients for the example data are shown below. <strong>Please use these numbers to provide an interpretation of the interaction between Gender and Reading. For practice, please attempt the interpret the interaction in terms of (a) the gender gap in Math, with Reading as the moderator; and (b) the relationship between Math and Reading, with Gender as the moderator. Don’t worry about statistical significance, just focus on the interpreting the coefficients reported in the “Estimate” column.</strong></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + genderXachrdg12)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     14.80310    2.64922   5.588  3.8e-08 ***
achrdg12         0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale      13.39328    3.65828   3.661 0.000278 ***
genderXachrdg12 -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Some potential answers are hidden in the “Code” tab below, but don’t peak until you have tried it for yourself!</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gender gap</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># General: The gender gap in Math is smaller for students who are also strong in Reading</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Specific: The gender gap in Math Achievement decreases by .18 percentage points for each percentage point increase Reading Achievement</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple slopes</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># General: The relationship between Math and Reading is stronger (i.e. has a larger slope) for females than for males</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Specific:</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  For females, Math scores are predicted to increase by .72 percentage points for each percentage point increase in Reading Achievement</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  For males, Math scores are predicted to increase by .55 percentage points for each percentage point increase in Reading Achievement</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="centering-the-continuous-predictor" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="centering-the-continuous-predictor"><span class="header-section-number">5.3.3</span> Centering the continuous predictor</h3>
<p>You may have noticed that the regression coefficient on Gender was wildly different in regression models with and without the interaction. In the model without the interaction (<a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a>) the coefficient on Gender was 3.50, and in the model with the interaction (above), it was 13.40. So in one model, the “effect” of being male was a 3.5 percentage point gain on a Math test, but in the other model, it was a 13.40 percentage point gain. Why this huge difference in the “effect” of Gender?</p>
<p>The answer can be seen in the equation for the gender gap. In the model <strong>without the interaction</strong>, the gender gap was constant and equal to the regression coefficient on Gender (denoted as <span class="math inline">\(b_2\)</span> in the model):</p>
<p><span class="math display">\[\widehat Y (Male) - \widehat Y (Female) = b_2. \]</span></p>
<p>But in the regression model <strong>with the interaction</strong>, the gender gap was a linear function of Reading and the regression coefficient on Gender is the intercept of that linear relationship.</p>
<p><span class="math display">\[ \widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 X_1. \]</span></p>
<p>This equation tell us that, in the model with the interaction, <span class="math inline">\(b_2\)</span> is the gender gap for students who score 0% on the Reading test. Since the lowest score on Reading was around 35%, the intercept in this equation (i.e., <span class="math inline">\(b_2\)</span>, the regression coefficient on Gender) is not very meaningful.</p>
<p>In previous sections, we have ignored the regression intercept when it was not meaningful. But, ignoring the regression slopes for predictor variables can get confusing, and, in general, it is nice for the regression coefficients to be interpretable (otherwise, why are we doing this!).</p>
<p>One way to address this situation is to center Reading Achievement so that it has a mean of zero. To do this, we compute the deviation score</p>
<p><span class="math display">\[D_1 = X_1 - \bar X_1.\]</span></p>
<p><span class="math inline">\(D_1\)</span> is the mean-centered version of <span class="math inline">\(X_1\)</span> (Reading Achievement). If we regress Math Achievement on <span class="math inline">\(D_1\)</span> rather than <span class="math inline">\(X_1\)</span> we end up with the following equation for the gender gap in Math:</p>
<p><span class="math display">\[\widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 D_1\]</span></p>
<p>Since <span class="math inline">\(D_1 = 0\)</span> when <span class="math inline">\(X_1 = \bar X_1\)</span>, the regression coefficient on Gender (<span class="math inline">\(b_2\)</span>) is now interpretable as the gender gap in Math Achievement, for students with average Reading Achievement. This is a much more interpretable number than the coefficient in the original interaction model!</p>
<p>Using the example data, this approach yields the following regression coefficients (the <code>_dev</code> notation means the variable was centered):</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the deviation scores for reading</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>reading_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12, <span class="at">na.rm =</span> T) </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the interaction model as above</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>genderXreading_dev <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> reading_dev</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> reading_dev <span class="sc">+</span> gender <span class="sc">+</span> genderXreading_dev)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ reading_dev + gender + genderXreading_dev)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        55.29439    0.35127 157.411  &lt; 2e-16 ***
reading_dev         0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale          3.49930    0.52135   6.712 5.26e-11 ***
genderXreading_dev -0.17794    0.06514  -2.732  0.00652 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The regression coefficient for Gender is now pretty close to what it was in the multiple regression model without the interaction, but the interpretation is different (i.e., it is now the predicted gender gap in Math for students with an average level of Reading, rather than the predicted gender gap in Math for all students).</p>
<p>Notice that the intercept in the model above has also changed compared to the previous model in which Reading was not centered. This is should make sense based on what you already know about the regression intercept.</p>
<p>Also note that centering Reading did not affect the regression coefficient for Reading or the interaction. So, centering makes the regression slope on Gender more interpretable, but it doesn’t affect our overall interpretation of the simple trends or the gender gap. To learn more about how centering works, see <a href="#sec-how-centering-works-5"><span>Section&nbsp;5.5.5</span></a> (which is optional).</p>
<p><strong>Please write down your interpretation of the intercept and the regression coefficient on Gender in the above regression output, and be prepared to share your answer in class</strong>.</p>
</section>
<section id="summary-1" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="summary-1"><span class="header-section-number">5.3.4</span> Summary</h3>
<p>The interaction between two variables is just their product. When this product is added as a predictor in a multiple regression model with one continuous and one binary predictor:</p>
<ul>
<li><p>The model again results in two regression lines (simple trends), one for each value of the binary predictor.</p></li>
<li><p>However, the simple trends can now have different intercepts <em>and different slopes</em>. The difference in slopes is equal to the regression coefficient on the interaction term. In other words, the simple trends have different slopes because of the interaction.</p></li>
<li><p>The difference (“gap”) between the regression lines changes as a linear function of the continuous predictor, and the slope of this linear function is again equal to the regression coefficient on the interaction term.</p></li>
<li><p>The last two points are equivalent ways of stating the central idea behind a (two-way) interaction: the relationship between two variables changes as a function of a third variable.</p></li>
<li><p>When interpreting an interaction, the researcher chooses which pair of variables will be the “focal relationship” and which variable will be the moderator.</p>
<ul>
<li>In our example, we focused on the gender gap in Math (i.e., the relationship between Math and Gender) and Reading was the moderator.</li>
<li>But, if we were more interested in the relationship between Math and Reading, would could have focused on the simple trends and treated Gender as the moderator.</li>
<li>It is usual to only report one way of these two ways of “breaking down” the interaction – the one that is most relevant to your research question.</li>
</ul></li>
<li><p>Centering the continuous predictor can be helpful for ensuring that the regression coefficient on the binary predictor remains interpretable in the presence of an interaction.</p></li>
</ul>
</section>
</section>
<section id="sec-inference-for-interactions-5" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="sec-inference-for-interactions-5"><span class="header-section-number">5.4</span> Following-up an interaction</h2>
<p>The procedures discussed in this section are used typically used <em>after</em> we have concluded that there is a statistically significant between two predictors (i.e., after we have examined the <code>summary(lm)</code> output in the previous section). When we follow-up an interaction, the goal is to gain a better understanding of <em>how</em> the focal relationship depends on the moderator. Basically, the <code>summary(lm)</code> output from the previous section tells us whether or not the interaction is significant, and, if it is significant, the procedures discussed in this section let us describe the interaction in more detail.</p>
<p>The overall idea is illustrated <a href="#fig-visreg-1">Figure&nbsp;<span>5.5</span></a>. Compared to the plots we have seen previously in this chapter, <a href="#fig-visreg-1">Figure&nbsp;<span>5.5</span></a> now includes confidence bands for the simple trends. The confidence bands show the values of Reading for which the gender gap in Math is statistically significant. In particular, it appears that the gap is not significant for students at the highest levels of Reading Achievement.</p>
<p>Note that this information was not available from the <code>summary(lm)</code> output in the previous section. The <code>summary(lm)</code> output told us that the interaction term was statistically significant, which means that the gender gap in Math changes as a function of reading. The plot provides more information about <em>how</em> the gender gap depends on Reading – it is statistical significant for students at lower levels of Reading Achievement, but appears to shrink and eventually disappear as Reading Achievement increases.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package if you haven't already done so</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("visreg")</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visreg)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression model using R's syntax for interactions "*"</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> gender<span class="sc">*</span>achrdg12, <span class="at">data=</span> NELS)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># One line of code to plot trends with confidence bands :) </span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod6, <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, <span class="at">by =</span> <span class="st">"gender"</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-visreg-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-visreg-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.5: Example of a plot using the <code>visreg</code> package.</figcaption>
</figure>
</div>
</div>
</div>
<p>In this section, we discuss how to translate the confidence bands in the plot into statistical tests that can provide more specific information about the how the gender gap in Math depends on Reading. Making these kinds of inferences about interactions is one of the main advantages of using multiple regression rather than just fitting the simple trends separately as we did in <a href="#sec-example-5"><span>Section&nbsp;5.1</span></a>. Another advantage is that we can now easily produce nice plots like <a href="#fig-visreg-1">Figure&nbsp;<span>5.5</span></a> :)</p>
<p>Before moving on, it is important to emphasize that, if the interaction term in the <code>summary(lm)</code> output is <strong>not</strong> significant, we don’t use the procedures discussed in this section. This is because a non-significant interaction means that we have inferred the focal relationship <em>does not</em> depend on the moderator. Consequently, there is no need to describe this dependence in more detail, which is what the procedures in this section are for.</p>
<section id="marginal-effects" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="marginal-effects"><span class="header-section-number">5.4.1</span> Marginal effects</h3>
<p>Since we are interested in the gender gap in Math Achievement, we will start by considering the values of Reading for which the gap is statistically significant. Note that this information was not available from the standard <code>summary(lm)</code> output shown in <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a> – the output showed that the regression coefficient representing the interaction was statistically significant, but it didn’t tell us for the values of Reading for which the gender gap was statistically significant. We can answer this type of question using the marginal “effects” discussed in this section.</p>
<p>There are three main types of marginal effects. For linear models, they are all basically the same, and we will only use one of them in this section. However, it is important that you can distinguish among them, especially when we get into non-linear models (e.g., logistic regression; see <span class="quarto-unresolved-ref">?sec-chap-10</span>). In general, when you report marginal effects in your research, you should be able to tell your reader which approach you used so they understand what you did and how to interpret the results.</p>
<p>To explain the three approaches, first let’s write the gender gap in Math Achievement using a slightly more compact notation (“<span class="math inline">\(\Delta\)</span>” for difference):</p>
<p><span class="math display">\[ \widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 X_1 = \Delta(X_1)\]</span></p>
<p>The three types of marginal effects are:</p>
<ul>
<li>Marginal effects at the mean (MEM): Report the gap at the mean value of <span class="math inline">\(X_1\)</span></li>
</ul>
<p><span class="math display">\[MEM =  \Delta(\bar X_1) \]</span></p>
<ul>
<li>Average marginal effect (AVE): Average the effect over values of <span class="math inline">\(X_1\)</span>:</li>
</ul>
<p><span class="math display">\[AVE =  \frac{\sum_i \Delta(X_{i1})}{N} \]</span></p>
<ul>
<li>Marginal effects at representative values (MERV): Report the marginal effect for a range of “interesting values” chosen by the researcher (denoted by *, <span class="math inline">\(\dagger\)</span>, etc.)</li>
</ul>
<p><span class="math display">\[ MERV =  \{\Delta(X^*_1), \Delta(X^\dagger_1), \dots \} \]</span></p>
<p>MEM and AVE are equivalent in linear models, but are different for nonlinear models (see <span class="quarto-unresolved-ref">?sec-chap-10</span>). The MERV approach also overlaps with MEM and AVE, because usually we choose the mean (or median) as one of the representative values of the predictor.</p>
<p>In this section we focus on MERV, because it is widely used. One common choice for the “interesting values” is the quartiles of <span class="math inline">\(X_1\)</span>, which are reported below for the example data. The output shows the gender gap in Math Achievement for 5 values of Reading Achievement. The values of Reading Achievement are its 5 quartiles. You can think of the output as a tabular summary of <a href="#fig-visreg-1">Figure&nbsp;<span>5.5</span></a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the emmeans package if you haven't already done so</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("emmeans")</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using R's formula syntax for interaction '*'</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> gender<span class="sc">*</span>achrdg12, <span class="at">data =</span> NELS)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>gap <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod6, </span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">specs =</span> <span class="st">"gender"</span>,</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">by =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>               <span class="at">cov.reduce =</span> quantile)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the differences are significant</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 31.8:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -7.74 1.637 496  -4.728  &lt;.0001

achrdg12 = 51.3:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -4.27 0.593 496  -7.207  &lt;.0001

achrdg12 = 57.0:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -3.25 0.529 496  -6.138  &lt;.0001

achrdg12 = 61.7:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -2.41 0.658 496  -3.659  0.0003

achrdg12 = 68.1:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -1.28 0.967 496  -1.321  0.1872</code></pre>
</div>
</div>
<p><strong>Please use the output to make a conclusion about the levels of Reading Achievement for which the gender gap was significant. Please be prepared to share your answer in class!</strong></p>
<p>Note that the computations going on “under the hood” when testing marginal effects can get pretty complicated. You can read more details here: <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html">https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html</a></p>
</section>
<section id="simple-trends" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="simple-trends"><span class="header-section-number">5.4.2</span> Simple trends</h3>
<p>In this section we test whether the slope of each of the simple trends is significantly different from zero. Like the marginal effects in the previous section, this is information was not entirely available in the <code>summary(lm)</code> output discussed in <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a>. From the <code>summary(lm)</code> output we learned the following two points about the simple trends:</p>
<ul>
<li><p>The regression coefficient on Reading told us about the relationship between Math and Reading, simply for the group designated as zero on the binary predictor (simply for females).</p></li>
<li><p>The regression coefficient on the interaction term told us whether the simple trends differ for the two groups (e.g., whether the simple trend for males differs from the simple trend for females).</p></li>
</ul>
<p>Note that what is missing, or implicit, is a test of whether the simple trend for males is different from zero. This test is of less relevance to our example (since we are treating Reading as the moderator), but we consider it for illustrative purposes.</p>
<p>The tests of the simple trends for the example data are reported below. As stated, these aren’t super interesting in the context of our example, but you should <strong>check your understanding of simple trends by writing down an interpretation of the output below</strong>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The regression coefficients on reading, broken down by gender</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod6, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> gender achrdg12.trend     SE  df t.ratio p.value
 Female          0.728 0.0470 496  15.487  &lt;.0001
 Male            0.550 0.0451 496  12.208  &lt;.0001</code></pre>
</div>
</div>
</section>
<section id="summary-2" class="level3" data-number="5.4.3">
<h3 data-number="5.4.3" class="anchored" data-anchor-id="summary-2"><span class="header-section-number">5.4.3</span> Summary</h3>
<p>When making inferences about an interaction:</p>
<ul>
<li><p>If the interaction isn’t significant in the <code>summary(lm)</code> output, we stop there. But if the interaction is significant, we may want to report more information about how the focal relationship depends on the moderator.</p></li>
<li><p>When the focal predictor is categorical, we can follow-up a significant interaction by taking a closer look at the statistical significance of the marginal effects (e.g, how the gender gap in Math changes as a function of Reading)</p></li>
<li><p>When the focal predictor is continuous, we can follow-up a significant interaction by taking a closer look at the statistical significance of the simple trends / simple slopes.</p></li>
</ul>
</section>
</section>
<section id="sec-two-continuous-predictors-5" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-two-continuous-predictors-5"><span class="header-section-number">5.5</span> Two continuous predictors</h2>
<p>At this point, we have covered the main ideas behind two-way interactions. In this section and the next, we apply these ideas to different combinations of predictors variables. In this section we address interactions between two continuous predictors. In the next section we address two categorical predictors. In both cases, the regression equation and overall interpretation is the same as the previous sections – e.g., the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span> changes as a function of <span class="math inline">\(X_2\)</span>. However, there are also some special details that crop up in these different settings.</p>
<p>In this section we will address:</p>
<ul>
<li><p>The importance of centering the two continuous predictors. Centering helps us interpret the “main effects” (i.e., the regression coefficients on the individual predictors).</p></li>
<li><p>How to follow-up a significant interaction using simple trends. As was the case for a categorical and a continuous predictor, this helps us interpret the interaction in more detail.</p></li>
</ul>
<p>First, we introduce an new example.</p>
<section id="another-nels-example" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="another-nels-example"><span class="header-section-number">5.5.1</span> Another NELS example</h3>
<p>To illustrate an interaction between two continuous predictors, let’s replace Gender with SES in our previous analysis. Apologies that this new example is mainly for convenience and doesn’t represent a great research question about, e.g., why the relationships between Math and Reading might change as a function of SES.</p>
<p>The overall approach with SES as the moderator is illustrated in <a href="#fig-readingXses-5">Figure&nbsp;<span>5.6</span></a> below. It presents the simple trends for Math and Reading at three values of SES. The overall situation should hopefully feel pretty familiar from the previous sections. The displayed values of SES (9, 19, and 28) are its 10th, 50th, and 90th percentiles, which is the default choice for the software we are using for plotting. For visual clarity, the confidence bands are not shown.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Interaction without centering </span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>mod7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses, <span class="at">data =</span> NELS)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that band = F removes the confidence intervals</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod7, </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">by =</span> <span class="st">"ses"</span>, </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">overlay =</span> <span class="cn">TRUE</span>, </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">band =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-readingXses-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-readingXses-5-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.6: Math (achmat), Reading (achrdg), and SES</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="centering-the-predictors" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="centering-the-predictors"><span class="header-section-number">5.5.2</span> Centering the predictors</h3>
<p>The take home message of this section is that you should center continuous predictors when their interaction is included in the model. There are two reasons:</p>
<ul>
<li><p>Just like <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a>, centering makes it easier to interpret the “main effects” (i.e., the regression coefficients on the individual predictors).</p></li>
<li><p>Centering can make the estimates of the main effects more precise. This is because centering can reduce the correlation between the individual predictors and the interaction term. Remember from <a href="ch3_two_predictors.html#sec-inference-for-coeffecients-3"><span>Section&nbsp;3.7.1</span></a> that highly correlated predictors lead to less precise estimates of the regression coefficients. We discuss this problem in more detail in <span class="quarto-unresolved-ref">?sec-multicollinearity-6</span>, but for now we just discuss how centering helps us avoid the problem.</p></li>
</ul>
<p>First lets consider how centering facilitates interpretation. Begin by noting that the coefficients <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> in the regression model</p>
<p><span class="math display">\[ \widehat Y = b_0 + b_1X_1 + b_2X_2 + b_3 (X_1 \times X_2) \]</span></p>
<p>can be interpreted in terms of the following simple trends:</p>
<p><span id="eq-simple-5"><span class="math display">\[\begin{align}
\widehat Y(X_2 =0) &amp; = b_0 + b_1X_1 \\
\widehat Y(X_1 =0)&amp;  = b_0 + b_2X_2
\end{align} \tag{5.9}\]</span></span></p>
<p>The first equation shows us that <span class="math inline">\(b_1\)</span> is the slope of relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_1\)</span>, when <span class="math inline">\(X_2\)</span> is equal to zero – in our example, the relationship between Math and Reading when SES is equal to zero. Similarly, the second equation shows us that <span class="math inline">\(b_2\)</span> is the slope of relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X_2\)</span> when <span class="math inline">\(X_1\)</span> is equal to zero – in our example, the relationship between Math and SES when Reading is equal to zero.</p>
<p>In general, the value of zero may not be meaningful for continuous predictors. But, when the predictor is <em>centered</em> (i.e., a deviation score), the value of zero is always the mean of the original variable. For example, if we centered SES, then <span class="math inline">\(b_1\)</span> would represent the relationship between Math and Reading for students with average SES. Similar considerations apply if we treat Reading as the moderator instead of SES. Note that this is just the same trick as <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a>, but this time both predictors are continuous and so both can be centered.</p>
<p>The second main reason for centering is a bit more technical. It has to do with reducing the correlation between the predictors and their interaction. In general, the interaction term will be correlated with both predictors if (a) the predictors themselves are correlated and (b) both predictors take on strictly positive (or strictly negative) values. Highly correlated predictors lead to redundant information the model, so we want to avoid this situation (this is technically called <em>multicollinearity</em> and we discuss it in more detail in a <span class="quarto-unresolved-ref">?sec-multicollinearity-6</span>).</p>
<p>To see how centering can reduce the correlation between the predictors and their interaction, let’s take a look at <a href="#fig-centering-5">Figure&nbsp;<span>5.7</span></a>. The left hand panel shows the relationship between SES and its interaction with Reading. We can see that they are highly correlated. This is because (a) SES and Reading are themselves correlated, and (b) both SES and Reading take on strictly positive values. As mentioned above, the interaction term will be correlated with both predictors whenever these two conditions hold. (The figure shows the correlation just for SES and the interaction, but the same situation holds for Reading.)</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation without centering</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">cor</span>(ses, achrdg12<span class="sc">*</span>ses)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"correlation = "</span>, <span class="fu">round</span>(r, <span class="dv">3</span>))</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ses, achrdg12<span class="sc">*</span>ses, </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> title, </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"SES X Reading"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation with centering</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>ses_dev <span class="ot">&lt;-</span> ses <span class="sc">-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">cor</span>(ses_dev, achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"correlation = "</span>, <span class="fu">round</span>(r, <span class="dv">3</span>))</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ses_dev, </span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>     achrdg12_dev<span class="sc">*</span>ses_dev, </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> title, </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"SES Centered"</span>, </span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"SES Centered X Reading Centered"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-centering-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-centering-5-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.7: Correlation Between SES and SES X Reading, With and Without Centering</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see in the right hand panel of <a href="#fig-centering-5">Figure&nbsp;<span>5.7</span></a> how centering the two predictors “breaks” the linear relationship between SES and its interaction with Reading. After centering, the relationship between SES and its interaction is now highly non-linear, and the correlation is approximately zero. Again, the same is true for the relationship between Reading and the interaction, but the figure only shows the situation for SES. The upshot of all this is that centering reduces multicollinearity between the “main effects” of the predictors and their interaction.</p>
<p>Below we show the output for two regression models. Both models regress Math on Reading, SES, and their interaction. The first model does not center the predictors, but the second model does (the <code>_dev</code> notation denotes the centered predictors).</p>
<p>The main difference between the models is that SES is a significant predictor in the centered model but not in the “un-centered” model. This is because the main effect of SES has a different meaning in the centered model, and it is also less correlated with the interaction. This is also true for Reading, but the differences between the two sets of results are less pronounced for Reading.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Without centering</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>mod7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod7)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 * ses)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.1336  -3.8944   0.7278   4.1301  15.0153 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  25.849200   5.389797   4.796 2.14e-06 ***
achrdg12      0.511601   0.099427   5.145 3.85e-07 ***
ses          -0.100114   0.291214  -0.344    0.731    
achrdg12:ses  0.004270   0.005196   0.822    0.412    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.031 on 496 degrees of freedom
Multiple R-squared:  0.4184,    Adjusted R-squared:  0.4149 
F-statistic: 118.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>mod8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod8)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12_dev * ses_dev)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.1336  -3.8944   0.7278   4.1301  15.0153 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)          56.826225   0.286906 198.065   &lt;2e-16 ***
achrdg12_dev          0.590313   0.036103  16.351   &lt;2e-16 ***
ses_dev               0.137305   0.041485   3.310    0.001 ** 
achrdg12_dev:ses_dev  0.004270   0.005196   0.822    0.412    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.031 on 496 degrees of freedom
Multiple R-squared:  0.4184,    Adjusted R-squared:  0.4149 
F-statistic: 118.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><strong>Please provide an interpretation of all four regression coefficients in the centered model. Your interpretations should make reference to the situation where one or both predictors are equal to zero (see <a href="#eq-simple-5">Equation&nbsp;<span>5.9</span></a> above) and should also mentioned the interpretation of the value of zero for the centered variables.</strong></p>
<p>Note that the interaction and the R-squared are the same in the centered and uncentered models. This is discussed in more detail in the extra material at the end of this section (<a href="#sec-two-categorical-predictors-5"><span>Section&nbsp;5.6</span></a>), but it is sufficient to note that centering only affects the interpretation of the main effects (and the intercept, of course).</p>
</section>
<section id="simple-trends-1" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="simple-trends-1"><span class="header-section-number">5.5.3</span> Simple trends</h3>
<p>Centering helps us interpret the main effects of the individual predictors, but we haven’t yet discussed how to interpret the interaction term. As shown in <a href="#fig-readingXses-5">Figure&nbsp;<span>5.6</span></a>, the overall situation is not that different than with a binary predictor.</p>
<p>The usual way to follow up a significant interaction between two continuous is using the MERV approach discussed in <a href="#sec-inference-for-interactions-5"><span>Section&nbsp;5.4</span></a>. Using this approach, we consider the focal relationship for some “interesting values” of the moderator. As with MERV, the choice of values of the moderator is up to the researcher, but some usual choices are</p>
<ul>
<li>The quartiles of the moderator</li>
<li>M <span class="math inline">\(\pm\)</span> 1 SD of the moderator</li>
<li>A selection of percentiles of the moderator (The <code>visreg</code> plot in <a href="#fig-readingXses-5">Figure&nbsp;<span>5.6</span></a> uses the 10th, 50th, and 90th)</li>
</ul>
<p>These are all doing very similar things, so choosing among them usually isn’t super important.</p>
<p>Although the interaction between Reading and SES was not significant in our example model, let’s break down the interaction using SES as the moderator, just to see how this approach works. The output below presents the simple slopes for the three values of SES shown in <a href="#fig-readingXses-5">Figure&nbsp;<span>5.6</span></a> (i.e., the 10th, 50th, and 90th percentiles). We can see in the output that the simple slopes are all different from zero. (And the non-significant interaction in the <code>summary(lm)</code> output tells us that the slopes are not statistically different from one another.)</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Break down interaction with SES as moderator</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span><span class="fu">emtrends</span>(mod7, </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">var =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">specs =</span> <span class="st">"ses"</span>, </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">at =</span> <span class="fu">list</span>(<span class="at">ses =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">19</span>, <span class="dv">28</span>)))</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> ses achrdg12.trend     SE  df t.ratio p.value
   9          0.550 0.0583 496   9.429  &lt;.0001
  19          0.593 0.0365 496  16.251  &lt;.0001
  28          0.631 0.0639 496   9.878  &lt;.0001</code></pre>
</div>
</div>
</section>
<section id="summary-3" class="level3" data-number="5.5.4">
<h3 data-number="5.5.4" class="anchored" data-anchor-id="summary-3"><span class="header-section-number">5.5.4</span> Summary</h3>
<p>When regressing an outcome on two continuous predictors and their interaction, the overall interpretation of the model is same as discussed in <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a>, but:</p>
<ul>
<li><p>It is useful to center both predictors, to facilitate the interpretation of the main effects (i.e., regression coefficients on the individual predictors), and to improve the precision of the main effects (i.e., reduce multicollinearity).</p></li>
<li><p>When following up a significant interaction, the usual approach is to report the simple trends for the focal variables at a selection of values of the moderator (e.g., a selection of percentiles). The example illustrated how to do this even though the interaction was not significant, but you shouldn’t follow up a non-significant interaction.</p></li>
</ul>
</section>
<section id="sec-how-centering-works-5" class="level3" data-number="5.5.5">
<h3 data-number="5.5.5" class="anchored" data-anchor-id="sec-how-centering-works-5"><span class="header-section-number">5.5.5</span> Extra: How centering works*</h3>
<p>It might seem that centering both predictors is a bit dubious – how can we just change the predictors in the model? This sections shows that using the centered or the un-centered predictors doesn’t make a difference in term of what predictors are in the model, it just changes the interpretation of the main effects (and intercept).</p>
<p>Using <span class="math inline">\(D = X - \bar X\)</span> for the centered variables, simple algebra shows:</p>
<p><span class="math display">\[\begin{align}
\widehat Y &amp; = b_0 + b_1D_1 + b_1D_2 + b_3 (D_1 \times D_2) \\
&amp; = b_0^* + (b_1 - b_3 \bar X_1) X_1 + (b_2 - b_3 \bar X_2) X_2 +  b_3 (X_1 \times X_2) \\
\text{where} &amp; \\ \\
b_0^* &amp; = a - b_1\bar X_1 - b_2\bar X_2 - b_3\bar X_1\bar X_2.
\end{align}\]</span></p>
<p>The second line of the equation shows that we are not changing what we regress <span class="math inline">\(Y\)</span> on – i.e., the predictors are still <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. We are changing the interpretation of the main effects (and intercept), but this is exactly the purpose of this approach. Also note centering does not change the regression coefficient for the interaction at all. So, we get main effects (and intercept) that can be more easily interpreted, and the same interaction</p>
</section>
</section>
<section id="sec-two-categorical-predictors-5" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="sec-two-categorical-predictors-5"><span class="header-section-number">5.6</span> Two categorical predictors</h2>
<p>This section addresses interactions between two categorical predictors. Up until now, we have looked at interactions only for categorical predictors that are dichotomous. In this section, we address an example in which one of the categorical predictors has more than two levels. This requires combining what we learned about contrast coding (<a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>) with what we have learned about interactions. One nice aspect of interactions among categorical predictors is that we usually don’t need to use procedures like marginal effects to follow up significant interactions, so long as we make good use of contrast coding.</p>
<p>In experimental (as opposed to observational) settings, interactions among categorical predictors fall under the much larger topic of ANOVA and experimental design. The analysis we look at in this section is a two-way between-subjects ANOVA, meaning that there are two categorical predictors considered, as well as their interaction, and both predictors are cross-sectional. ANOVA is a big topic and is not the focus of this course. However, we will discuss how to summarize the results of our analysis in an ANOVA table, and consider how this differs from the standard regression approach.</p>
<section id="an-example-from-ecls" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="an-example-from-ecls"><span class="header-section-number">5.6.1</span> An example from ECLS</h3>
<p>For this topic we will switch over to the ECLS data and examine how SES and Pre-K attendance interact to predict Math Achievement at the beginning of Kindergarten. The variables we will examine are</p>
<ul>
<li><p>Math Achievement at the beginning of K (<code>c1rmscal</code>). This is the number of correct questions on a test with approximately 70 items.</p></li>
<li><p>Whether the child attended Pre-K (<code>p1center</code>). This is a binary variable that indicates pre-K attendance.</p></li>
<li><p>SES, coded as quintiles (<code>wksesq5</code>). We will denote this variable as SES, but keep in mind it is quintiles in this example (e.g., SES = 1 are the respondents with SES between the minimum and the first quintile).</p></li>
</ul>
<p>Coding SES as quintiles allows us to consider it as a categorical predictor with 5 levels. This is a widely-used practice, because SES often has non-linear relationships with outcome variables of interest, and these relationships can be more easily captured by treating SES as a categorical variable. This approach to SES is also convenient for our illustration of interactions between categorical predictors.</p>
<p>In this analysis, our focus will be whether the “effect” of Pre-K on Math Achievement depends on (i.e., is moderated by) the child’s SES. Please note that I will use the term “effect” in this section to simplify language, but we know that Pre-K attendance was not randomly assigned in ECLS, so please keep in mind that this terminology is not strictly correct.</p>
<p>The relationship among the three variables is summarized in the <code>visreg</code> plot below. We can see that the effect of Pre-K on Math Achievement appears to differ as a function of SES – i.e., it appears that there is an interaction between Pre-K and SES. Our goal in this section is to produce an analysis corresponding to the figure.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-prek-by-ses-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/fig-prek-by-ses-5-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5.8: Math Achievement, Pre-K Attendence, and SES</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Before moving on, please take a moment to write down your interpretation of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>, focussing on how it illustrates an interaction between SES and Pre-K. Additionally, please describe how the figure would be different if there was no interaction between Pre-K and SES</strong>.</p>
</section>
<section id="the-no-interaction-model" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="the-no-interaction-model"><span class="header-section-number">5.6.2</span> The “no-interaction” model</h3>
<p>As in <a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a>, we will start with a model that includes only the main effects of SES and Pre-K. Seeing where that model “goes wrong” is a good way of understanding the interaction between the two predictors.</p>
<p>In order to represent a model with multiple categorical predictors, it is helpful to change our notation from the usual <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> to the more informative “variable names” notation:</p>
<p><span id="eq-prek-ses-5"><span class="math display">\[
\begin{align}
\widehat Y = b_0 + b_1 PREK + b_2SES_2 + b_3SES_3 + b_4 SES_4 + b_5 SES_5.
\end{align} \tag{5.10}\]</span></span></p>
<p>In this notation, the predictor variables are indicators (binary dummies). The variable <span class="math inline">\(PREK\)</span> is just the indicator for Pre-K attendance, as defined above. The variable <span class="math inline">\(SES_j\)</span> is an indicator for the j-th quintile of SES.</p>
<p>Both predictors use reference-group coding, as discussed in <a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>. For <span class="math inline">\(PREK\)</span>, reference-group coding is implied because it is a binary indicator. For <span class="math inline">\(SES\)</span>, reference-group coding is accomplished by omitting the binary dummy for the first quintile (i.e., the first quintile is the reference group).</p>
<p>We can interpret the coefficients in this model using the same two-step procedure described in <a href="ch4_categorical_predictors.html"><span>Chapter&nbsp;4</span></a>. Since there are many terms in the model, things are going to start getting messy quickly, so brace yourself for some long equations (but simple math!).</p>
<p>The main points about the interpretation of this model are as follows.</p>
<ul>
<li>The intercept is the predicted value of Math Achievement for students in the first SES quintile who did not attend Pre-K. This corresponds to the blue line in the first column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>.</li>
</ul>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 0, SES = 1) &amp; = b_0 + b_1 (0) + b_2(0)+ b_3(0) + b_4 (0) + b_5 (0) \\  
&amp; = b_0
\end{align}\]</span></p>
<ul>
<li>The effect of Pre-K attendance for students in the first SES quintile is equal to <span class="math inline">\(b_1\)</span>. This corresponds to the difference between the red and blue lines in the first column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>.</li>
</ul>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 1, SES = 1) &amp; = b_0 + b_1 (1) + b_2(0)+ b_3(0) + b_4 (0) + b_5 (0) \\  
&amp; = b_0 + b_1 \\
\implies &amp;
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 1, SES = 1) - \widehat Y(PREK = 0, SES = 1) &amp; = b_1
\end{align}\]</span></p>
<ul>
<li>Because the model in <a href="#eq-prek-ses-5">Equation&nbsp;<span>5.10</span></a> does not include an interaction, we already know that it implies that the effect of Pre-K is constant over levels of SES. Below we show that effect of Pre-K for SES = 2 is the same as the effect for SES = 1. The same approach can be used to show the effect is constant over all levels of SES. Note that while the model assumes the effect of Pre-K is constant over levels of SES, this is actually inconsistent with what is shown in <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>. We will improve on this model by adding an interaction in the following section.</li>
</ul>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 0, SES = 2) &amp; = b_0 + b_1 (0) + b_2(1 )+ b_3(0) + b_4 (0) + b_5 (0)\\  
&amp; = b_0 + b_2 \\ \\
\widehat Y(PREK = 1, SES = 2)&amp; = b_0 + b_1 (1) + b_2(1)+ b_3(0) + b_4 (0) + b_5 (0)\\  
&amp; = b_0 + b_1 + b_2 \\ \\
\implies &amp;
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2) = b_1  
\end{align}\]</span></p>
<p>This equation says that the difference between the red and blue lines in the second column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a> is the same as the difference in the first column – i.e., they both equal <span class="math inline">\(b_1\)</span>. This is what it means for there to be no interaction between two categorical predictors.</p>
<p>If you want more practice with this, you can show that <a href="#eq-prek-ses-5">Equation&nbsp;<span>5.10</span></a> implies the effect of Pre-K is constant over all levels of SES. Additionally, you can use the 2-step approach to show that the effect of SES is constant over levels of Pre-K attendance.</p>
</section>
<section id="adding-the-interactions" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="adding-the-interactions"><span class="header-section-number">5.6.3</span> Adding the interaction(s)</h3>
<p>We have just seen that <a href="#eq-prek-ses-5">Equation&nbsp;<span>5.10</span></a> implies that the effect of Pre-K is constant over levels of SES, and vise versa. In order to address our research question about whether the relationship between Pre-K attendance and Math Achievement depends on children’s SES, we will need to add something to the model – an interaction (surprise!).</p>
<p>We know that interactions are just products (multiplication) of predictor variables. Since SES is represented as 4 dummies, this means we need 4 products to represent the interaction of Pre-K with SES. The resulting model can be written:</p>
<p><span id="eq-prek-ses-5b"><span class="math display">\[\begin{align}
\widehat Y  = &amp; b_0 + b_1 PREK + b_2SES_2 + b_3SES_3 + b_4 SES_4 + b_5 SES_5 + \\
&amp;  b_6 (PREK \times SES_2) + b_7(PREK \times SES_3) + \\
&amp; b_8 (PREK \times SES_4) + b_9 (PREK \times SES_5)
\end{align} \tag{5.11}\]</span></span></p>
<p>As you can see, we have a lot of predictors in this model! Although we are only considering two distinct “conceptual” predictors, we have 9 coefficients in our regression model (+ the intercept).</p>
<p>Again, there are a few main things to notice:</p>
<ul>
<li><p>The interpretation of the intercept has not changed. It still corresponds to the blue line in the first column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>.</p></li>
<li><p>The regression coefficient on <span class="math inline">\(PREK\)</span> is still the “effect” of Pre-K for students in the first SES quintile (i.e., the difference between the red and blue line in the first column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a>). This is because all the <span class="math inline">\(SES_j\)</span> variables are equal to zero for students in the first SES quintile, and so all of the interaction terms in <a href="#eq-prek-ses-5b">Equation&nbsp;<span>5.11</span></a> are equal to zero.</p></li>
<li><p>The effect of Pre-K is no longer constant over levels of SES. Again we will focus on SES = 2, but the same approach works for the other levels of SES.</p></li>
</ul>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 0, SES = 2) &amp; = b_0 + b_1 (0) + b_2(1 )+ b_3(0) + b_4 (0) + b_5 (0) + \\
&amp;  b_6 (0 \times 1) + b_7(0 \times 0) + b_8 (0 \times 0) + b_9 (0\times 0) \\  
&amp; = b_0 + b_2 \\ \\
\widehat Y(PREK = 1, SES = 2) &amp; = b_0 + b_1 (1) + b_2(1)+ b_3(0) + b_4 (0) + b_5 (0) + \\
&amp;  b_6 (1 \times 1) + b_7(1 \times 0) + b_8 (1 \times 0) + b_9 (1\times 0) \\  
&amp; = b_0 + b_1 + b_2 + b_6 \\ \\
\implies &amp;
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2) = b_1 + b_6
\end{align}\]</span></p>
<p>The last line shows that the “effect” of Pre-K for students in the second SES quintile is <span class="math inline">\(b_1 + b_6\)</span>. This is not the same as the effect for students in the first quintile, which was just <span class="math inline">\(b_1\)</span>. In other words, the difference between the red and blue lines in the first column of <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a> (i.e., <span class="math inline">\(b_1\)</span>) is not equal to the difference in the second column (i.e., <span class="math inline">\(b_1 + b_6\)</span>) unless the interaction is equal to zero (i.e., <span class="math inline">\(b_6 = 0\)</span>).</p>
<p>The same approach shows that the effect of Pre-K at each level of SES results in a similar equation:</p>
<p><span class="math display">\[\begin{align}
\widehat Y(PREK = 1, SES = 3) - \widehat Y(PREK = 0, SES = 3) &amp; = b_1 + b_7 \\
\widehat Y(PREK = 1, SES = 4) - \widehat Y(PREK = 0, SES = 4) &amp; = b_1 + b_8 \\
\widehat Y(PREK = 1, SES = 5) - \widehat Y(PREK = 0, SES = 5) &amp; = b_1 + b_9 \\
\end{align}\]</span></p>
<p>This pattern makes it clear that, to isolate the interactions (i.e., <span class="math inline">\(b_6\)</span> through <span class="math inline">\(b_9\)</span>), we need to subtract off <span class="math inline">\(b_1\)</span> – i.e., we need to subtract off the effect of Pre-K for students in the first SES quintile. In anology with reference group coding for single predictor (see <a href="ch4_categorical_predictors.html#sec-reference-group-coding-4"><span>Section&nbsp;4.4</span></a>), we can think of <span class="math inline">\(b_1\)</span> the “reference effect” or baseline to which the interaction terms are compared.</p>
<p>For example</p>
<ul>
<li><p>The interaction between Pre-K and the second SES quintile is the effect Pre-K has on Math Achievement for students in the second SES quintile, <em>as compared to the effect in the first SES quintile.</em></p></li>
<li><p>The interaction between Pre-K and the third SES quintile is the effect Pre-K has on Math Achievement for students in the 3rd SES quintile, <em>as compared to the effect in the first SES quintile.</em></p></li>
<li><p>etc. etc.</p></li>
</ul>
<p>Mathematically, the interaction terms are represented as “differences-in-differences”. For example,</p>
<p><span class="math display">\[\begin{align}
b_6 &amp; = [\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2)] -  b_1 \\
    &amp; = [\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2)] \\
    &amp; - [\widehat Y(PREK = 1, SES = 1) - \widehat Y(PREK = 0, SES = 1)]
\end{align}\]</span></p>
<p>This looks quite complicated but it is just an extension of reference-group coding. This equation is saying that the “reference effect” or “baseline” for interpreting the interaction (<span class="math inline">\(b_6\)</span>) is the effect of Pre-K in the first SES quintile (i.e., <span class="math inline">\(b_1\)</span>). As noted above, all of the interaction terms have the same reference effect.</p>
</section>
<section id="back-to-the-example-1" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="back-to-the-example-1"><span class="header-section-number">5.6.4</span> Back to the example</h3>
<p>That last section was a lot to take in, so let’s put some numbers on the page to check our understanding. The output below shows the summary for a model that regresses Math Achievement on Pre-K, SES, and their interaction. <strong>Please write down an interpretation of magnitude, direction, and statistical significance of each regression coefficient in this output (including the intercept), and be prepared to share your answers in class.</strong> Remember that <code>wksesq5</code> is the variable code for the SES quintiles – the digit that follows the variable code indicates the level of variable. It may be helpful to refer to <a href="#fig-prek-by-ses-5">Figure&nbsp;<span>5.8</span></a> when interpreting the coefficients.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = c1rmscal ~ prek * wksesq5, data = ecls)

Residuals:
     Min       1Q   Median       3Q      Max 
-16.7682  -4.7682  -0.9755   3.9545  31.2318 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     16.0455     0.7355  21.816  &lt; 2e-16 ***
prek1           -0.3735     0.9601  -0.389  0.69732    
wksesq52         2.2931     0.9570   2.396  0.01663 *  
wksesq53         2.9300     0.9127   3.210  0.00134 ** 
wksesq54         4.6310     0.9439   4.906 9.87e-07 ***
wksesq55         7.2990     1.0343   7.057 2.19e-12 ***
prek1:wksesq52   1.0638     1.2118   0.878  0.38012    
prek1:wksesq53   2.1087     1.1544   1.827  0.06785 .  
prek1:wksesq54   1.6715     1.1684   1.431  0.15267    
prek1:wksesq55   2.7972     1.2340   2.267  0.02349 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.9 on 2567 degrees of freedom
Multiple R-squared:  0.1621,    Adjusted R-squared:  0.1592 
F-statistic: 55.19 on 9 and 2567 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section>
<section id="the-anova-approach" class="level3" data-number="5.6.5">
<h3 data-number="5.6.5" class="anchored" data-anchor-id="the-anova-approach"><span class="header-section-number">5.6.5</span> The ANOVA approach</h3>
<p>The output in the previous section is detailed enough that it is not usually required to follow-up a significant interaction among categorical predictors using marginal effects. However, the summary output still omits some information we might be interested in. For example, the Pre-K indicator in the above output tells us the effect of Pre-K, but only for children in the first SES quintile. We might also want to know about the overall effect of Pre-K across levels of SES – i.e., is there a significant difference in Math Achievement for students who attended Pre-K, after controlling for their level of SES? Similarly, what is the overall main effect of SES?</p>
<p>One way to summarize the main effects of Pre-K and SES, as well as their interaction, by asking how much variance they explain after controlling for the other predictors in the model. This is the ANOVA approach we discussed last semester, but now applied to two categorical predictors.</p>
<p>The ANOVA table for our example is below, and it is followed by the R-squared coefficients for each predictor, which are called “eta-squared” (<span class="math inline">\(\eta^2\)</span>) in the context of ANOVA. These R-squared (eta-squared) coefficients tell us what proportion of the variance in Math Achievement is attributable to the main effects and the interaction.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA Table</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: c1rmscal
               Df Sum Sq Mean Sq  F value Pr(&gt;F)    
prek            1   3434  3434.3  72.1437 &lt;2e-16 ***
wksesq5         4  19914  4978.4 104.5805 &lt;2e-16 ***
prek:wksesq5    4    299    74.7   1.5701 0.1795    
Residuals    2567 122198    47.6                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared (eta-squared)</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("effectsize")</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter    |     Eta2 |       95% CI
--------------------------------------
prek         |     0.02 | [0.01, 1.00]
wksesq5      |     0.14 | [0.12, 1.00]
prek:wksesq5 | 2.05e-03 | [0.00, 1.00]

- One-sided CIs: upper bound fixed at [1.00].</code></pre>
</div>
</div>
<p><strong>Please write down your interpretation of the ANOVA table and R-squared (eta-squared) coefficients and be prepared to share you thoughts in class.</strong> Note that the ANOVA output leads to different conclusions than the regression output above. We will discuss the discrepancies between the ANOVA and regression output in class.</p>
<p>Let’s end this discussion of ANOVA with two qualifications.</p>
<p>First, I should clarify that the term “main effect” has a somewhat different meaning in ANOVA as compared to regression. In the regression examples, we talked about the effect of a predictor, <em>conditional on</em> the other predictor being zero. In ANOVA stuff above, we instead talked about the average or overall effect of a predictor, while holding the other predictor constant. These two interpretations are related but not the same, and in the ANOVA literature, “main effect” usually means the average or overall effect.</p>
<p>Second, some people claim that it is bad practice to interpret main effects <em>qua</em> average effects in the presence of an interaction. The basic argument is that we shouldn’t report the average effect when the “real message” of the interaction is that the effect changes as a function of the other predictor. I think that main effects and interactions aren’t really incompatible concepts, especially if we are talking about conditional main effects rather than average main effects. But, you should be aware that this topic is debated and you are free to make up your own mind (as always!).</p>
</section>
</section>
<section id="workbook" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="workbook"><span class="header-section-number">5.7</span> Workbook</h2>
<p>This section collects the questions asked in this chapter. The lessons for this chapter will focus on discussing these questions and then working on the exercises in <a href="#sec-exercises-5"><span>Section&nbsp;5.8</span></a>. The lesson will <strong>not</strong> be a lecture that reviews all of the material in the chapter! So, if you haven’t written down / thought about the answers to these questions before class, the lesson will not be very useful for you. Please engage with each question by writing down one or more answers, asking clarifying questions about related material, posing follow up questions, etc.</p>
<p><a href="#sec-example-5"><span>Section&nbsp;5.1</span></a></p>
<ul>
<li>What does the following plot is telling us about the relationships among the three variables. In particular:
<ul>
<li>Does the gender gap in Math Achievement change as a function of Reading Achievement?</li>
<li>Is the relationship between Math Achievement and Reading Achievement the the same for males and females?</li>
<li>What do the results mean for gender equality in Math and STEM education?</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[females] <span class="sc">~</span> achrdg12[females])</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[males] <span class="sc">~</span> achrdg12[males])</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod1, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender),</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><a href="#sec-binary-continuous-5"><span>Section&nbsp;5.2</span></a></p>
<ul>
<li>No interaction model: The regression coefficients for the example data are shown below. Please use these numbers to provide an interpretation of the simple trends and the gender gap in Math Achievement for the NELS example. Don’t worry about statistical significance, just focus on the meaning of the coefficients.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender, <span class="at">data =</span> NELS)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender, data = NELS)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.2448  -3.6075   0.3968   3.9836  15.5606 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 19.98122    1.86278  10.727  &lt; 2e-16 ***
achrdg12     0.63551    0.03275  19.404  &lt; 2e-16 ***
genderMale   3.50166    0.52473   6.673 6.69e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.839 on 497 degrees of freedom
Multiple R-squared:  0.4538,    Adjusted R-squared:  0.4516 
F-statistic: 206.4 on 2 and 497 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Here is an example to help you get started:</p>
<ul>
<li><p>Simply for females, the regression of Math Achievement on Reading Achievement has an intercept equal to 19.98 and a slope equal to 0.64. The intercept tells us that a female student with Reading Achievement score of 0% is expected to have a Math Achievement score of 19.98% (the units of the two tests are percent correct). Since the lowest value of Reading Achievement in our example is about 35%, the intercept is not very meaningful for these data. The regression slope tells us that, for females, a 1 unit increase in Reading Achievement is associated with a .64 unit increase in Math Achievement.</p></li>
<li><p>Simply for males, ….</p></li>
<li><p>The gender gap in Math Achievement was equal to …</p></li>
</ul>
<p><a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a></p>
<ul>
<li>Interaction model: The regression coefficients for the example data are shown below. Please use these numbers to provide an interpretation of the interaction between Gender and Reading. Don’t worry about statistical significance, just focus on the meaning of the coefficients.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hard code the interaction term</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>genderXachrdg12 <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Rund the model with the interaction included</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXachrdg12)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + genderXachrdg12)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     14.80310    2.64922   5.588  3.8e-08 ***
achrdg12         0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale      13.39328    3.65828   3.661 0.000278 ***
genderXachrdg12 -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ul>
<li>Interaction model using the centered continuous predictor: Please write down your interpretation of the intercept and the regression coefficient for Gender in the regression output below.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the deviation scores for reading</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>reading_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12, <span class="at">na.rm =</span> T) </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the interaction model as above</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>genderXreading_dev <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> reading_dev</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> reading_dev <span class="sc">+</span> gender <span class="sc">+</span> genderXreading_dev)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ reading_dev + gender + genderXreading_dev)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        55.29439    0.35127 157.411  &lt; 2e-16 ***
reading_dev         0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale          3.49930    0.52135   6.712 5.26e-11 ***
genderXreading_dev -0.17794    0.06514  -2.732  0.00652 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><a href="#sec-inference-for-interactions-5"><span>Section&nbsp;5.4</span></a></p>
<ul>
<li>The output shows the gender gap in Math Achievement for 5 values of Reading Achievement. The values of Reading Achievement are its 5 quartiles. You can think of the output as a tabular summary of <a href="#fig-visreg-1">Figure&nbsp;<span>5.5</span></a>. Please use the output to make a conclusion about the levels of Reading Achievement for which the gender gap was significant. Please be prepared to share your answer in class</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the emmeans package if you haven't already done so</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("emmeans")</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using R's formula syntax for interaction '*'</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> gender<span class="sc">*</span>achrdg12, <span class="at">data =</span> NELS)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>gap <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod6, </span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">specs =</span> <span class="st">"gender"</span>,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">by =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>               <span class="at">cov.reduce =</span> quantile)</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the differences are significant</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 31.8:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -7.74 1.637 496  -4.728  &lt;.0001

achrdg12 = 51.3:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -4.27 0.593 496  -7.207  &lt;.0001

achrdg12 = 57.0:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -3.25 0.529 496  -6.138  &lt;.0001

achrdg12 = 61.7:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -2.41 0.658 496  -3.659  0.0003

achrdg12 = 68.1:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -1.28 0.967 496  -1.321  0.1872</code></pre>
</div>
</div>
<ul>
<li>The test of the slopes of the simple trends for the example are reported below. As previously stated, these aren’t super interesting in the context of our example, but you should check your understanding of simple trends by writing down an interpretation of the output below.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The regression coefficients on reading, broken down by gender</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod6, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> gender achrdg12.trend     SE  df t.ratio p.value
 Female          0.728 0.0470 496  15.487  &lt;.0001
 Male            0.550 0.0451 496  12.208  &lt;.0001</code></pre>
</div>
</div>
<p><a href="#sec-two-continuous-predictors-5"><span>Section&nbsp;5.5</span></a></p>
<ul>
<li>Please provide an interpretation of all four regression coefficients in the centered model. Your interpretations should make reference to the situation where one or both predictors are equal to zero (see <a href="#eq-simple-5">Equation&nbsp;<span>5.9</span></a> above) and should also mentioned the interpretation of the value of zero for the centered variables.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>mod8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod8)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12_dev * ses_dev)

Residuals:
     Min       1Q   Median       3Q      Max 
-17.1336  -3.8944   0.7278   4.1301  15.0153 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)          56.826225   0.286906 198.065   &lt;2e-16 ***
achrdg12_dev          0.590313   0.036103  16.351   &lt;2e-16 ***
ses_dev               0.137305   0.041485   3.310    0.001 ** 
achrdg12_dev:ses_dev  0.004270   0.005196   0.822    0.412    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.031 on 496 degrees of freedom
Multiple R-squared:  0.4184,    Adjusted R-squared:  0.4149 
F-statistic: 118.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><a href="#sec-two-categorical-predictors-5"><span>Section&nbsp;5.6</span></a></p>
<ul>
<li>Please take a moment to write down your interpretation of the figure below, focussing on how it illustrates an interaction between SES and Pre-K. Additionally, please describe how the figure would be different if there was no interaction between Pre-K and SES.</li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch5_interactions_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>The output below shows the summary for a model that regresses Math Achievement on Pre-K, SES, and their interaction. Please write down an interpretation of magnitude, direction, and statistical significance of each regression coefficient in this output (including the intercept), and be prepared to share your answers in class. Remember that <code>wksesq5</code> is the variable code for the SES quintiles – the digit that follows the variable code indicates the level of variable. It may be helpful to refer to the previous figure in your interpretations.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = c1rmscal ~ prek * wksesq5, data = ecls)

Residuals:
     Min       1Q   Median       3Q      Max 
-16.7682  -4.7682  -0.9755   3.9545  31.2318 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     16.0455     0.7355  21.816  &lt; 2e-16 ***
prek1           -0.3735     0.9601  -0.389  0.69732    
wksesq52         2.2931     0.9570   2.396  0.01663 *  
wksesq53         2.9300     0.9127   3.210  0.00134 ** 
wksesq54         4.6310     0.9439   4.906 9.87e-07 ***
wksesq55         7.2990     1.0343   7.057 2.19e-12 ***
prek1:wksesq52   1.0638     1.2118   0.878  0.38012    
prek1:wksesq53   2.1087     1.1544   1.827  0.06785 .  
prek1:wksesq54   1.6715     1.1684   1.431  0.15267    
prek1:wksesq55   2.7972     1.2340   2.267  0.02349 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.9 on 2567 degrees of freedom
Multiple R-squared:  0.1621,    Adjusted R-squared:  0.1592 
F-statistic: 55.19 on 9 and 2567 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ul>
<li>Please write down your interpretation of the ANOVA table and R-squared (eta-squared) coefficients below and be prepared to share you thoughts in class. Note that the ANOVA output leads to different conclusions than the regression output above. We will discuss the discrepancies between the ANOVA and regression output in class.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA Table</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: c1rmscal
               Df Sum Sq Mean Sq  F value Pr(&gt;F)    
prek            1   3434  3434.3  72.1437 &lt;2e-16 ***
wksesq5         4  19914  4978.4 104.5805 &lt;2e-16 ***
prek:wksesq5    4    299    74.7   1.5701 0.1795    
Residuals    2567 122198    47.6                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared (eta-squared)</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("effectsize")</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter    |     Eta2 |       95% CI
--------------------------------------
prek         |     0.02 | [0.01, 1.00]
wksesq5      |     0.14 | [0.12, 1.00]
prek:wksesq5 | 2.05e-03 | [0.00, 1.00]

- One-sided CIs: upper bound fixed at [1.00].</code></pre>
</div>
</div>
</section>
<section id="sec-exercises-5" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="sec-exercises-5"><span class="header-section-number">5.8</span> Exercises</h2>
<p>These exercises provide an overview of how to compute interactions using the <code>lm</code> function, how to center continuous predictors, and how to follow-up significant interactions with the <code>emmeans</code> package. We will go through this material in class together, so you don’t need to work on it before class (but you can if you want.)</p>
<p>Before staring this section, you may find it useful to scroll to the top of the page, click on the “&lt;/&gt; Code” menu, and select “Show All Code.”</p>
<section id="binary-continuous-interaction" class="level3" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="binary-continuous-interaction"><span class="header-section-number">5.8.1</span> Binary + continuous + interaction</h3>
<p>There are multiple ways of implementing interactions in R.</p>
<ul>
<li><p>We can “hard code” new variables into our data (e.g., the product of a binary gender variable and reading)</p></li>
<li><p>We can use R’s formula notation for single term interactions (<code>:</code>)</p></li>
<li><p>We can use R’s formula notation for factorial interactions (<code>*</code>)</p></li>
</ul>
<p>The following code illustrates the three approaches and shows that they all producing the same output. In general, the <code>*</code> syntax is the easiest to use, so we will stick with that one going forward. The variables used in the example are from the NELS data:</p>
<ul>
<li><code>achmat12</code> is Mat Achievement (percent correct on a math test) in grade 12.</li>
<li><code>achrdg12</code> is Reading Achievement (percent correct on a reading test) in grade 12.</li>
<li><code>gender</code> is dichotomous encoding of gender with values <code>Male</code> and <code>Female</code> (it is not a binary variable, but a factor, as discussed in <a href="ch4_categorical_predictors.html#sec-exercises-4"><span>Section&nbsp;4.9</span></a>.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via hard coding</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>genderXreading <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXreading)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + genderXreading)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    14.80310    2.64922   5.588  3.8e-08 ***
achrdg12        0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale     13.39328    3.65828   3.661 0.000278 ***
genderXreading -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via `:` operator</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> achrdg12<span class="sc">:</span>gender)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + achrdg12:gender)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         14.80310    2.64922   5.588  3.8e-08 ***
achrdg12             0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale          13.39328    3.65828   3.661 0.000278 ***
achrdg12:genderMale -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via `*` operator</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>gender)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 * gender)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         14.80310    2.64922   5.588  3.8e-08 ***
achrdg12             0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale          13.39328    3.65828   3.661 0.000278 ***
achrdg12:genderMale -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Before moving on, check your interpretation of the coefficients in the models. In particular, what does the regression coefficient on the interaction term mean?</p>
</section>
<section id="centering-continuous-predictors" class="level3" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="centering-continuous-predictors"><span class="header-section-number">5.8.2</span> Centering continuous predictors</h3>
<p>As noted in <a href="#sec-binary-continuous-interaction-5"><span>Section&nbsp;5.3</span></a>, the regression coefficient on Gender is not very interpretable when there is an interaction in the model. In the above output, the coefficient on gender tells us the gender gap in Math Achievement when <code>achrdg12 = 0</code>. We can fix this issue by re-scaling <code>achrdg12</code> so that zero has a meaningful value. One widely used approach is to center <code>achrdg12</code> at its mean. When a variable is centered at its mean it is called a <em>deviation score.</em></p>
<p>Let’s see what happens to our regression output when we use deviation scores for <code>achrdg12</code> instead of the “raw” score</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run the model with reading centered at its mean</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>gender)</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12_dev * gender)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                        Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)             55.29439    0.35127 157.411  &lt; 2e-16 ***
achrdg12_dev             0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale               3.49930    0.52135   6.712 5.26e-11 ***
achrdg12_dev:genderMale -0.17794    0.06514  -2.732  0.00652 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Note that the intercept and the regression coefficient on Gender have changed values compared to <code>mod3</code>. What is the interpretation of these coefficients in the new model?</p>
</section>
<section id="breaking-down-a-significant-interaction" class="level3" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="breaking-down-a-significant-interaction"><span class="header-section-number">5.8.3</span> Breaking down a significant interaction</h3>
<p>Next, let’s plot our model with the interaction term. One advantage of having everything in a single model is that we can level-up our plotting! The following code uses the <code>visreg</code> package. Note that the error bands in the plot are produced using the standard errors from <code>emmeans</code>, which is discussed below. If you want to know more about how visreg works, type <code>help(visreg)</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package if you haven't already done so</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("visreg")</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visreg)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod3, <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, <span class="at">by =</span> <span class="st">"gender"</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch5_interactions_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If the interaction is significant, then we usually want to report a bit more information about how the focal relationship changes as a function of the moderators. There are two main ways to do this:</p>
<ul>
<li><p>Marginal effects (aka marginal means, least squares means, adjusted means): This approach is used when the focal predictor is categorical and we want to compare means across the categories, conditional on levels of the moderator.</p></li>
<li><p>Simple trends (aka simple slopes): This approach is used when the focal predictor is continuous and we want to examine the slopes of the simple trends, conditional on the moderator.</p></li>
</ul>
<p>Usually, the researcher will chose one or the other approach, whichever is best suited to address the research questions of interest. Our example was motivated by consideration of the gender gap in STEM (i.e., the relationship between a STEM and a categorical predictor), so the marginal effects approach is better suited. We will also illustrate simple trends, just to show how that approach works.</p>
</section>
<section id="marginal-effects-1" class="level3" data-number="5.8.4">
<h3 data-number="5.8.4" class="anchored" data-anchor-id="marginal-effects-1"><span class="header-section-number">5.8.4</span> Marginal effects</h3>
<p>Let’s breakdown the interaction by asking how the relationship between Math and Gender (i.e., the gender achievement gap in Math) changes as a function of Reading. This can be done using <code>emmeans</code> package, and the main function in that pacakge is also called <code>emmeans</code>.</p>
<p>The three main arguments for the <code>emmeans</code> function:</p>
<ul>
<li><code>object</code> – the output of <code>lm</code>. This is the first argument</li>
<li><code>specs</code> – which factors in the model we want the means of (i.e., the focal predictor)</li>
<li><code>by</code> – which predictor(s) we want to use to breakdown the means (i.e., the moderator(s))</li>
</ul>
<p>We can use <code>emmeans</code> to compute the marginal effect at the mean (MEM) as follows:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package if you haven't already done so</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># install.packages("emmeans")</span></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>gap <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod3, <span class="at">specs =</span> <span class="st">"gender"</span>, <span class="at">by =</span> <span class="st">"achrdg12"</span>)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gap)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 55.6:
 gender emmean    SE  df lower.CL upper.CL
 Female   55.3 0.351 496     54.6     56.0
 Male     58.8 0.385 496     58.0     59.6

Confidence level used: 0.95 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the difference is significant</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 55.6:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male     -3.5 0.521 496  -6.712  &lt;.0001</code></pre>
</div>
</div>
<p>In the above output, we only get one Gender difference in Math, and that is computed for the value of <code>achrdg12 = 55.6</code>, which is the mean value of Reading. As noted, this is called the marginal effect at the mean (MEM).</p>
<p>It is often more helpful to report Gender difference for multiple different values of <code>achrdg12</code>, which is called MERV (marginal effects at representative values). While there are many ways to chose the representative values, one convenient approach approach is to use the quartiles of <code>achrdg12</code>. This is accomplished using the <code>cov.reduce</code> argument of <code>emmeans</code> as follows.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the the covarate reduce option of emmeans with the quantile function</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>gap_quartiles <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod3, <span class="at">specs =</span> <span class="st">"gender"</span>, <span class="at">by =</span> <span class="st">"achrdg12"</span>, <span class="at">cov.reduce =</span> quantile)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gap_quartiles)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 31.8:
 gender emmean    SE  df lower.CL upper.CL
 Female   37.9 1.186 496     35.6     40.3
 Male     45.7 1.129 496     43.5     47.9

achrdg12 = 51.3:
 gender emmean    SE  df lower.CL upper.CL
 Female   52.1 0.412 496     51.3     52.9
 Male     56.4 0.426 496     55.6     57.2

achrdg12 = 57.0:
 gender emmean    SE  df lower.CL upper.CL
 Female   56.3 0.355 496     55.6     57.0
 Male     59.6 0.393 496     58.8     60.3

achrdg12 = 61.7:
 gender emmean    SE  df lower.CL upper.CL
 Female   59.8 0.447 496     58.9     60.6
 Male     62.2 0.482 496     61.2     63.1

achrdg12 = 68.1:
 gender emmean    SE  df lower.CL upper.CL
 Female   64.4 0.674 496     63.1     65.7
 Male     65.7 0.693 496     64.3     67.0

Confidence level used: 0.95 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the gender difference in math achievement is significant at each quartile of reading achievement</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap_quartiles, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>achrdg12 = 31.8:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -7.74 1.637 496  -4.728  &lt;.0001

achrdg12 = 51.3:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -4.27 0.593 496  -7.207  &lt;.0001

achrdg12 = 57.0:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -3.25 0.529 496  -6.138  &lt;.0001

achrdg12 = 61.7:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -2.41 0.658 496  -3.659  0.0003

achrdg12 = 68.1:
 contrast      estimate    SE  df t.ratio p.value
 Female - Male    -1.28 0.967 496  -1.321  0.1872</code></pre>
</div>
</div>
<p>At this point, you should be able to summarize your conclusions about the gender gap in Math and how it depends on Reading.</p>
</section>
<section id="simple-trends-2" class="level3" data-number="5.8.5">
<h3 data-number="5.8.5" class="anchored" data-anchor-id="simple-trends-2"><span class="header-section-number">5.8.5</span> Simple trends</h3>
<p>Next we will show how to use <code>emtrends</code> to test the conditional or “simple” slopes of Math on Reading, given Gender. As mentioned, this approach is not very well suited to the example, but we are going through it here just to illustrate how to do this type of analysis.</p>
<p>The three main arguments for <code>emtrends</code> are</p>
<ul>
<li><code>object</code> – the output of <code>lm</code>. This is the first argument</li>
<li><code>var</code> – which continuous predictor in the model we want the slopes of</li>
<li><code>specs</code> – which factor predictor(s) in the model to break the trend down by</li>
</ul>
<p>Let’s see how it works.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emtrends function to get the regression coefficients on reading, broken down by gender</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod3, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> gender achrdg12.trend     SE  df lower.CL upper.CL
 Female          0.728 0.0470 496    0.636    0.821
 Male            0.550 0.0451 496    0.462    0.639

Confidence level used: 0.95 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> gender achrdg12.trend     SE  df t.ratio p.value
 Female          0.728 0.0470 496  15.487  &lt;.0001
 Male            0.550 0.0451 496  12.208  &lt;.0001</code></pre>
</div>
</div>
<p>The foregoing analysis tells us how the relationship between reading and math changes as a function of gender, and, in particular, whether the simple slopes are significant for males and females. Recall that the simple slope for females (the group coded zero) is just the regression coefficient on reading in the original <code>lm</code> output. So, the only new thing this output gives us is the simple slope for males.</p>
</section>
<section id="two-continuous-predictors" class="level3" data-number="5.8.6">
<h3 data-number="5.8.6" class="anchored" data-anchor-id="two-continuous-predictors"><span class="header-section-number">5.8.6</span> Two continuous predictors</h3>
<p>Interactions with continuous predictors are basically the same as for continuous and categorical. One main issue is that we should always center the predictors, not only to facilitate interpretation of the regression coefficients, but also to reduce the correlation between the main effects and the interaction.</p>
<p>For an example, let’s replace gender with SES from our previous analysis. Apologies that this new example is mainly for convenience and doesn’t represent a great research question about, e.g., about why the relationships between math and reading might change as a function of SES!</p>
<p>Here we will focus on how centering affects the results of a regression with interactions among continuous predictors.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Without centering</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + genderXreading)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    14.80310    2.64922   5.588  3.8e-08 ***
achrdg12        0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale     13.39328    3.65828   3.661 0.000278 ***
genderXreading -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>ses_dev <span class="ot">&lt;-</span> ses <span class="sc">-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = achmat12 ~ achrdg12 + gender + achrdg12:gender)

Residuals:
     Min       1Q   Median       3Q      Max 
-19.0582  -3.7864   0.5014   4.0775  16.2889 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         14.80310    2.64922   5.588  3.8e-08 ***
achrdg12             0.72824    0.04702  15.487  &lt; 2e-16 ***
genderMale          13.39328    3.65828   3.661 0.000278 ***
achrdg12:genderMale -0.17794    0.06514  -2.732 0.006524 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.801 on 496 degrees of freedom
Multiple R-squared:  0.4619,    Adjusted R-squared:  0.4586 
F-statistic: 141.9 on 3 and 496 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>We can see that, while both models account for the same overall variation in math, SES is significant in the centered model. This has to do both with changing the interpretation of the coefficient (it now represents the relationship between math and reading for students with average reading) and because it is no longer so highly redundant with the interaction term.</p>
<p>Although the interaction with SES was not significant in either model, let’s break down the interaction with <code>emtrends</code> just to see how it works. This time we will use the <code>at</code> option rather than the ’cov.reduce<code>option to break down the interaction. The values 9, 19, and 28 are the 10th, 50th, and 90th percentile of SES, which is the same approach</code>visreg<code>uses (You can overwrite the defaults using the</code>breaks<code>argument -- see</code>help(visreg)`).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Break down interaction with SES as moderator</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span><span class="fu">emtrends</span>(mod5, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"ses"</span>, <span class="at">at =</span> <span class="fu">list</span>(<span class="at">ses =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">19</span>, <span class="dv">28</span>)))</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_slopes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code> ses achrdg12.trend     SE  df lower.CL upper.CL
   9          0.550 0.0583 496    0.435    0.665
  19          0.593 0.0365 496    0.521    0.664
  28          0.631 0.0639 496    0.506    0.757

Confidence level used: 0.95 </code></pre>
</div>
</div>
<p>Finally let’s summarize our (non significant) interaction with a nice plot.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that band = F removes the confidence intervals</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod5, <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, <span class="at">by =</span> <span class="st">"ses"</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>, <span class="at">band =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch5_interactions_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="two-categorical-predictors" class="level3" data-number="5.8.7">
<h3 data-number="5.8.7" class="anchored" data-anchor-id="two-categorical-predictors"><span class="header-section-number">5.8.7</span> Two categorical predictors</h3>
<p>For this topic we will switch over to the ECLS data and examine how SES and Pre-K attendance interact to predict Math Achievement at the beginning of Kindergarten. The variables we will examine are</p>
<ul>
<li>Math Achievement at the beginning of K (<code>c1rmscal</code>). This is the number of correct questions on a test with approximately 70 items.</li>
<li>Whether the child attended Pre-K (<code>p1center</code>). This is a binary variable that indicates pre-K attendance.</li>
<li>SES, coded as quintiles (<code>wksesq5</code>). We will denote this variable as SES, but keep in mind it is quintiles in this example (e.g., SES = 1 are the respondents with SES between the minimum and the first quintile).</li>
</ul>
<p>The regression model is as follows. Note that both variables need to be converted to factors in R, so that R will treat them as categorical variables. Also recall that in R the default contrast coding for categorical predictors is reference-group coding.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = c1rmscal ~ prek * wksesq5, data = ecls)

Residuals:
     Min       1Q   Median       3Q      Max 
-16.7682  -4.7682  -0.9755   3.9545  31.2318 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     16.0455     0.7355  21.816  &lt; 2e-16 ***
prek1           -0.3735     0.9601  -0.389  0.69732    
wksesq52         2.2931     0.9570   2.396  0.01663 *  
wksesq53         2.9300     0.9127   3.210  0.00134 ** 
wksesq54         4.6310     0.9439   4.906 9.87e-07 ***
wksesq55         7.2990     1.0343   7.057 2.19e-12 ***
prek1:wksesq52   1.0638     1.2118   0.878  0.38012    
prek1:wksesq53   2.1087     1.1544   1.827  0.06785 .  
prek1:wksesq54   1.6715     1.1684   1.431  0.15267    
prek1:wksesq55   2.7972     1.2340   2.267  0.02349 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.9 on 2567 degrees of freedom
Multiple R-squared:  0.1621,    Adjusted R-squared:  0.1592 
F-statistic: 55.19 on 9 and 2567 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>To facilitate interpretation of the ouput, you can refer to the plot below. Each regression coefficient in the output corresponds to a feature of this plot.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch5_interactions_files/figure-html/unnamed-chunk-33-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In order to summarize the model as an ANOVA table, we can use the following code. Note that the ANOVA output tests the variance explained (i.e., R-squared) of the original variables, and does not include dummy variables.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: c1rmscal
               Df Sum Sq Mean Sq  F value Pr(&gt;F)    
prek            1   3434  3434.3  72.1437 &lt;2e-16 ***
wksesq5         4  19914  4978.4 104.5805 &lt;2e-16 ***
prek:wksesq5    4    299    74.7   1.5701 0.1795    
Residuals    2567 122198    47.6                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>In an ANOVA context, the R-squared statistics are called eta-squared. They are reported below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA (Type I)

Parameter    |     Eta2 |       95% CI
--------------------------------------
prek         |     0.02 | [0.01, 1.00]
wksesq5      |     0.14 | [0.12, 1.00]
prek:wksesq5 | 2.05e-03 | [0.00, 1.00]

- One-sided CIs: upper bound fixed at [1.00].</code></pre>
</div>
</div>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch4_categorical_predictors.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Categorical predictors</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ch6_model_building.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model building</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb88" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="an">fold:</span><span class="co"> true</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: 72</span></span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="fu"># Interactions {#sec-chap-5}</span></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>In statistics, the term *interaction* means that the relationship between two variables depends on a third variable. In the context of regression, we are usually interested in the situation where the relationship between the outcome $Y$ and a predictor $X_1$ depends on another predictor $X_2$. This situation is also referred to as *moderation* or sometimes as *effect heterogeneity*.</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>Interactions are a big-picture idea with a lot conceptual power, especially when describing topics related to social inequality or "gaps". Some examples of interactions are:  </span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The relationship between wages and years of education depends on gender. This has been called the gender pay gap and it is considered a pretty important issue for gender equality (e.g., <span class="co">[</span><span class="ot">https://en.wikipedia.org/wiki/Gender_pay_gap</span><span class="co">](https://en.wikipedia.org/wiki/Gender_pay_gap)</span>).</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The relationship between reading achievement and age depends on race. This has been interpreted in terms of racial inequality in educational outcomes (e.g., <span class="co">[</span><span class="ot">https://cepa.stanford.edu/educational-opportunity-monitoring-project/achievement-gaps/race/</span><span class="co">](https://cepa.stanford.edu/educational-opportunity-monitoring-project/achievement-gaps/race/)</span>).</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The effect of COVID-19 school shutdowns on academic achievement depended on SES. This has been interpreted in terms of social inequality in access to educational resources outside of schools (e.g., <span class="co">[</span><span class="ot">https://www.mckinsey.com/industries/education/our-insights/covid-19-and-student-learning-in-the-united-states-the-hurt-could-last-a-lifetime</span><span class="co">](https://www.mckinsey.com/industries/education/our-insights/covid-19-and-student-learning-in-the-united-states-the-hurt-could-last-a-lifetime)</span>).</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>I hope these examples convince you that some of the big issues facing education and society at large are actually about interactions -- how the relationship between two variables depends on a third variable. In this chapter we are going to talk about how you can use regression to conduct research on these types of topics.  </span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a>Some terminology: When we talk about statistical interactions, we often leave the outcome variable implicit and focus on the predictors. For example, the gender pay gap can be described as an interaction between gender and years of education. The outcome variable (wages) is implicit in this description. Throughout this chapter we are exclusively interested in interactions between two predictors at a time, which are called *two-way interactions*. There are actually three variables involved, because a two-way interaction also requires an outcome variable. It is possible to consider "higher-order" interactions (e.g., interactions among three predictors or *three-way interactions*) but we aren't going to do that here. Sometimes we will use the terminology *main effect* to describe the relationship between each individual predictor and the outcome variable, as distinct from the interactions among the predictors. Up to now, we have be working with main effects only. </span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>We start by considering what happens when both categorical and continuous predictors are used together in a multiple regression model. We use this combination of predictors as bridge from the previous chapter and as a way of digging into the math behind interactions. Later sections will consider what happens when we have interactions between two continuous predictors, or two categorical predictors.</span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-26"><a href="#cb88-26" aria-hidden="true" tabindex="-1"></a>It might be helpful to mention that this chapter gets pretty complicated and is very long (sorry!). It is definitely the hardest material we have covered so far, because we are drawing on everything we have done up to now and adding even more stuff into the mix. So, if these readings feel daunting at moments, that is to be expected. You might consider taking a break and doing the readings in smaller chunks. Also keep in mind that we are going to discuss all of this in class together, so just get what you can from these notes, provide some initial responses to the Workbook questions, and press on. This is where regression starts to get really interesting -- you got this! </span>
<span id="cb88-27"><a href="#cb88-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-28"><a href="#cb88-28" aria-hidden="true" tabindex="-1"></a><span class="fu">## An example from NELS {#sec-example-5}</span></span>
<span id="cb88-29"><a href="#cb88-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-30"><a href="#cb88-30" aria-hidden="true" tabindex="-1"></a>For the first few sections of this chapter, we will focus on the gender gap in Math Achievement as our example (e.g., <span class="co">[</span><span class="ot">https://www.nctm.org/Publications/TCM-blog/Blog/Current-Research-on-Gender-Differences-in-Math/</span><span class="co">](https://www.nctm.org/Publications/TCM-blog/Blog/Current-Research-on-Gender-Differences-in-Math/)</span>). The t-test reported below uses the NELS data to illustrate the gender gap in Math Achievement in 12th grade. The output shows that, on average, males scored about 3.18 percentage points higher than females on a Grade 12 Math test. This gap isn't very big. However, it tends to grow rather than get smaller as students progress to higher grades, and it has implications for gender equality in STEM education and STEM professions. </span>
<span id="cb88-31"><a href="#cb88-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-32"><a href="#cb88-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-35"><a href="#cb88-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-36"><a href="#cb88-36" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"NELS.RData"</span>)</span>
<span id="cb88-37"><a href="#cb88-37" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(NELS)</span>
<span id="cb88-38"><a href="#cb88-38" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(achmat12 <span class="sc">~</span> gender, <span class="at">var.equal =</span> T)</span>
<span id="cb88-39"><a href="#cb88-39" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-40"><a href="#cb88-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-41"><a href="#cb88-41" aria-hidden="true" tabindex="-1"></a>In this chapter, our goal is to use linear regression to better understand the gender gap in Math Achievement. To help us do this, we will also consider a third variable, Reading Achievement. The plot below shows the relationship between Math Achievement and Reading Achievement estimated just for males (Blue), and the same relationship estimated just for females (Black). </span>
<span id="cb88-42"><a href="#cb88-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-43"><a href="#cb88-43" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-math-reading-1, fig.cap = 'Math Achievement, Reading Achievement, and Gender.', fig.align = 'center'}</span></span>
<span id="cb88-44"><a href="#cb88-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Create indicators for females and males</span></span>
<span id="cb88-45"><a href="#cb88-45" aria-hidden="true" tabindex="-1"></a>females <span class="ot">&lt;-</span> gender <span class="sc">==</span> <span class="st">"Female"</span></span>
<span id="cb88-46"><a href="#cb88-46" aria-hidden="true" tabindex="-1"></a>males <span class="ot">&lt;-</span> gender <span class="sc">==</span> <span class="st">"Male"</span></span>
<span id="cb88-47"><a href="#cb88-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-48"><a href="#cb88-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Regress math on reading, for each group separately</span></span>
<span id="cb88-49"><a href="#cb88-49" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[females] <span class="sc">~</span> achrdg12[females])</span>
<span id="cb88-50"><a href="#cb88-50" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[males] <span class="sc">~</span> achrdg12[males])</span>
<span id="cb88-51"><a href="#cb88-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-52"><a href="#cb88-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb88-53"><a href="#cb88-53" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb88-54"><a href="#cb88-54" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb88-55"><a href="#cb88-55" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb88-56"><a href="#cb88-56" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb88-57"><a href="#cb88-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-58"><a href="#cb88-58" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod1, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-59"><a href="#cb88-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-60"><a href="#cb88-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Add again for males</span></span>
<span id="cb88-61"><a href="#cb88-61" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb88-62"><a href="#cb88-62" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb88-63"><a href="#cb88-63" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb88-64"><a href="#cb88-64" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb88-65"><a href="#cb88-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-66"><a href="#cb88-66" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-67"><a href="#cb88-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-68"><a href="#cb88-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb88-69"><a href="#cb88-69" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb88-70"><a href="#cb88-70" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb88-71"><a href="#cb88-71" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb88-72"><a href="#cb88-72" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span>
<span id="cb88-73"><a href="#cb88-73" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-74"><a href="#cb88-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-75"><a href="#cb88-75" aria-hidden="true" tabindex="-1"></a>**Please take a minute to think about what this plot is telling us about the relationships among the three variables. In particular: **</span>
<span id="cb88-76"><a href="#cb88-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-77"><a href="#cb88-77" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Does the gender gap in Math Achievement change as a function of Reading Achievement?**  </span>
<span id="cb88-78"><a href="#cb88-78" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Is the relationship between Math Achievement and Reading Achievement the the same for males and females?**</span>
<span id="cb88-79"><a href="#cb88-79" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**What do the results mean for gender equality in Math and STEM education?**</span>
<span id="cb88-80"><a href="#cb88-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-81"><a href="#cb88-81" aria-hidden="true" tabindex="-1"></a>Note that in @fig-math-reading-1, we estimated two separate simple regression models, one just for males and one just for females. In the next few sections, we will work our way towards a single multiple regression model that can be used to represent the relationships among these three variables.  </span>
<span id="cb88-82"><a href="#cb88-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-83"><a href="#cb88-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-84"><a href="#cb88-84" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binary + continuous {#sec-binary-continuous-5}</span></span>
<span id="cb88-85"><a href="#cb88-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-86"><a href="#cb88-86" aria-hidden="true" tabindex="-1"></a>Let's start by considering what happens when we include both Gender and Reading Achievement as predictors of Math Achievement in our usual multiple regression equation: </span>
<span id="cb88-87"><a href="#cb88-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-88"><a href="#cb88-88" aria-hidden="true" tabindex="-1"></a>$$\widehat Y = b_0 + b_1X_1 + b_2 X_2$$ {#eq-yhat-5a}</span>
<span id="cb88-89"><a href="#cb88-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-90"><a href="#cb88-90" aria-hidden="true" tabindex="-1"></a>where</span>
<span id="cb88-91"><a href="#cb88-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-92"><a href="#cb88-92" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$Y$ is Math Achievement in grade 12</span>
<span id="cb88-93"><a href="#cb88-93" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X_1$ is Reading Achievement in grade 12</span>
<span id="cb88-94"><a href="#cb88-94" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X_2$ is Gender (binary, with female = 0 and male = 1)</span>
<span id="cb88-95"><a href="#cb88-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-96"><a href="#cb88-96" aria-hidden="true" tabindex="-1"></a>Note that this model does **not** include an interaction between the two predictors -- we are first going to consider what is "missing" from the usual regression model, and then use this to motivate inclusion of another predictor that represents the interaction. To get an initial sense of what is missing, the model in @eq-yhat-5a is plotted in @fig-math-reading-2 using the NELS data -- can you spot the difference with @fig-math-reading-1? </span>
<span id="cb88-97"><a href="#cb88-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-98"><a href="#cb88-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-99"><a href="#cb88-99" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-math-reading-2, fig.cap = 'Math Achievement, Reading Achievement, and Gender (No Interaction).', fig.align = 'center'}</span></span>
<span id="cb88-100"><a href="#cb88-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-101"><a href="#cb88-101" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the regression</span></span>
<span id="cb88-102"><a href="#cb88-102" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender, <span class="at">data =</span> NELS)</span>
<span id="cb88-103"><a href="#cb88-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-104"><a href="#cb88-104" aria-hidden="true" tabindex="-1"></a>a_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod3)[<span class="dv">1</span>]</span>
<span id="cb88-105"><a href="#cb88-105" aria-hidden="true" tabindex="-1"></a>b_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod3)[<span class="dv">2</span>]</span>
<span id="cb88-106"><a href="#cb88-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-107"><a href="#cb88-107" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the slope and intercept for males</span></span>
<span id="cb88-108"><a href="#cb88-108" aria-hidden="true" tabindex="-1"></a>a_males <span class="ot">&lt;-</span> a_females <span class="sc">+</span> <span class="fu">coef</span>(mod3)[<span class="dv">3</span>]</span>
<span id="cb88-109"><a href="#cb88-109" aria-hidden="true" tabindex="-1"></a>b_males <span class="ot">&lt;-</span> b_females </span>
<span id="cb88-110"><a href="#cb88-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-111"><a href="#cb88-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb88-112"><a href="#cb88-112" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb88-113"><a href="#cb88-113" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb88-114"><a href="#cb88-114" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb88-115"><a href="#cb88-115" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb88-116"><a href="#cb88-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-117"><a href="#cb88-117" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_females, b_females, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-118"><a href="#cb88-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-119"><a href="#cb88-119" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb88-120"><a href="#cb88-120" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb88-121"><a href="#cb88-121" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb88-122"><a href="#cb88-122" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb88-123"><a href="#cb88-123" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb88-124"><a href="#cb88-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-125"><a href="#cb88-125" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_males, b_males, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-126"><a href="#cb88-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-127"><a href="#cb88-127" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb88-128"><a href="#cb88-128" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb88-129"><a href="#cb88-129" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb88-130"><a href="#cb88-130" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb88-131"><a href="#cb88-131" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span>
<span id="cb88-132"><a href="#cb88-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-133"><a href="#cb88-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-134"><a href="#cb88-134" aria-hidden="true" tabindex="-1"></a>In order to interpret our multiple regression model, we can use the same overall approach as we used to interpret categorical predictors in @sec-chap-4. If we plug-in values for the categorical predictor, we get: </span>
<span id="cb88-135"><a href="#cb88-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-136"><a href="#cb88-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb88-137"><a href="#cb88-137" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-138"><a href="#cb88-138" aria-hidden="true" tabindex="-1"></a>\text{Simple trend for females:   } \widehat Y (Female) &amp; = b_0 + b_1X_1 + b_2 (0) <span class="sc">\\</span> &amp; = b_0 + b_1X_1</span>
<span id="cb88-139"><a href="#cb88-139" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-140"><a href="#cb88-140" aria-hidden="true" tabindex="-1"></a>$$ {#eq-females1-5}</span>
<span id="cb88-141"><a href="#cb88-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-142"><a href="#cb88-142" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb88-143"><a href="#cb88-143" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-144"><a href="#cb88-144" aria-hidden="true" tabindex="-1"></a>\text{Simple trend for males:   } \widehat Y (Male) &amp; = b_0 + b_1X_1 + b_2 (1) <span class="sc">\\</span> &amp; = (b_0 + b_2) + b_1 X_1</span>
<span id="cb88-145"><a href="#cb88-145" aria-hidden="true" tabindex="-1"></a>\end{align} </span>
<span id="cb88-146"><a href="#cb88-146" aria-hidden="true" tabindex="-1"></a>$$ {#eq-males1-5}</span>
<span id="cb88-147"><a href="#cb88-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-148"><a href="#cb88-148" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb88-149"><a href="#cb88-149" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-150"><a href="#cb88-150" aria-hidden="true" tabindex="-1"></a>\text{Predicted gender gap:   } \widehat Y (Male) - \widehat Y (Female) &amp; = b_2</span>
<span id="cb88-151"><a href="#cb88-151" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-152"><a href="#cb88-152" aria-hidden="true" tabindex="-1"></a>$$ {#eq-gap1-5}</span>
<span id="cb88-153"><a href="#cb88-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-154"><a href="#cb88-154" aria-hidden="true" tabindex="-1"></a>The equations for $\widehat Y (Female)$ and $\widehat Y (Male)$ are referred to as *simple trends* or *simple slopes*. These describe the regression of Math on Reading, simply for females, or simply for males. The difference between the two simple regression equations is the predicted gender gap in Math Achievement. </span>
<span id="cb88-155"><a href="#cb88-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-156"><a href="#cb88-156" aria-hidden="true" tabindex="-1"></a>Based on these equations we can interpret regression coefficients as follows</span>
<span id="cb88-157"><a href="#cb88-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-158"><a href="#cb88-158" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression intercept, $b_0$, is the intercept of the simple trend for the group coded "0" (i.e., the intercept of the regression of Math on Reading, simply for females; see @eq-females1-5). </span>
<span id="cb88-159"><a href="#cb88-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-160"><a href="#cb88-160" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression slope for the continuous predictor, $b_1$, is the slope of both of the simple trends (see @eq-females1-5 and @eq-males1-5)  </span>
<span id="cb88-161"><a href="#cb88-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-162"><a href="#cb88-162" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression slope for the binary predictor, $b_2$, is the difference between the intercepts of the simple trends (i.e., we add $b_2$ to $b_0$ to get the intercept of the regression of Math on Reading, simply for males; see @eq-males1-5). </span>
<span id="cb88-163"><a href="#cb88-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-164"><a href="#cb88-164" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>In this model, $b_2$ is the also the predicted gender gap in Math Achievement (see @eq-gap1-5).</span>
<span id="cb88-165"><a href="#cb88-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-166"><a href="#cb88-166" aria-hidden="true" tabindex="-1"></a>The regression coefficients for the example data are shown below. **Please use these numbers to provide an interpretation of the simple trends and the gender gap in Math Achievement for the NELS example. (Don't worry about statistical significance, just focus on the meaning of the coefficients reported in the "Estimate" column.)** </span>
<span id="cb88-167"><a href="#cb88-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-170"><a href="#cb88-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-171"><a href="#cb88-171" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span>
<span id="cb88-172"><a href="#cb88-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-173"><a href="#cb88-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-174"><a href="#cb88-174" aria-hidden="true" tabindex="-1"></a>Here is an example to help you get started: </span>
<span id="cb88-175"><a href="#cb88-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-176"><a href="#cb88-176" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simply for females, the regression of Math Achievement on Reading Achievement has an intercept equal to 19.98 and a slope equal to 0.64. The intercept tells us that a female student with Reading Achievement score of 0% is expected to have a Math Achievement score of 19.98% (the units of the two tests are percent correct). Since the lowest value of Reading Achievement in our example is about 35%, the intercept is not very meaningful for these data. The regression slope tells us that, for females, a 1 unit increase in Reading Achievement is associated with a .64 unit increase in Math Achievement. </span>
<span id="cb88-177"><a href="#cb88-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-178"><a href="#cb88-178" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simply for males, .... </span>
<span id="cb88-179"><a href="#cb88-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-180"><a href="#cb88-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-181"><a href="#cb88-181" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The gender gap in Math Achievement was equal to ... </span>
<span id="cb88-182"><a href="#cb88-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-183"><a href="#cb88-183" aria-hidden="true" tabindex="-1"></a><span class="fu">### Marginal means</span></span>
<span id="cb88-184"><a href="#cb88-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-185"><a href="#cb88-185" aria-hidden="true" tabindex="-1"></a>Before moving on to consider interactions, let's revisit a topic from the previous chapter. In @sec-chap-4, we noted that the regression coefficients for categorical predictors (dummy variables) can be interpreted in terms of the group means of the outcome variable. However, when additional predictors are included in the regression model, this interpretation no longer holds. This section explains why.  </span>
<span id="cb88-186"><a href="#cb88-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-187"><a href="#cb88-187" aria-hidden="true" tabindex="-1"></a>To see what the issue is, let's compare the output of the t-test in @sec-example-5 with the regression output shown above. In the t-test, the mean Math Achievement for females was 55.47, and for males it was 58.63. The mean difference was</span>
<span id="cb88-188"><a href="#cb88-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-189"><a href="#cb88-189" aria-hidden="true" tabindex="-1"></a>$$58.63 - 55.47 = 3.16$$</span>
<span id="cb88-190"><a href="#cb88-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-191"><a href="#cb88-191" aria-hidden="true" tabindex="-1"></a>However, the regression coefficient on Gender in the multiple regression model above is equal to $3.50$. Thus, unlike @sec-chap-4, the regression coefficient on Gender is no longer equal to the group-mean difference in Math Achievement. But why?  </span>
<span id="cb88-192"><a href="#cb88-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-193"><a href="#cb88-193" aria-hidden="true" tabindex="-1"></a>Remember that in the multiple regression model, the regression coefficient on Gender is interpreted as the relationship between Math Achievement and Gender, *holding Reading Achievement constant*. So, the regression coefficient on Gender is still interpreted as a mean difference, but now it is a *predicted* mean difference that represents the gender gap in Math Achievement after controlling for Reading Achievement. The t-test doesn't control for Reading.</span>
<span id="cb88-194"><a href="#cb88-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-195"><a href="#cb88-195" aria-hidden="true" tabindex="-1"></a>In order to emphasize the distinction between "raw" group means computed from the data and the predicted group means obtained from a multiple regression model, the latter are referred to as *marginal means*, or sometimes as *adjusted means* or *least squares means*. I think they should be called *predicted means*, but, alas. </span>
<span id="cb88-196"><a href="#cb88-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-197"><a href="#cb88-197" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary </span></span>
<span id="cb88-198"><a href="#cb88-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-199"><a href="#cb88-199" aria-hidden="true" tabindex="-1"></a>In a regression model with one continuous predictor and one binary predictor (and no interaction):  </span>
<span id="cb88-200"><a href="#cb88-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-201"><a href="#cb88-201" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The model results in two regression lines, one for each value of the binary predictor. These are called the simple trends.</span>
<span id="cb88-202"><a href="#cb88-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-203"><a href="#cb88-203" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The simple trends are parallel but can have different intercepts; the difference between the intercepts is equal to regression coefficient of the binary variable. </span>
<span id="cb88-204"><a href="#cb88-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-205"><a href="#cb88-205" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The difference between the simple trends is often called a "gap", and the gap is also equal to the regression coefficient of the binary variable. </span>
<span id="cb88-206"><a href="#cb88-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-207"><a href="#cb88-207" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It is important to note that the predicted group means for the binary variable are no longer equal to the "raw" group means computed directly from the data, because the predicted group means  control for the correlation between the predictors. The predicted group means are called marginal means to emphasize this distinction. </span>
<span id="cb88-208"><a href="#cb88-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-209"><a href="#cb88-209" aria-hidden="true" tabindex="-1"></a>Keep in mind that this summary applies to the multiple regression model **without an interaction**. In the next section we improve our model by adding an interaction.  </span>
<span id="cb88-210"><a href="#cb88-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-211"><a href="#cb88-211" aria-hidden="true" tabindex="-1"></a><span class="fu">## Binary + continuous + interaction {#sec-binary-continuous-interaction-5}</span></span>
<span id="cb88-212"><a href="#cb88-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-213"><a href="#cb88-213" aria-hidden="true" tabindex="-1"></a>In this section, we discuss what was missing from the multiple regression model in the previous section: The interaction between Gender and Reading. </span>
<span id="cb88-214"><a href="#cb88-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-215"><a href="#cb88-215" aria-hidden="true" tabindex="-1"></a>Mathematically, an interaction is just the product between two variables. @eq-yhat-5b shows how to include this product in our multiple regression model -- we just take the product of the two predictors and add it into the model as a third predictor:</span>
<span id="cb88-216"><a href="#cb88-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-217"><a href="#cb88-217" aria-hidden="true" tabindex="-1"></a>$$\hat Y = b_0 + b_1X_1 + b_2 X_2 + b_3 (X_1 \times X_2). $${#eq-yhat-5b}</span>
<span id="cb88-218"><a href="#cb88-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-219"><a href="#cb88-219" aria-hidden="true" tabindex="-1"></a>In terms of computation, we would literally take the product of our two predictors and save it as a new variable in our data set, then add the new variable in to the regression model. In practice, R will do all of this for us behind the scenes, so we don't actually need to "hard code" new variables. </span>
<span id="cb88-220"><a href="#cb88-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-221"><a href="#cb88-221" aria-hidden="true" tabindex="-1"></a>For the NELS example, the regression model with the interaction is depicted in @fig-math-reading-3. Note the the simple trends are no longer parallel and the regression lines agree exactly with what we had in @sec-example-5. So, as promised, we have now arrived at a single multiple regression model that captures the relationships among Math Achievement, Reading Achievement, and Gender.</span>
<span id="cb88-222"><a href="#cb88-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-223"><a href="#cb88-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-224"><a href="#cb88-224" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-math-reading-3, fig.cap = 'Math Achievement, Reading Achievement, and Gender (No Interaction).', fig.align = 'center'}</span></span>
<span id="cb88-225"><a href="#cb88-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-226"><a href="#cb88-226" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via hard coding</span></span>
<span id="cb88-227"><a href="#cb88-227" aria-hidden="true" tabindex="-1"></a>genderXachrdg12 <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb88-228"><a href="#cb88-228" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXachrdg12)</span>
<span id="cb88-229"><a href="#cb88-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-230"><a href="#cb88-230" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for females</span></span>
<span id="cb88-231"><a href="#cb88-231" aria-hidden="true" tabindex="-1"></a>a_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod4)[<span class="dv">1</span>]</span>
<span id="cb88-232"><a href="#cb88-232" aria-hidden="true" tabindex="-1"></a>b_females <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod4)[<span class="dv">2</span>]</span>
<span id="cb88-233"><a href="#cb88-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-234"><a href="#cb88-234" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the coefficients for males</span></span>
<span id="cb88-235"><a href="#cb88-235" aria-hidden="true" tabindex="-1"></a>a_males <span class="ot">&lt;-</span> a_females <span class="sc">+</span> <span class="fu">coef</span>(mod4)[<span class="dv">3</span>]</span>
<span id="cb88-236"><a href="#cb88-236" aria-hidden="true" tabindex="-1"></a>b_males <span class="ot">&lt;-</span> b_females <span class="sc">+</span> <span class="fu">coef</span>(mod4)[<span class="dv">4</span>]</span>
<span id="cb88-237"><a href="#cb88-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-238"><a href="#cb88-238" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb88-239"><a href="#cb88-239" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb88-240"><a href="#cb88-240" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb88-241"><a href="#cb88-241" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb88-242"><a href="#cb88-242" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb88-243"><a href="#cb88-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-244"><a href="#cb88-244" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_females, b_females, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-245"><a href="#cb88-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-246"><a href="#cb88-246" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb88-247"><a href="#cb88-247" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb88-248"><a href="#cb88-248" aria-hidden="true" tabindex="-1"></a>       achmat12[males],</span>
<span id="cb88-249"><a href="#cb88-249" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb88-250"><a href="#cb88-250" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb88-251"><a href="#cb88-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-252"><a href="#cb88-252" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(a_males, b_males, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-253"><a href="#cb88-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-254"><a href="#cb88-254" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb88-255"><a href="#cb88-255" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>,</span>
<span id="cb88-256"><a href="#cb88-256" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender), </span>
<span id="cb88-257"><a href="#cb88-257" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb88-258"><a href="#cb88-258" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span>
<span id="cb88-259"><a href="#cb88-259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-260"><a href="#cb88-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-261"><a href="#cb88-261" aria-hidden="true" tabindex="-1"></a>To see how to interpret the coefficients in this model, let's work through the model equations using our two-step procedure. As before, we first plug-in values for the categorical predictor, then we use the resulting equations solve for the simple trends and the gender gap in Math. </span>
<span id="cb88-262"><a href="#cb88-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-263"><a href="#cb88-263" aria-hidden="true" tabindex="-1"></a>$$\begin{align}</span>
<span id="cb88-264"><a href="#cb88-264" aria-hidden="true" tabindex="-1"></a>\widehat Y (Female) &amp; = b_0 + b_1X_1 + b_2 (0) + b_3(X_1 \times 0) <span class="sc">\\</span> &amp; = b_0 + b_1X_1</span>
<span id="cb88-265"><a href="#cb88-265" aria-hidden="true" tabindex="-1"></a>\end{align}$$ {#eq-females2-5}</span>
<span id="cb88-266"><a href="#cb88-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-267"><a href="#cb88-267" aria-hidden="true" tabindex="-1"></a>$$\begin{align}</span>
<span id="cb88-268"><a href="#cb88-268" aria-hidden="true" tabindex="-1"></a>\widehat Y (Male) &amp; = b_0 + b_1X_1 + b_2 (1) +  b_3(X_1 \times 1)<span class="sc">\\</span> &amp; = (b_0 + b_2) + (b_1 + b_3) X_1 \end{align}$$ {#eq-males2-5}</span>
<span id="cb88-269"><a href="#cb88-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-270"><a href="#cb88-270" aria-hidden="true" tabindex="-1"></a>$$\begin{align}</span>
<span id="cb88-271"><a href="#cb88-271" aria-hidden="true" tabindex="-1"></a>\widehat Y (Male) - \widehat Y (Female) &amp; = b_2 + b_3 X_1</span>
<span id="cb88-272"><a href="#cb88-272" aria-hidden="true" tabindex="-1"></a>\end{align}$${#eq-gap2-5}</span>
<span id="cb88-273"><a href="#cb88-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-274"><a href="#cb88-274" aria-hidden="true" tabindex="-1"></a>These equations are summarized graphically below in @fig-interactions. </span>
<span id="cb88-275"><a href="#cb88-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-276"><a href="#cb88-276" aria-hidden="true" tabindex="-1"></a><span class="al">![Interaction between a categorical and a continuous predictor. Image credit: Daniela Rodriguez-Mincey, Spring 2023](files/images/Interaction.jpg)</span>{#fig-interactions width=50%}</span>
<span id="cb88-277"><a href="#cb88-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-278"><a href="#cb88-278" aria-hidden="true" tabindex="-1"></a>Based on the equations and figure, we can interpret regression coefficients as follows. Some of these interpretations are the same as in the previous section, but some are different. </span>
<span id="cb88-279"><a href="#cb88-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-280"><a href="#cb88-280" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression intercept, $b_0$, is the intercept of the simple trend for the group coded "0" (i.e., the intercept of the regression of Math on Reading, simply for females; see @eq-females2-5). This is the **same** interpretation as for the model without the interaction discussed in  @sec-binary-continuous-5. </span>
<span id="cb88-281"><a href="#cb88-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-282"><a href="#cb88-282" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression slope for the continuous predictor, $b_1$, is the slope of the simple trend for the group coded "0" (females; see @eq-females2-5). This is **different** from the interpretation of the model in @sec-binary-continuous-5 -- in that model, $b_1$ was the slope of both simple trends, not just the trend for females. </span>
<span id="cb88-283"><a href="#cb88-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-284"><a href="#cb88-284" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression slope for the binary predictor, $b_2$, is the difference between the intercepts of the simple trends (i.e., we add $b_2$ to $b_0$ to get the intercept of the regression of Math on Reading, simply for males; see @eq-males2-5). This is the **same** interpretation as for the model without the interaction discussed in  @sec-binary-continuous-5. </span>
<span id="cb88-285"><a href="#cb88-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-286"><a href="#cb88-286" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression slope for the interaction term (or simply, the interaction), $b_3$, is the difference between the slopes of the simple trends (i.e., we add $b_3$ to $b_1$ to get the slope of the regression of Math on Reading, simply for males; see @eq-males2-5). This is **different** from the interpretation of the model in @sec-binary-continuous-5 -- in that model, $b_1$ was the slope of both simple trends. </span>
<span id="cb88-287"><a href="#cb88-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-288"><a href="#cb88-288" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The difference between the predicted values (i.e., the predicted gender gap in Math Achievement) is no longer constant, but is instead a function of $X_1$ (see @eq-gap2-5). In particular, the predicted gender gap in Math changes by $b_3$ units for each unit of increase in Reading. This is **different** from the interpretation of the model in @sec-binary-continuous-5 -- in that model, the predicted gender gap was constant over Reading and equal to $b_2$. </span>
<span id="cb88-289"><a href="#cb88-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-290"><a href="#cb88-290" aria-hidden="true" tabindex="-1"></a>This last point is especially important in the context of our example. The gender gap in Math Achievement is a function of Reading Achievement. This is the mathematical meaning behind the concept of an interaction -- the relationship between two variables (Math and Gender) is changing as a function of a third variable (Reading). </span>
<span id="cb88-291"><a href="#cb88-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-292"><a href="#cb88-292" aria-hidden="true" tabindex="-1"></a><span class="fu">### Choosing the moderator </span></span>
<span id="cb88-293"><a href="#cb88-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-294"><a href="#cb88-294" aria-hidden="true" tabindex="-1"></a>Interpreting interactions can feel a bit unwieldy at first. This section introduces some additional terminology that helps better align the mathematical results with the kinds of research scenarios we considered in the introduction to this chapter. </span>
<span id="cb88-295"><a href="#cb88-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-296"><a href="#cb88-296" aria-hidden="true" tabindex="-1"></a>First, note that it is equally valid to say </span>
<span id="cb88-297"><a href="#cb88-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-298"><a href="#cb88-298" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>the relationship between Math and Gender depends on Reading, or</span>
<span id="cb88-299"><a href="#cb88-299" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>the relationship between Math and Reading depends on Gender. </span>
<span id="cb88-300"><a href="#cb88-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-301"><a href="#cb88-301" aria-hidden="true" tabindex="-1"></a>In other words, it is equally valid to interpret our interaction in terms of the gender gap (i.e., the relationship between Math and Gender) or in terms of the simple trends (the relationship between Math and Reading). </span>
<span id="cb88-302"><a href="#cb88-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-303"><a href="#cb88-303" aria-hidden="true" tabindex="-1"></a>Although both interpretations are equally valid, in most research settings we will be more interested in one of them rather than the other. For example, our research interest in @sec-example-5 was about the gender gap in Math Achievement. So, we can simplify our lives by focusing the gender gap (i.e., the relationship between Math and Gender). For the purpose of our example, the simple trends are an equivalent but less interesting way of interpreting the interaction. The point is: we don't have to report both the simple trends and the gender gap -- we usually just choose one. </span>
<span id="cb88-304"><a href="#cb88-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-305"><a href="#cb88-305" aria-hidden="true" tabindex="-1"></a>In the two bullet points above, whichever variable appears in the "depends on" clause is called the *moderator*, and the other two variables are called the focal variables. The researcher chooses which variable to treat as the moderator when interpreting an interaction. The overall idea here is to "break down" the interaction in the way that is most compatible with your research question(s). </span>
<span id="cb88-306"><a href="#cb88-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-307"><a href="#cb88-307" aria-hidden="true" tabindex="-1"></a>Since our focus is the gender gap in Math (i.e., the relationship is between Math and Gender), Reading is our moderator. In particular, we might interpret the interaction as follows</span>
<span id="cb88-308"><a href="#cb88-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-309"><a href="#cb88-309" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The predicted gender gap in Math changes by $b_3$ units for each unit of increase in Reading.  </span>
<span id="cb88-310"><a href="#cb88-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-311"><a href="#cb88-311" aria-hidden="true" tabindex="-1"></a>By contrast, if we were mainly interested in the relationship between Math and Reading (i.e., the simple trends), then we could treat Gender as the moderator. For example, we might say: </span>
<span id="cb88-312"><a href="#cb88-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-313"><a href="#cb88-313" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>For females, predicted Math Achievement changed by $b_1$ units for each unit of increase in Reading, whereas for males, the predicted change was ($b_1 + b_3$) units for each unit of increase in Reading. </span>
<span id="cb88-314"><a href="#cb88-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-315"><a href="#cb88-315" aria-hidden="true" tabindex="-1"></a>The simple trends might feel less intuitive than the gender gap, but the two interpretations are mathematically equivalent. It is just a matter of whether you want to interpret the interaction with reference to the gender gap, or with reference to the simple trends. When writing up your research, you don't need to do both. But I am going to make you do both in the next section for practice. </span>
<span id="cb88-316"><a href="#cb88-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-317"><a href="#cb88-317" aria-hidden="true" tabindex="-1"></a><span class="fu">### Back to the example </span></span>
<span id="cb88-318"><a href="#cb88-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-319"><a href="#cb88-319" aria-hidden="true" tabindex="-1"></a>The regression coefficients for the example data are shown below. **Please use these numbers to provide an interpretation of the interaction between Gender and Reading. For practice, please attempt the interpret the interaction in terms of (a) the gender gap in Math, with Reading as the moderator; and (b) the relationship between Math and Reading, with Gender as the moderator. Don't worry about statistical significance, just focus on the interpreting the coefficients reported in the "Estimate" column.**</span>
<span id="cb88-320"><a href="#cb88-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-323"><a href="#cb88-323" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-324"><a href="#cb88-324" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span>
<span id="cb88-325"><a href="#cb88-325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-326"><a href="#cb88-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-327"><a href="#cb88-327" aria-hidden="true" tabindex="-1"></a>Some potential answers are hidden in the "Code" tab below, but don't peak until you have tried it for yourself!</span>
<span id="cb88-328"><a href="#cb88-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-331"><a href="#cb88-331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-332"><a href="#cb88-332" aria-hidden="true" tabindex="-1"></a><span class="co"># Gender gap</span></span>
<span id="cb88-333"><a href="#cb88-333" aria-hidden="true" tabindex="-1"></a><span class="co"># General: The gender gap in Math is smaller for students who are also strong in Reading</span></span>
<span id="cb88-334"><a href="#cb88-334" aria-hidden="true" tabindex="-1"></a><span class="co"># Specific: The gender gap in Math Achievement decreases by .18 percentage points for each percentage point increase Reading Achievement</span></span>
<span id="cb88-335"><a href="#cb88-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-336"><a href="#cb88-336" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple slopes</span></span>
<span id="cb88-337"><a href="#cb88-337" aria-hidden="true" tabindex="-1"></a><span class="co"># General: The relationship between Math and Reading is stronger (i.e. has a larger slope) for females than for males</span></span>
<span id="cb88-338"><a href="#cb88-338" aria-hidden="true" tabindex="-1"></a><span class="co"># Specific:</span></span>
<span id="cb88-339"><a href="#cb88-339" aria-hidden="true" tabindex="-1"></a><span class="co">#  For females, Math scores are predicted to increase by .72 percentage points for each percentage point increase in Reading Achievement</span></span>
<span id="cb88-340"><a href="#cb88-340" aria-hidden="true" tabindex="-1"></a><span class="co">#  For males, Math scores are predicted to increase by .55 percentage points for each percentage point increase in Reading Achievement</span></span>
<span id="cb88-341"><a href="#cb88-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-342"><a href="#cb88-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-343"><a href="#cb88-343" aria-hidden="true" tabindex="-1"></a><span class="fu">### Centering the continuous predictor</span></span>
<span id="cb88-344"><a href="#cb88-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-345"><a href="#cb88-345" aria-hidden="true" tabindex="-1"></a>You may have noticed that the regression coefficient on Gender was wildly different in regression models with and without the interaction. In the model without the interaction (@sec-binary-continuous-5) the coefficient on Gender was 3.50, and in the model with the interaction (above), it was 13.40. So in one model, the "effect" of being male was a 3.5 percentage point gain on a Math test, but in the other model, it was a 13.40 percentage point gain. Why this huge difference in the "effect" of Gender? </span>
<span id="cb88-346"><a href="#cb88-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-347"><a href="#cb88-347" aria-hidden="true" tabindex="-1"></a>The answer can be seen in the equation for the gender gap. In the model **without the interaction**, the gender gap was constant and equal to the regression coefficient on Gender (denoted as $b_2$ in the model): </span>
<span id="cb88-348"><a href="#cb88-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-349"><a href="#cb88-349" aria-hidden="true" tabindex="-1"></a>$$\widehat Y (Male) - \widehat Y (Female) = b_2. $$</span>
<span id="cb88-350"><a href="#cb88-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-351"><a href="#cb88-351" aria-hidden="true" tabindex="-1"></a>But in the regression model **with the interaction**, the gender gap was a linear function of Reading and the regression coefficient on Gender is the intercept of that linear relationship. </span>
<span id="cb88-352"><a href="#cb88-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-353"><a href="#cb88-353" aria-hidden="true" tabindex="-1"></a>$$ \widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 X_1. $$</span>
<span id="cb88-354"><a href="#cb88-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-355"><a href="#cb88-355" aria-hidden="true" tabindex="-1"></a>This equation tell us that, in the model with the interaction, $b_2$ is the gender gap for students who score 0% on the Reading test. Since the lowest score on Reading was around 35%, the intercept in this equation (i.e., $b_2$, the regression coefficient on Gender) is not very meaningful. </span>
<span id="cb88-356"><a href="#cb88-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-357"><a href="#cb88-357" aria-hidden="true" tabindex="-1"></a>In previous sections, we have ignored the regression intercept when it was not meaningful. But, ignoring the regression slopes for predictor variables can get confusing, and, in general, it is nice for the regression coefficients to be interpretable (otherwise, why are we doing this!).  </span>
<span id="cb88-358"><a href="#cb88-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-359"><a href="#cb88-359" aria-hidden="true" tabindex="-1"></a>One way to address this situation is to center Reading Achievement so that it has a mean of zero. To do this, we compute the deviation score</span>
<span id="cb88-360"><a href="#cb88-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-361"><a href="#cb88-361" aria-hidden="true" tabindex="-1"></a>$$D_1 = X_1 - \bar X_1.$$</span>
<span id="cb88-362"><a href="#cb88-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-363"><a href="#cb88-363" aria-hidden="true" tabindex="-1"></a>$D_1$ is the mean-centered version of $X_1$ (Reading Achievement). If we regress Math Achievement on $D_1$ rather than $X_1$ we end up with the following equation for the gender gap in Math: </span>
<span id="cb88-364"><a href="#cb88-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-365"><a href="#cb88-365" aria-hidden="true" tabindex="-1"></a>$$\widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 D_1$$ </span>
<span id="cb88-366"><a href="#cb88-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-367"><a href="#cb88-367" aria-hidden="true" tabindex="-1"></a>Since $D_1 = 0$ when $X_1 = \bar X_1$, the regression coefficient on Gender ($b_2$) is now interpretable as the gender gap in Math Achievement, for students with average Reading Achievement. This is a much more interpretable number than the coefficient in the original interaction model! </span>
<span id="cb88-368"><a href="#cb88-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-369"><a href="#cb88-369" aria-hidden="true" tabindex="-1"></a>Using the example data, this approach yields the following regression coefficients (the <span class="in">`_dev`</span> notation means the variable was centered): </span>
<span id="cb88-370"><a href="#cb88-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-373"><a href="#cb88-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-374"><a href="#cb88-374" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the deviation scores for reading</span></span>
<span id="cb88-375"><a href="#cb88-375" aria-hidden="true" tabindex="-1"></a>reading_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12, <span class="at">na.rm =</span> T) </span>
<span id="cb88-376"><a href="#cb88-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-377"><a href="#cb88-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the interaction model as above</span></span>
<span id="cb88-378"><a href="#cb88-378" aria-hidden="true" tabindex="-1"></a>genderXreading_dev <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> reading_dev</span>
<span id="cb88-379"><a href="#cb88-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-380"><a href="#cb88-380" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> reading_dev <span class="sc">+</span> gender <span class="sc">+</span> genderXreading_dev)</span>
<span id="cb88-381"><a href="#cb88-381" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod5)</span>
<span id="cb88-382"><a href="#cb88-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-383"><a href="#cb88-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-384"><a href="#cb88-384" aria-hidden="true" tabindex="-1"></a>The regression coefficient for Gender is now pretty close to what it was in the multiple regression model without the interaction, but the interpretation is different (i.e., it is now the predicted gender gap in Math for students with an average level of Reading, rather than the predicted gender gap in Math for all students). </span>
<span id="cb88-385"><a href="#cb88-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-386"><a href="#cb88-386" aria-hidden="true" tabindex="-1"></a>Notice that the intercept in the model above has also changed compared to the previous model in which Reading was not centered. This is should make sense based on what you already know about the regression intercept. </span>
<span id="cb88-387"><a href="#cb88-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-388"><a href="#cb88-388" aria-hidden="true" tabindex="-1"></a>Also note that centering Reading did not affect the regression coefficient for Reading or the interaction. So, centering makes the regression slope on Gender more interpretable, but it doesn't affect our overall interpretation of the simple trends or the gender gap. To learn more about how centering works, see @sec-how-centering-works-5 (which is optional). </span>
<span id="cb88-389"><a href="#cb88-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-390"><a href="#cb88-390" aria-hidden="true" tabindex="-1"></a>**Please write down your interpretation of the intercept and the regression coefficient on Gender in the above regression output, and be prepared to share your answer in class**. </span>
<span id="cb88-391"><a href="#cb88-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-392"><a href="#cb88-392" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb88-393"><a href="#cb88-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-394"><a href="#cb88-394" aria-hidden="true" tabindex="-1"></a>The interaction between two variables is just their product. When this product is added as a predictor in a multiple regression model with one continuous and one binary predictor:</span>
<span id="cb88-395"><a href="#cb88-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-396"><a href="#cb88-396" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The model again results in two regression lines (simple trends), one for each value of the binary predictor.</span>
<span id="cb88-397"><a href="#cb88-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-398"><a href="#cb88-398" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>However, the simple trends can now have different intercepts *and different slopes*. The difference in slopes is equal to the regression coefficient on the interaction term. In other words, the simple trends have different slopes because of the interaction. </span>
<span id="cb88-399"><a href="#cb88-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-400"><a href="#cb88-400" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The difference (“gap”) between the regression lines changes as a linear function of the continuous predictor, and the slope of this linear function is again equal to the regression coefficient on the interaction term.</span>
<span id="cb88-401"><a href="#cb88-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-402"><a href="#cb88-402" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The last two points are equivalent ways of stating the central idea behind a (two-way) interaction: the relationship between two variables changes as a function of a third variable.</span>
<span id="cb88-403"><a href="#cb88-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-404"><a href="#cb88-404" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When interpreting an interaction, the researcher chooses which pair of variables will be the "focal relationship" and which variable will be the moderator. </span>
<span id="cb88-405"><a href="#cb88-405" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>In our example, we focused on the gender gap in Math (i.e., the relationship between Math and Gender) and Reading was the moderator. </span>
<span id="cb88-406"><a href="#cb88-406" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>But, if we were more interested in the relationship between Math and Reading, would could have focused on the simple trends and treated Gender as the moderator.</span>
<span id="cb88-407"><a href="#cb88-407" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>It is usual to only report one way of these two ways of "breaking down" the interaction -- the one that is most relevant to your research question. </span>
<span id="cb88-408"><a href="#cb88-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-409"><a href="#cb88-409" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Centering the continuous predictor can be helpful for ensuring that the regression coefficient on the binary predictor remains interpretable in the presence of an interaction. </span>
<span id="cb88-410"><a href="#cb88-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-411"><a href="#cb88-411" aria-hidden="true" tabindex="-1"></a><span class="fu">## Following-up an interaction {#sec-inference-for-interactions-5}</span></span>
<span id="cb88-412"><a href="#cb88-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-413"><a href="#cb88-413" aria-hidden="true" tabindex="-1"></a>The procedures discussed in this section are used typically used *after* we have concluded that there is a statistically significant between two predictors (i.e., after we have examined the `summary(lm)` output in the previous section). When we follow-up an interaction, the goal is to gain a better understanding of *how* the focal relationship depends on the moderator. Basically, the <span class="in">`summary(lm)`</span> output from the previous section tells us whether or not the interaction is significant, and, if it is significant, the procedures discussed in this section let us describe the interaction in more detail. </span>
<span id="cb88-414"><a href="#cb88-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-415"><a href="#cb88-415" aria-hidden="true" tabindex="-1"></a>The overall idea is illustrated @fig-visreg-1. Compared to the plots we have seen previously in this chapter, @fig-visreg-1 now includes confidence bands for the simple trends. The confidence bands show the values of Reading for which the gender gap in Math is statistically significant. In particular, it appears that the gap is not significant for students at the highest levels of Reading Achievement. </span>
<span id="cb88-416"><a href="#cb88-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-417"><a href="#cb88-417" aria-hidden="true" tabindex="-1"></a>Note that this information was not available from the <span class="in">`summary(lm)`</span> output in the previous section. The <span class="in">`summary(lm)`</span> output told us that the interaction term was statistically significant, which means that the gender gap in Math changes as a function of reading. The plot provides more information about *how* the gender gap depends on Reading -- it is statistical significant for students at lower levels of Reading Achievement, but appears to shrink and eventually disappear as Reading Achievement increases. </span>
<span id="cb88-418"><a href="#cb88-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-419"><a href="#cb88-419" aria-hidden="true" tabindex="-1"></a>``<span class="in">`{r fig-visreg-1, fig.cap = 'Example of a plot using the `</span>visreg` package.', fig.align = 'center'}</span>
<span id="cb88-420"><a href="#cb88-420" aria-hidden="true" tabindex="-1"></a><span class="fu"># Install the package if you haven't already done so</span></span>
<span id="cb88-421"><a href="#cb88-421" aria-hidden="true" tabindex="-1"></a><span class="fu"># install.packages("visreg")</span></span>
<span id="cb88-422"><a href="#cb88-422" aria-hidden="true" tabindex="-1"></a><span class="fu"># Load the package into memory</span></span>
<span id="cb88-423"><a href="#cb88-423" aria-hidden="true" tabindex="-1"></a>library(visreg)</span>
<span id="cb88-424"><a href="#cb88-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-425"><a href="#cb88-425" aria-hidden="true" tabindex="-1"></a><span class="fu"># Run the regression model using R's syntax for interactions "*"</span></span>
<span id="cb88-426"><a href="#cb88-426" aria-hidden="true" tabindex="-1"></a>mod6 &lt;- lm(achmat12 ~ gender*achrdg12, data= NELS)</span>
<span id="cb88-427"><a href="#cb88-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-428"><a href="#cb88-428" aria-hidden="true" tabindex="-1"></a><span class="fu"># One line of code to plot trends with confidence bands :) </span></span>
<span id="cb88-429"><a href="#cb88-429" aria-hidden="true" tabindex="-1"></a>visreg(mod6, xvar = "achrdg12", by = "gender", overlay = TRUE)</span>
<span id="cb88-430"><a href="#cb88-430" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-431"><a href="#cb88-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-432"><a href="#cb88-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-433"><a href="#cb88-433" aria-hidden="true" tabindex="-1"></a><span class="in">In this section, we discuss how to translate the confidence bands in the plot into statistical tests that can provide more specific information about the how the gender gap in Math depends on Reading. Making these kinds of inferences about interactions is one of the main advantages of using multiple regression rather than just fitting the simple trends separately as we did in @sec-example-5. Another advantage is that we can now easily produce nice plots like @fig-visreg-1 :) </span></span>
<span id="cb88-434"><a href="#cb88-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-435"><a href="#cb88-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-436"><a href="#cb88-436" aria-hidden="true" tabindex="-1"></a><span class="in">Before moving on, it is important to emphasize that, if the interaction term in the `summary(lm)` output is **not** significant, we don't use the procedures discussed in this section. This is because a non-significant interaction means that we have inferred the focal relationship *does not* depend on the moderator. Consequently, there is no need to describe this dependence in more detail, which is what the procedures in this section are for. </span></span>
<span id="cb88-437"><a href="#cb88-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-438"><a href="#cb88-438" aria-hidden="true" tabindex="-1"></a><span class="in">### Marginal effects</span></span>
<span id="cb88-439"><a href="#cb88-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-440"><a href="#cb88-440" aria-hidden="true" tabindex="-1"></a><span class="in">Since we are interested in the gender gap in Math Achievement, we will start by considering the values of Reading for which the gap is statistically significant. Note that this information was not available from the standard `summary(lm)` output shown in @sec-binary-continuous-interaction-5 --  the output showed that the regression coefficient representing the interaction was statistically significant, but it didn't tell us for the values of Reading for which the gender gap was statistically significant.  We can answer this type of question using the marginal "effects" discussed in this section. </span></span>
<span id="cb88-441"><a href="#cb88-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-442"><a href="#cb88-442" aria-hidden="true" tabindex="-1"></a><span class="in">There are three main types of marginal effects. For linear models, they are all basically the same, and we will only use one of them in this section. However, it is important that you can distinguish among them, especially when we get into non-linear models (e.g., logistic regression; see @sec-chap-10). In general, when you report marginal effects in your research, you should be able to tell your reader which approach you used so they understand what you did and how to interpret the results.   </span></span>
<span id="cb88-443"><a href="#cb88-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-444"><a href="#cb88-444" aria-hidden="true" tabindex="-1"></a><span class="in">To explain the three approaches, first let's write the gender gap in Math Achievement using a slightly more compact notation ("$\Delta$" for difference):</span></span>
<span id="cb88-445"><a href="#cb88-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-446"><a href="#cb88-446" aria-hidden="true" tabindex="-1"></a><span class="in">$$ \widehat Y (Male) - \widehat Y (Female) = b_2 + b_3 X_1 = \Delta(X_1)$$ </span></span>
<span id="cb88-447"><a href="#cb88-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-448"><a href="#cb88-448" aria-hidden="true" tabindex="-1"></a><span class="in">The three types of marginal effects are: </span></span>
<span id="cb88-449"><a href="#cb88-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-450"><a href="#cb88-450" aria-hidden="true" tabindex="-1"></a><span class="in">* Marginal effects at the mean (MEM): Report the gap at the mean value of $X_1$</span></span>
<span id="cb88-451"><a href="#cb88-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-452"><a href="#cb88-452" aria-hidden="true" tabindex="-1"></a><span class="in">$$MEM =  \Delta(\bar X_1) $$</span></span>
<span id="cb88-453"><a href="#cb88-453" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb88-454"><a href="#cb88-454" aria-hidden="true" tabindex="-1"></a><span class="in"> * Average marginal effect (AVE): Average the effect over values of $X_1$: </span></span>
<span id="cb88-455"><a href="#cb88-455" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb88-456"><a href="#cb88-456" aria-hidden="true" tabindex="-1"></a><span class="in">$$AVE =  \frac{\sum_i \Delta(X_{i1})}{N} $$</span></span>
<span id="cb88-457"><a href="#cb88-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-458"><a href="#cb88-458" aria-hidden="true" tabindex="-1"></a><span class="in">* Marginal effects at representative values (MERV): Report the marginal effect for a range of "interesting values" chosen by the researcher (denoted by *, $\dagger$, etc.)</span></span>
<span id="cb88-459"><a href="#cb88-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-460"><a href="#cb88-460" aria-hidden="true" tabindex="-1"></a><span class="in">$$ MERV =  \{\Delta(X^*_1), \Delta(X^\dagger_1), \dots \} $$ </span></span>
<span id="cb88-461"><a href="#cb88-461" aria-hidden="true" tabindex="-1"></a><span class="in"> </span></span>
<span id="cb88-462"><a href="#cb88-462" aria-hidden="true" tabindex="-1"></a><span class="in">MEM and AVE are equivalent in linear models, but are different for nonlinear models (see @sec-chap-10). The MERV approach also overlaps with MEM and AVE, because usually we choose the mean (or median) as one of the representative values of the predictor. </span></span>
<span id="cb88-463"><a href="#cb88-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-464"><a href="#cb88-464" aria-hidden="true" tabindex="-1"></a><span class="in">In this section we focus on MERV, because it is widely used. One common choice for the "interesting values" is the quartiles of $X_1$, which are reported below for the example data. The output shows the gender gap in Math Achievement for 5 values of Reading Achievement. The values of Reading Achievement are its 5 quartiles. You can think of the output as a tabular summary of @fig-visreg-1.</span></span>
<span id="cb88-465"><a href="#cb88-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-468"><a href="#cb88-468" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-469"><a href="#cb88-469" aria-hidden="true" tabindex="-1"></a><span class="in"># Install the emmeans package if you haven't already done so</span></span>
<span id="cb88-470"><a href="#cb88-470" aria-hidden="true" tabindex="-1"></a><span class="in"># install.packages("emmeans")</span></span>
<span id="cb88-471"><a href="#cb88-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-472"><a href="#cb88-472" aria-hidden="true" tabindex="-1"></a><span class="in"># Load the package into memory</span></span>
<span id="cb88-473"><a href="#cb88-473" aria-hidden="true" tabindex="-1"></a><span class="in">library(emmeans)</span></span>
<span id="cb88-474"><a href="#cb88-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-475"><a href="#cb88-475" aria-hidden="true" tabindex="-1"></a><span class="in"># Fit the model using R's formula syntax for interaction '*'</span></span>
<span id="cb88-476"><a href="#cb88-476" aria-hidden="true" tabindex="-1"></a><span class="in">mod6 &lt;- lm(achmat12 ~ gender*achrdg12, data = NELS)</span></span>
<span id="cb88-477"><a href="#cb88-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-478"><a href="#cb88-478" aria-hidden="true" tabindex="-1"></a><span class="in"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb88-479"><a href="#cb88-479" aria-hidden="true" tabindex="-1"></a><span class="in">gap &lt;- emmeans(mod6, </span></span>
<span id="cb88-480"><a href="#cb88-480" aria-hidden="true" tabindex="-1"></a><span class="in">               specs = "gender",</span></span>
<span id="cb88-481"><a href="#cb88-481" aria-hidden="true" tabindex="-1"></a><span class="in">               by = "achrdg12", </span></span>
<span id="cb88-482"><a href="#cb88-482" aria-hidden="true" tabindex="-1"></a><span class="in">               cov.reduce = quantile)</span></span>
<span id="cb88-483"><a href="#cb88-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-484"><a href="#cb88-484" aria-hidden="true" tabindex="-1"></a><span class="in"># Test whether the differences are significant</span></span>
<span id="cb88-485"><a href="#cb88-485" aria-hidden="true" tabindex="-1"></a><span class="in">contrast(gap, method = "pairwise")</span></span>
<span id="cb88-486"><a href="#cb88-486" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-487"><a href="#cb88-487" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb88-488"><a href="#cb88-488" aria-hidden="true" tabindex="-1"></a>**Please use the output to make a conclusion about the levels of Reading Achievement for which the gender gap was significant. Please be prepared to share your answer in class!**</span>
<span id="cb88-489"><a href="#cb88-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-490"><a href="#cb88-490" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb88-491"><a href="#cb88-491" aria-hidden="true" tabindex="-1"></a>Note that the computations going on "under the hood" when testing marginal effects can get pretty complicated. You can read more details here: <span class="co">[</span><span class="ot">https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html</span><span class="co">](https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html)</span></span>
<span id="cb88-492"><a href="#cb88-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-493"><a href="#cb88-493" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple trends</span></span>
<span id="cb88-494"><a href="#cb88-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-495"><a href="#cb88-495" aria-hidden="true" tabindex="-1"></a>In this section we test whether the slope of each of the simple trends is significantly different from zero. Like the marginal effects in the previous section, this is information was not entirely available in the <span class="in">`summary(lm)`</span> output discussed in @sec-binary-continuous-interaction-5. From the <span class="in">`summary(lm)`</span> output we learned the following two points about the simple trends: </span>
<span id="cb88-496"><a href="#cb88-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-497"><a href="#cb88-497" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression coefficient on Reading told us about the relationship between Math and Reading, simply for the group designated as zero on the binary predictor (simply for  females). </span>
<span id="cb88-498"><a href="#cb88-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-499"><a href="#cb88-499" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression coefficient on the interaction term told us whether the simple trends differ for the two groups (e.g., whether the simple trend for males differs from the simple trend for females). </span>
<span id="cb88-500"><a href="#cb88-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-501"><a href="#cb88-501" aria-hidden="true" tabindex="-1"></a>Note that what is missing, or implicit, is a test of whether the simple trend for males is different from zero. This test is of less relevance to our example (since we are treating Reading as the moderator), but we consider it for illustrative purposes. </span>
<span id="cb88-502"><a href="#cb88-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-503"><a href="#cb88-503" aria-hidden="true" tabindex="-1"></a>The tests of the simple trends for the example data are reported below. As stated, these aren't super interesting in the context of our example, but you should **check your understanding of simple trends by writing down an interpretation of the output below**. </span>
<span id="cb88-504"><a href="#cb88-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-507"><a href="#cb88-507" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-508"><a href="#cb88-508" aria-hidden="true" tabindex="-1"></a><span class="co"># The regression coefficients on reading, broken down by gender</span></span>
<span id="cb88-509"><a href="#cb88-509" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod6, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb88-510"><a href="#cb88-510" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span>
<span id="cb88-511"><a href="#cb88-511" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-512"><a href="#cb88-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-513"><a href="#cb88-513" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb88-514"><a href="#cb88-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-515"><a href="#cb88-515" aria-hidden="true" tabindex="-1"></a>When making inferences about an interaction: </span>
<span id="cb88-516"><a href="#cb88-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-517"><a href="#cb88-517" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the interaction isn't significant in the <span class="in">`summary(lm)`</span> output, we stop there. But if the interaction is significant, we may want to report more information about how the focal relationship depends on the moderator. </span>
<span id="cb88-518"><a href="#cb88-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-519"><a href="#cb88-519" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When the focal predictor is categorical, we can follow-up a significant interaction by taking a closer look at the statistical significance of the marginal effects (e.g, how the gender gap in Math changes as a function of Reading)</span>
<span id="cb88-520"><a href="#cb88-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-521"><a href="#cb88-521" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When the focal predictor is continuous, we can follow-up a significant interaction by taking a closer look at the statistical significance of the simple trends / simple slopes. </span>
<span id="cb88-522"><a href="#cb88-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-523"><a href="#cb88-523" aria-hidden="true" tabindex="-1"></a><span class="fu">## Two continuous predictors {#sec-two-continuous-predictors-5}</span></span>
<span id="cb88-524"><a href="#cb88-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-525"><a href="#cb88-525" aria-hidden="true" tabindex="-1"></a>At this point, we have covered the main ideas behind two-way interactions. In this section and the next, we apply these ideas to different combinations of predictors variables. In this section we address interactions between two continuous predictors. In the next section we address two categorical predictors. In both cases, the regression equation and overall interpretation is the same as the previous sections – e.g., the relationship between $Y$ and $X_1$ changes as a function of $X_2$. However, there are also some special details that crop up in these different settings. </span>
<span id="cb88-526"><a href="#cb88-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-527"><a href="#cb88-527" aria-hidden="true" tabindex="-1"></a>In this section we will address: </span>
<span id="cb88-528"><a href="#cb88-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-529"><a href="#cb88-529" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The importance of centering the two continuous predictors. Centering helps us interpret the "main effects" (i.e., the regression coefficients on the individual predictors).</span>
<span id="cb88-530"><a href="#cb88-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-531"><a href="#cb88-531" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>How to follow-up a significant interaction using simple trends. As was the case for a categorical and a continuous predictor, this helps us interpret the interaction in more detail.</span>
<span id="cb88-532"><a href="#cb88-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-533"><a href="#cb88-533" aria-hidden="true" tabindex="-1"></a>First, we introduce an new example. </span>
<span id="cb88-534"><a href="#cb88-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-535"><a href="#cb88-535" aria-hidden="true" tabindex="-1"></a><span class="fu">### Another NELS example</span></span>
<span id="cb88-536"><a href="#cb88-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-537"><a href="#cb88-537" aria-hidden="true" tabindex="-1"></a>To illustrate an interaction between two continuous predictors, let's replace Gender with SES in our previous analysis. Apologies that this new example is mainly for convenience and doesn't represent a great research question about, e.g., why the relationships between Math and Reading might change as a function of SES. </span>
<span id="cb88-538"><a href="#cb88-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-539"><a href="#cb88-539" aria-hidden="true" tabindex="-1"></a>The overall approach with SES as the moderator is illustrated in @fig-readingXses-5 below. It presents the simple trends for Math and Reading at three values of SES. The overall situation should hopefully feel pretty familiar from the previous sections. The displayed values of SES (9, 19, and 28) are its 10th, 50th, and 90th percentiles, which is the default choice for the software we are using for plotting.  For visual clarity, the confidence bands are not shown.  </span>
<span id="cb88-540"><a href="#cb88-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-541"><a href="#cb88-541" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-readingXses-5, fig.cap = 'Math (achmat), Reading (achrdg), and SES', fig.align = 'center'}</span></span>
<span id="cb88-542"><a href="#cb88-542" aria-hidden="true" tabindex="-1"></a><span class="co">#Interaction without centering </span></span>
<span id="cb88-543"><a href="#cb88-543" aria-hidden="true" tabindex="-1"></a>mod7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses, <span class="at">data =</span> NELS)</span>
<span id="cb88-544"><a href="#cb88-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-545"><a href="#cb88-545" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that band = F removes the confidence intervals</span></span>
<span id="cb88-546"><a href="#cb88-546" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod7, </span>
<span id="cb88-547"><a href="#cb88-547" aria-hidden="true" tabindex="-1"></a>       <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb88-548"><a href="#cb88-548" aria-hidden="true" tabindex="-1"></a>       <span class="at">by =</span> <span class="st">"ses"</span>, </span>
<span id="cb88-549"><a href="#cb88-549" aria-hidden="true" tabindex="-1"></a>       <span class="at">overlay =</span> <span class="cn">TRUE</span>, </span>
<span id="cb88-550"><a href="#cb88-550" aria-hidden="true" tabindex="-1"></a>       <span class="at">band =</span> F)</span>
<span id="cb88-551"><a href="#cb88-551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-552"><a href="#cb88-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-553"><a href="#cb88-553" aria-hidden="true" tabindex="-1"></a><span class="fu">### Centering the predictors</span></span>
<span id="cb88-554"><a href="#cb88-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-555"><a href="#cb88-555" aria-hidden="true" tabindex="-1"></a>The take home message of this section is that you should center continuous predictors when their interaction is included in the model. There are two reasons: </span>
<span id="cb88-556"><a href="#cb88-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-557"><a href="#cb88-557" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Just like @sec-binary-continuous-interaction-5, centering makes it easier to interpret the "main effects" (i.e., the regression coefficients on the individual predictors).</span>
<span id="cb88-558"><a href="#cb88-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-559"><a href="#cb88-559" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Centering can make the estimates of the main effects more precise. This is because centering can reduce the correlation between the individual predictors and the interaction term. Remember from @sec-inference-for-coeffecients-3 that highly correlated predictors lead to less precise estimates of the regression coefficients. We discuss this problem in more detail in @sec-multicollinearity-6, but for now we just discuss how centering helps us avoid the problem.  </span>
<span id="cb88-560"><a href="#cb88-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-561"><a href="#cb88-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-562"><a href="#cb88-562" aria-hidden="true" tabindex="-1"></a>First lets consider how centering facilitates interpretation. Begin by noting that the coefficients $b_1$ and $b_2$ in the regression model</span>
<span id="cb88-563"><a href="#cb88-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-564"><a href="#cb88-564" aria-hidden="true" tabindex="-1"></a>$$ \widehat Y = b_0 + b_1X_1 + b_2X_2 + b_3 (X_1 \times X_2) $$</span>
<span id="cb88-565"><a href="#cb88-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-566"><a href="#cb88-566" aria-hidden="true" tabindex="-1"></a>can be interpreted in terms of the following simple trends: </span>
<span id="cb88-567"><a href="#cb88-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-568"><a href="#cb88-568" aria-hidden="true" tabindex="-1"></a>$$\begin{align} </span>
<span id="cb88-569"><a href="#cb88-569" aria-hidden="true" tabindex="-1"></a>\widehat Y(X_2 =0) &amp; = b_0 + b_1X_1 <span class="sc">\\</span></span>
<span id="cb88-570"><a href="#cb88-570" aria-hidden="true" tabindex="-1"></a>\widehat Y(X_1 =0)&amp;  = b_0 + b_2X_2 </span>
<span id="cb88-571"><a href="#cb88-571" aria-hidden="true" tabindex="-1"></a>\end{align}$$ {#eq-simple-5}</span>
<span id="cb88-572"><a href="#cb88-572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-573"><a href="#cb88-573" aria-hidden="true" tabindex="-1"></a>The first equation shows us that $b_1$ is the slope of relationship between $Y$ and $X_1$, when $X_2$ is equal to zero -- in our example, the relationship between Math and Reading when SES is equal to zero. Similarly, the second equation shows us that $b_2$ is the slope of relationship between $Y$ and $X_2$ when $X_1$ is equal to zero --  in our example, the relationship between Math and SES when Reading is equal to zero.</span>
<span id="cb88-574"><a href="#cb88-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-575"><a href="#cb88-575" aria-hidden="true" tabindex="-1"></a>In general, the value of zero may not be meaningful for continuous predictors. But, when the predictor is *centered* (i.e., a deviation score), the value of zero is always the mean of the original variable. For example, if we centered SES, then $b_1$ would represent the relationship between Math and Reading for students with average SES. Similar considerations apply if we treat Reading as the moderator instead of SES. Note that this is just the same trick as @sec-binary-continuous-interaction-5, but this time both predictors are continuous  and so both can be centered.  </span>
<span id="cb88-576"><a href="#cb88-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-577"><a href="#cb88-577" aria-hidden="true" tabindex="-1"></a>The second main reason for centering is a bit more technical. It has to do with reducing the correlation between the predictors and their interaction. In general, the interaction term will be correlated with both predictors if (a) the predictors themselves are correlated and (b) both predictors take on strictly positive (or strictly negative) values. Highly correlated predictors lead to redundant information the model, so we want to avoid this situation (this is technically called *multicollinearity* and we discuss it in more detail in a  @sec-multicollinearity-6). </span>
<span id="cb88-578"><a href="#cb88-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-579"><a href="#cb88-579" aria-hidden="true" tabindex="-1"></a>To see how centering can reduce the correlation between the predictors and their interaction, let's take a look at @fig-centering-5. The left hand panel shows the relationship between SES and its interaction with Reading. We can see that they are highly correlated. This is because (a) SES and Reading are themselves correlated, and (b) both SES and Reading take on strictly positive values. As mentioned above, the interaction term will be correlated with both predictors whenever these two conditions hold. (The figure shows the correlation just for SES and the interaction, but the same situation holds for Reading.) </span>
<span id="cb88-580"><a href="#cb88-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-581"><a href="#cb88-581" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-centering-5, fig.cap = 'Correlation Between SES and SES X Reading, With and Without Centering', fig.align = 'center'}</span></span>
<span id="cb88-582"><a href="#cb88-582" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-583"><a href="#cb88-583" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation without centering</span></span>
<span id="cb88-584"><a href="#cb88-584" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">cor</span>(ses, achrdg12<span class="sc">*</span>ses)</span>
<span id="cb88-585"><a href="#cb88-585" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-586"><a href="#cb88-586" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb88-587"><a href="#cb88-587" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb88-588"><a href="#cb88-588" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"correlation = "</span>, <span class="fu">round</span>(r, <span class="dv">3</span>))</span>
<span id="cb88-589"><a href="#cb88-589" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ses, achrdg12<span class="sc">*</span>ses, </span>
<span id="cb88-590"><a href="#cb88-590" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb88-591"><a href="#cb88-591" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> title, </span>
<span id="cb88-592"><a href="#cb88-592" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb88-593"><a href="#cb88-593" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"SES X Reading"</span>)</span>
<span id="cb88-594"><a href="#cb88-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-595"><a href="#cb88-595" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation with centering</span></span>
<span id="cb88-596"><a href="#cb88-596" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb88-597"><a href="#cb88-597" aria-hidden="true" tabindex="-1"></a>ses_dev <span class="ot">&lt;-</span> ses <span class="sc">-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb88-598"><a href="#cb88-598" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">cor</span>(ses_dev, achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb88-599"><a href="#cb88-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-600"><a href="#cb88-600" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb88-601"><a href="#cb88-601" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"correlation = "</span>, <span class="fu">round</span>(r, <span class="dv">3</span>))</span>
<span id="cb88-602"><a href="#cb88-602" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ses_dev, </span>
<span id="cb88-603"><a href="#cb88-603" aria-hidden="true" tabindex="-1"></a>     achrdg12_dev<span class="sc">*</span>ses_dev, </span>
<span id="cb88-604"><a href="#cb88-604" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, </span>
<span id="cb88-605"><a href="#cb88-605" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> title, </span>
<span id="cb88-606"><a href="#cb88-606" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"SES Centered"</span>, </span>
<span id="cb88-607"><a href="#cb88-607" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"SES Centered X Reading Centered"</span>)</span>
<span id="cb88-608"><a href="#cb88-608" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-609"><a href="#cb88-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-610"><a href="#cb88-610" aria-hidden="true" tabindex="-1"></a>We can see in the right hand panel of @fig-centering-5 how centering the two predictors "breaks" the linear relationship between SES and its interaction with Reading. After centering, the relationship between SES and its interaction is now highly non-linear, and the correlation is approximately zero. Again, the same is true for the relationship between Reading and the interaction, but the figure only shows the situation for SES. The upshot of all this is that centering reduces multicollinearity between the "main effects" of the predictors and their interaction. </span>
<span id="cb88-611"><a href="#cb88-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-612"><a href="#cb88-612" aria-hidden="true" tabindex="-1"></a>Below we show the output for two regression models. Both models regress Math on Reading, SES, and their interaction. The first model does not center the predictors, but the second model does (the <span class="in">`_dev`</span> notation denotes the centered predictors).  </span>
<span id="cb88-613"><a href="#cb88-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-614"><a href="#cb88-614" aria-hidden="true" tabindex="-1"></a>The main difference between the models is that SES is a significant predictor in the centered model but not in the "un-centered" model. This is because the main effect of SES has a different meaning in the centered model, and it is also less correlated with the interaction. This is also true for Reading, but the differences between the two sets of results are less pronounced for Reading. </span>
<span id="cb88-615"><a href="#cb88-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-618"><a href="#cb88-618" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-619"><a href="#cb88-619" aria-hidden="true" tabindex="-1"></a><span class="co"># Without centering</span></span>
<span id="cb88-620"><a href="#cb88-620" aria-hidden="true" tabindex="-1"></a>mod7 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses)</span>
<span id="cb88-621"><a href="#cb88-621" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod7)</span>
<span id="cb88-622"><a href="#cb88-622" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-623"><a href="#cb88-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-626"><a href="#cb88-626" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-627"><a href="#cb88-627" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb88-628"><a href="#cb88-628" aria-hidden="true" tabindex="-1"></a>mod8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb88-629"><a href="#cb88-629" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod8)</span>
<span id="cb88-630"><a href="#cb88-630" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-631"><a href="#cb88-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-632"><a href="#cb88-632" aria-hidden="true" tabindex="-1"></a>**Please provide an interpretation of all four regression coefficients in the centered model. Your interpretations should make reference to the situation where one or both predictors are equal to zero (see @eq-simple-5 above) and should also mentioned the interpretation of the value of zero for the centered variables.**</span>
<span id="cb88-633"><a href="#cb88-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-634"><a href="#cb88-634" aria-hidden="true" tabindex="-1"></a>Note that the interaction and the R-squared are the same in the centered and uncentered models. This is discussed in more detail in the extra material at the end of this section (@sec-two-categorical-predictors-5), but it is sufficient to note that centering only affects the interpretation of the main effects (and the intercept, of course). </span>
<span id="cb88-635"><a href="#cb88-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-636"><a href="#cb88-636" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple trends</span></span>
<span id="cb88-637"><a href="#cb88-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-638"><a href="#cb88-638" aria-hidden="true" tabindex="-1"></a>Centering helps us interpret the main effects of the individual predictors, but we haven't yet discussed how to interpret the interaction term. As shown in @fig-readingXses-5, the overall situation is not that different than with a binary predictor.</span>
<span id="cb88-639"><a href="#cb88-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-640"><a href="#cb88-640" aria-hidden="true" tabindex="-1"></a>The usual way to follow up a significant interaction between two continuous is using the MERV approach discussed in @sec-inference-for-interactions-5. Using this approach, we consider the focal relationship for some "interesting values" of the moderator. As with MERV, the choice of values of the moderator is up to the researcher, but some usual choices are </span>
<span id="cb88-641"><a href="#cb88-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-642"><a href="#cb88-642" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The quartiles of the moderator</span>
<span id="cb88-643"><a href="#cb88-643" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>M $\pm$ 1 SD of the moderator</span>
<span id="cb88-644"><a href="#cb88-644" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>A selection of percentiles of the moderator (The <span class="in">`visreg`</span> plot in @fig-readingXses-5 uses the 10th, 50th, and 90th)</span>
<span id="cb88-645"><a href="#cb88-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-646"><a href="#cb88-646" aria-hidden="true" tabindex="-1"></a>These are all doing very similar things, so choosing among them usually isn't super important. </span>
<span id="cb88-647"><a href="#cb88-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-648"><a href="#cb88-648" aria-hidden="true" tabindex="-1"></a>Although the interaction between Reading and SES was not significant in our example model, let's break down the interaction using SES as the moderator, just to see how this approach works. The output below presents the simple slopes for the three values of SES shown in @fig-readingXses-5 (i.e., the 10th, 50th, and 90th percentiles). We can see in the output that the simple slopes are all different from zero. (And the non-significant interaction in the <span class="in">`summary(lm)`</span> output tells us that the slopes are not statistically different from one another.)</span>
<span id="cb88-649"><a href="#cb88-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-652"><a href="#cb88-652" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-653"><a href="#cb88-653" aria-hidden="true" tabindex="-1"></a><span class="co"># Break down interaction with SES as moderator</span></span>
<span id="cb88-654"><a href="#cb88-654" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span><span class="fu">emtrends</span>(mod7, </span>
<span id="cb88-655"><a href="#cb88-655" aria-hidden="true" tabindex="-1"></a>                         <span class="at">var =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb88-656"><a href="#cb88-656" aria-hidden="true" tabindex="-1"></a>                         <span class="at">specs =</span> <span class="st">"ses"</span>, </span>
<span id="cb88-657"><a href="#cb88-657" aria-hidden="true" tabindex="-1"></a>                         <span class="at">at =</span> <span class="fu">list</span>(<span class="at">ses =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">19</span>, <span class="dv">28</span>)))</span>
<span id="cb88-658"><a href="#cb88-658" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span>
<span id="cb88-659"><a href="#cb88-659" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-660"><a href="#cb88-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-661"><a href="#cb88-661" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb88-662"><a href="#cb88-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-663"><a href="#cb88-663" aria-hidden="true" tabindex="-1"></a>When regressing an outcome on two continuous predictors and their interaction, the overall interpretation of the model is same as discussed in @sec-binary-continuous-interaction-5, but: </span>
<span id="cb88-664"><a href="#cb88-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-665"><a href="#cb88-665" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>It is useful to center both predictors, to facilitate the interpretation of the main effects (i.e., regression coefficients on the individual predictors), and to improve the precision of the main effects (i.e., reduce multicollinearity). </span>
<span id="cb88-666"><a href="#cb88-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-667"><a href="#cb88-667" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>When following up a significant interaction, the usual approach is to report the simple trends for the focal variables at a selection of values of the moderator (e.g., a selection of percentiles). The example illustrated how to do this even though the interaction was not significant, but you shouldn't follow up a non-significant interaction. </span>
<span id="cb88-668"><a href="#cb88-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-669"><a href="#cb88-669" aria-hidden="true" tabindex="-1"></a><span class="fu">### Extra: How centering works* {#sec-how-centering-works-5}</span></span>
<span id="cb88-670"><a href="#cb88-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-671"><a href="#cb88-671" aria-hidden="true" tabindex="-1"></a>It might seem that centering both predictors is a bit dubious -- how can we just change the predictors in the model? This sections shows that using the centered or the un-centered predictors doesn’t make a difference in term of what predictors are in the model, it just changes the interpretation of the main effects (and intercept). </span>
<span id="cb88-672"><a href="#cb88-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-673"><a href="#cb88-673" aria-hidden="true" tabindex="-1"></a>Using $D = X - \bar X$ for the centered variables, simple algebra shows:  </span>
<span id="cb88-674"><a href="#cb88-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-675"><a href="#cb88-675" aria-hidden="true" tabindex="-1"></a>\begin{align} </span>
<span id="cb88-676"><a href="#cb88-676" aria-hidden="true" tabindex="-1"></a>\widehat Y &amp; = b_0 + b_1D_1 + b_1D_2 + b_3 (D_1 \times D_2) <span class="sc">\\</span> </span>
<span id="cb88-677"><a href="#cb88-677" aria-hidden="true" tabindex="-1"></a>&amp; = b_0^* + (b_1 - b_3 \bar X_1) X_1 + (b_2 - b_3 \bar X_2) X_2 +  b_3 (X_1 \times X_2) <span class="sc">\\</span> </span>
<span id="cb88-678"><a href="#cb88-678" aria-hidden="true" tabindex="-1"></a>\text{where} &amp; <span class="sc">\\</span> <span class="sc">\\</span> </span>
<span id="cb88-679"><a href="#cb88-679" aria-hidden="true" tabindex="-1"></a>b_0^* &amp; = a - b_1\bar X_1 - b_2\bar X_2 - b_3\bar X_1\bar X_2. </span>
<span id="cb88-680"><a href="#cb88-680" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-681"><a href="#cb88-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-682"><a href="#cb88-682" aria-hidden="true" tabindex="-1"></a>The second line of the equation shows that we are not changing what we regress $Y$ on -- i.e., the predictors are still $X_1$ and $X_2$. We are changing the interpretation of the main effects (and intercept), but this is exactly the purpose of this approach. Also note centering does not change the regression coefficient for the interaction at all. So, we get main effects (and intercept) that can be more easily interpreted, and the same interaction </span>
<span id="cb88-683"><a href="#cb88-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-684"><a href="#cb88-684" aria-hidden="true" tabindex="-1"></a><span class="fu">## Two categorical predictors {#sec-two-categorical-predictors-5}</span></span>
<span id="cb88-685"><a href="#cb88-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-686"><a href="#cb88-686" aria-hidden="true" tabindex="-1"></a>This section addresses interactions between two categorical predictors. Up until now, we have looked at interactions only for categorical predictors that are dichotomous. In this section, we address an example in which one of the categorical predictors has more than two levels. This requires combining what we learned about contrast coding (@sec-chap-4) with what we have learned about interactions. One nice aspect of interactions among categorical predictors is that we usually don't need to use procedures like marginal effects to follow up significant interactions, so long as we make good use of contrast coding. </span>
<span id="cb88-687"><a href="#cb88-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-688"><a href="#cb88-688" aria-hidden="true" tabindex="-1"></a>In experimental (as opposed to observational) settings, interactions among categorical predictors fall under the much larger topic of ANOVA and experimental design. The analysis we look at in this section is a two-way between-subjects ANOVA, meaning that there are two categorical predictors considered, as well as their interaction, and both predictors are cross-sectional. ANOVA is a big topic and is not the focus of this course. However, we will discuss how to summarize the results of our analysis in an ANOVA table, and consider how this differs from the standard regression approach.  </span>
<span id="cb88-689"><a href="#cb88-689" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-690"><a href="#cb88-690" aria-hidden="true" tabindex="-1"></a><span class="fu">### An example from ECLS</span></span>
<span id="cb88-691"><a href="#cb88-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-692"><a href="#cb88-692" aria-hidden="true" tabindex="-1"></a>For this topic we will switch over to the ECLS data and examine how SES and Pre-K attendance interact to predict Math Achievement at the beginning of Kindergarten. The variables we will examine are</span>
<span id="cb88-693"><a href="#cb88-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-694"><a href="#cb88-694" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Math Achievement at the beginning of K (<span class="in">`c1rmscal`</span>). This is the number of correct questions on a test with approximately 70 items. </span>
<span id="cb88-695"><a href="#cb88-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-696"><a href="#cb88-696" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Whether the child attended Pre-K (<span class="in">`p1center`</span>). This is a binary variable that indicates pre-K attendance. </span>
<span id="cb88-697"><a href="#cb88-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-698"><a href="#cb88-698" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>SES, coded as quintiles (<span class="in">`wksesq5`</span>). We will denote this variable as SES, but keep in mind it is quintiles in this example (e.g., SES = 1 are the respondents with SES between the minimum and the first quintile). </span>
<span id="cb88-699"><a href="#cb88-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-700"><a href="#cb88-700" aria-hidden="true" tabindex="-1"></a>Coding SES as quintiles allows us to consider it as a categorical predictor with 5 levels. This is a widely-used practice, because SES often has non-linear relationships with outcome variables of interest, and these relationships can be more easily captured by treating SES as a categorical variable. This approach to SES is also convenient for our illustration of interactions between categorical predictors. </span>
<span id="cb88-701"><a href="#cb88-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-702"><a href="#cb88-702" aria-hidden="true" tabindex="-1"></a>In this analysis, our focus will be whether the "effect" of Pre-K on Math Achievement depends on (i.e., is moderated by) the child's SES. Please note that I will use the term "effect" in this section to simplify language, but we know that Pre-K attendance was not randomly assigned in ECLS, so please keep in mind that this terminology is not strictly correct. </span>
<span id="cb88-703"><a href="#cb88-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-704"><a href="#cb88-704" aria-hidden="true" tabindex="-1"></a>The relationship among the three variables is summarized in the <span class="in">`visreg`</span> plot below. We can see that the effect of Pre-K on Math Achievement appears to differ as a function of SES -- i.e., it appears that there is an interaction between Pre-K and SES. Our goal in this section is to produce an analysis corresponding to the figure.</span>
<span id="cb88-705"><a href="#cb88-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-706"><a href="#cb88-706" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig-prek-by-ses-5, fig.cap = 'Math Achievement, Pre-K Attendence, and SES', fig.align = 'center'}</span></span>
<span id="cb88-707"><a href="#cb88-707" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb88-708"><a href="#cb88-708" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb88-709"><a href="#cb88-709" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb88-710"><a href="#cb88-710" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb88-711"><a href="#cb88-711" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb88-712"><a href="#cb88-712" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb88-713"><a href="#cb88-713" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb88-714"><a href="#cb88-714" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb88-715"><a href="#cb88-715" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span>
<span id="cb88-716"><a href="#cb88-716" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-717"><a href="#cb88-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-718"><a href="#cb88-718" aria-hidden="true" tabindex="-1"></a>**Before moving on, please take a moment to write down your interpretation of  @fig-prek-by-ses-5, focussing on how it illustrates an interaction between SES and Pre-K. Additionally, please describe how the figure would be different if there was no interaction between Pre-K and SES**. </span>
<span id="cb88-719"><a href="#cb88-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-720"><a href="#cb88-720" aria-hidden="true" tabindex="-1"></a><span class="fu">### The "no-interaction" model </span></span>
<span id="cb88-721"><a href="#cb88-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-722"><a href="#cb88-722" aria-hidden="true" tabindex="-1"></a>As in @sec-binary-continuous-5, we will start with a model that includes only the main effects of SES and Pre-K. Seeing where that model "goes wrong" is a good way of understanding the interaction between the two predictors. </span>
<span id="cb88-723"><a href="#cb88-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-724"><a href="#cb88-724" aria-hidden="true" tabindex="-1"></a>In order to represent a model with multiple categorical predictors, it is helpful to change our notation from the usual $Y$ and $X$ to the more informative "variable names" notation:</span>
<span id="cb88-725"><a href="#cb88-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-726"><a href="#cb88-726" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb88-727"><a href="#cb88-727" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-728"><a href="#cb88-728" aria-hidden="true" tabindex="-1"></a>\widehat Y = b_0 + b_1 PREK + b_2SES_2 + b_3SES_3 + b_4 SES_4 + b_5 SES_5. </span>
<span id="cb88-729"><a href="#cb88-729" aria-hidden="true" tabindex="-1"></a>\end{align}$${#eq-prek-ses-5}</span>
<span id="cb88-730"><a href="#cb88-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-731"><a href="#cb88-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-732"><a href="#cb88-732" aria-hidden="true" tabindex="-1"></a>In this notation, the predictor variables are indicators (binary dummies). The variable $PREK$ is just the indicator for Pre-K attendance, as defined above. The variable $SES_j$ is an indicator for the j-th quintile of SES. </span>
<span id="cb88-733"><a href="#cb88-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-734"><a href="#cb88-734" aria-hidden="true" tabindex="-1"></a>Both predictors use reference-group coding, as discussed in @sec-chap-4. For $PREK$, reference-group coding is implied because it is a binary indicator. For $SES$, reference-group coding is accomplished by omitting the binary dummy for the first quintile (i.e., the first quintile is the reference group). </span>
<span id="cb88-735"><a href="#cb88-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-736"><a href="#cb88-736" aria-hidden="true" tabindex="-1"></a>We can interpret the coefficients in this model using the same two-step procedure described in @sec-chap-4. Since there are many terms in the model, things are going to start getting messy quickly, so brace yourself for some long equations (but simple math!). </span>
<span id="cb88-737"><a href="#cb88-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-738"><a href="#cb88-738" aria-hidden="true" tabindex="-1"></a>The main points about the interpretation of this model are as follows. </span>
<span id="cb88-739"><a href="#cb88-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-740"><a href="#cb88-740" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The intercept is the predicted value of Math Achievement for students in the first SES quintile who did not attend Pre-K. This corresponds to the blue line in the first column of @fig-prek-by-ses-5. </span>
<span id="cb88-741"><a href="#cb88-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-742"><a href="#cb88-742" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-743"><a href="#cb88-743" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 0, SES = 1) &amp; = b_0 + b_1 (0) + b_2(0)+ b_3(0) + b_4 (0) + b_5 (0) <span class="sc">\\</span>  </span>
<span id="cb88-744"><a href="#cb88-744" aria-hidden="true" tabindex="-1"></a>&amp; = b_0</span>
<span id="cb88-745"><a href="#cb88-745" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-746"><a href="#cb88-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-747"><a href="#cb88-747" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The effect of Pre-K attendance for students in the first SES quintile is equal to $b_1$. This corresponds to the difference between the red and blue lines in the first column of @fig-prek-by-ses-5.</span>
<span id="cb88-748"><a href="#cb88-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-749"><a href="#cb88-749" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-750"><a href="#cb88-750" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 1) &amp; = b_0 + b_1 (1) + b_2(0)+ b_3(0) + b_4 (0) + b_5 (0) <span class="sc">\\</span>  </span>
<span id="cb88-751"><a href="#cb88-751" aria-hidden="true" tabindex="-1"></a>&amp; = b_0 + b_1 <span class="sc">\\</span></span>
<span id="cb88-752"><a href="#cb88-752" aria-hidden="true" tabindex="-1"></a>\implies &amp; </span>
<span id="cb88-753"><a href="#cb88-753" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-754"><a href="#cb88-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-755"><a href="#cb88-755" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-756"><a href="#cb88-756" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 1) - \widehat Y(PREK = 0, SES = 1) &amp; = b_1</span>
<span id="cb88-757"><a href="#cb88-757" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-758"><a href="#cb88-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-759"><a href="#cb88-759" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Because the model in @eq-prek-ses-5 does not include an interaction, we already know that it implies that the effect of Pre-K is constant over levels of SES.  Below we show that effect of Pre-K for SES = 2 is the same as the effect for SES = 1. The same approach can be used to show the effect is constant over all levels of SES. Note that while the model assumes the effect of Pre-K is constant over levels of SES, this is actually inconsistent with what is shown in @fig-prek-by-ses-5. We will improve on this model by adding an interaction in the following section.</span>
<span id="cb88-760"><a href="#cb88-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-761"><a href="#cb88-761" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-762"><a href="#cb88-762" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 0, SES = 2) &amp; = b_0 + b_1 (0) + b_2(1 )+ b_3(0) + b_4 (0) + b_5 (0)<span class="sc">\\</span>  </span>
<span id="cb88-763"><a href="#cb88-763" aria-hidden="true" tabindex="-1"></a>&amp; = b_0 + b_2 <span class="sc">\\</span> <span class="sc">\\</span> </span>
<span id="cb88-764"><a href="#cb88-764" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 2)&amp; = b_0 + b_1 (1) + b_2(1)+ b_3(0) + b_4 (0) + b_5 (0)<span class="sc">\\</span>  </span>
<span id="cb88-765"><a href="#cb88-765" aria-hidden="true" tabindex="-1"></a>&amp; = b_0 + b_1 + b_2 <span class="sc">\\</span> <span class="sc">\\</span> </span>
<span id="cb88-766"><a href="#cb88-766" aria-hidden="true" tabindex="-1"></a>\implies &amp; </span>
<span id="cb88-767"><a href="#cb88-767" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-768"><a href="#cb88-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-769"><a href="#cb88-769" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-770"><a href="#cb88-770" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2) = b_1  </span>
<span id="cb88-771"><a href="#cb88-771" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-772"><a href="#cb88-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-773"><a href="#cb88-773" aria-hidden="true" tabindex="-1"></a>This equation says that the difference between the red and blue lines in the second column of @fig-prek-by-ses-5 is the same as the difference in the first column -- i.e., they both equal $b_1$. This is what it means for there to be no interaction between two categorical predictors. </span>
<span id="cb88-774"><a href="#cb88-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-775"><a href="#cb88-775" aria-hidden="true" tabindex="-1"></a>If you want more practice with this, you can show that @eq-prek-ses-5 implies the effect of Pre-K is constant over all levels of SES. Additionally, you can use the 2-step approach to show that the effect of SES is constant over levels of Pre-K attendance. </span>
<span id="cb88-776"><a href="#cb88-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-777"><a href="#cb88-777" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adding the interaction(s)</span></span>
<span id="cb88-778"><a href="#cb88-778" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-779"><a href="#cb88-779" aria-hidden="true" tabindex="-1"></a>We have just seen that @eq-prek-ses-5 implies that the effect of Pre-K is constant over levels of SES, and vise versa. In order to address our research question about whether the relationship between Pre-K attendance and Math Achievement depends on children's SES, we will need to add something to the model -- an interaction (surprise!). </span>
<span id="cb88-780"><a href="#cb88-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-781"><a href="#cb88-781" aria-hidden="true" tabindex="-1"></a>We know that interactions are just products (multiplication) of predictor variables. Since SES is represented as 4 dummies, this means we need 4 products to represent the interaction of Pre-K with SES. The resulting model can be written: </span>
<span id="cb88-782"><a href="#cb88-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-783"><a href="#cb88-783" aria-hidden="true" tabindex="-1"></a>$$\begin{align}</span>
<span id="cb88-784"><a href="#cb88-784" aria-hidden="true" tabindex="-1"></a>\widehat Y  = &amp; b_0 + b_1 PREK + b_2SES_2 + b_3SES_3 + b_4 SES_4 + b_5 SES_5 + <span class="sc">\\</span> </span>
<span id="cb88-785"><a href="#cb88-785" aria-hidden="true" tabindex="-1"></a>&amp;  b_6 (PREK \times SES_2) + b_7(PREK \times SES_3) + <span class="sc">\\</span></span>
<span id="cb88-786"><a href="#cb88-786" aria-hidden="true" tabindex="-1"></a>&amp; b_8 (PREK \times SES_4) + b_9 (PREK \times SES_5) </span>
<span id="cb88-787"><a href="#cb88-787" aria-hidden="true" tabindex="-1"></a>\end{align}$$ {#eq-prek-ses-5b}</span>
<span id="cb88-788"><a href="#cb88-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-789"><a href="#cb88-789" aria-hidden="true" tabindex="-1"></a>As you can see, we have a lot of predictors in this model! Although we are only considering two distinct "conceptual" predictors, we have 9 coefficients in our regression model (+ the intercept). </span>
<span id="cb88-790"><a href="#cb88-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-791"><a href="#cb88-791" aria-hidden="true" tabindex="-1"></a>Again, there are a few main things to notice: </span>
<span id="cb88-792"><a href="#cb88-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-793"><a href="#cb88-793" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The interpretation of the intercept has not changed. It still corresponds to the blue line in the first column of @fig-prek-by-ses-5. </span>
<span id="cb88-794"><a href="#cb88-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-795"><a href="#cb88-795" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The regression coefficient on $PREK$ is still the "effect" of Pre-K for students in the first SES quintile (i.e., the difference between the red and blue line in the first column of @fig-prek-by-ses-5). This is because all the $SES_j$ variables are equal to zero for students in the first SES quintile, and so all of the interaction terms in @eq-prek-ses-5b are equal to zero. </span>
<span id="cb88-796"><a href="#cb88-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-797"><a href="#cb88-797" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The effect of Pre-K is no longer constant over levels of SES. Again we will focus on SES = 2, but the same approach works for the other levels of SES.</span>
<span id="cb88-798"><a href="#cb88-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-799"><a href="#cb88-799" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-800"><a href="#cb88-800" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 0, SES = 2) &amp; = b_0 + b_1 (0) + b_2(1 )+ b_3(0) + b_4 (0) + b_5 (0) + <span class="sc">\\</span></span>
<span id="cb88-801"><a href="#cb88-801" aria-hidden="true" tabindex="-1"></a>&amp;  b_6 (0 \times 1) + b_7(0 \times 0) + b_8 (0 \times 0) + b_9 (0\times 0) <span class="sc">\\</span>  </span>
<span id="cb88-802"><a href="#cb88-802" aria-hidden="true" tabindex="-1"></a>&amp; = b_0 + b_2 <span class="sc">\\</span> <span class="sc">\\</span> </span>
<span id="cb88-803"><a href="#cb88-803" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 2) &amp; = b_0 + b_1 (1) + b_2(1)+ b_3(0) + b_4 (0) + b_5 (0) + <span class="sc">\\</span></span>
<span id="cb88-804"><a href="#cb88-804" aria-hidden="true" tabindex="-1"></a>&amp;  b_6 (1 \times 1) + b_7(1 \times 0) + b_8 (1 \times 0) + b_9 (1\times 0) <span class="sc">\\</span>  </span>
<span id="cb88-805"><a href="#cb88-805" aria-hidden="true" tabindex="-1"></a>&amp; = b_0 + b_1 + b_2 + b_6 <span class="sc">\\</span> <span class="sc">\\</span> </span>
<span id="cb88-806"><a href="#cb88-806" aria-hidden="true" tabindex="-1"></a>\implies &amp; </span>
<span id="cb88-807"><a href="#cb88-807" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-808"><a href="#cb88-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-809"><a href="#cb88-809" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-810"><a href="#cb88-810" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2) = b_1 + b_6</span>
<span id="cb88-811"><a href="#cb88-811" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-812"><a href="#cb88-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-813"><a href="#cb88-813" aria-hidden="true" tabindex="-1"></a>The last line shows that the "effect" of Pre-K for students in the second SES quintile is $b_1 + b_6$. This is not the same as the effect for students in the first quintile, which was just $b_1$. In other words, the difference between the red and blue lines in the first column of @fig-prek-by-ses-5 (i.e., $b_1$) is not equal to the difference in the second column (i.e., $b_1 + b_6$) unless the interaction is equal to zero (i.e., $b_6 = 0$). </span>
<span id="cb88-814"><a href="#cb88-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-815"><a href="#cb88-815" aria-hidden="true" tabindex="-1"></a>The same approach shows that the effect of Pre-K at each level of SES results in a similar equation:</span>
<span id="cb88-816"><a href="#cb88-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-817"><a href="#cb88-817" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb88-818"><a href="#cb88-818" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 3) - \widehat Y(PREK = 0, SES = 3) &amp; = b_1 + b_7 <span class="sc">\\</span> </span>
<span id="cb88-819"><a href="#cb88-819" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 4) - \widehat Y(PREK = 0, SES = 4) &amp; = b_1 + b_8 <span class="sc">\\</span> </span>
<span id="cb88-820"><a href="#cb88-820" aria-hidden="true" tabindex="-1"></a>\widehat Y(PREK = 1, SES = 5) - \widehat Y(PREK = 0, SES = 5) &amp; = b_1 + b_9 <span class="sc">\\</span> </span>
<span id="cb88-821"><a href="#cb88-821" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-822"><a href="#cb88-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-823"><a href="#cb88-823" aria-hidden="true" tabindex="-1"></a>This pattern makes it clear that, to isolate the interactions (i.e., $b_6$ through $b_9$), we need to subtract off $b_1$ -- i.e., we need to subtract off the effect of Pre-K for students in the first SES quintile. In anology with reference group coding for single predictor (see @sec-reference-group-coding-4), we can think of $b_1$ the "reference effect" or baseline to which the interaction terms are compared. </span>
<span id="cb88-824"><a href="#cb88-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-825"><a href="#cb88-825" aria-hidden="true" tabindex="-1"></a>For example</span>
<span id="cb88-826"><a href="#cb88-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-827"><a href="#cb88-827" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The interaction between Pre-K and the second SES quintile is the effect Pre-K has on Math Achievement for students in the second SES quintile, *as compared to the effect in the first SES quintile.* </span>
<span id="cb88-828"><a href="#cb88-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-829"><a href="#cb88-829" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The interaction between Pre-K and the third SES quintile is the effect Pre-K has on Math Achievement for students in the 3rd SES quintile, *as compared to the effect in the first SES quintile.* </span>
<span id="cb88-830"><a href="#cb88-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-831"><a href="#cb88-831" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>etc. etc. </span>
<span id="cb88-832"><a href="#cb88-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-833"><a href="#cb88-833" aria-hidden="true" tabindex="-1"></a>Mathematically, the interaction terms are represented as "differences-in-differences". For example, </span>
<span id="cb88-834"><a href="#cb88-834" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-835"><a href="#cb88-835" aria-hidden="true" tabindex="-1"></a>\begin{align} </span>
<span id="cb88-836"><a href="#cb88-836" aria-hidden="true" tabindex="-1"></a>b_6 &amp; = <span class="co">[</span><span class="ot">\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2)</span><span class="co">]</span> -  b_1 <span class="sc">\\</span> </span>
<span id="cb88-837"><a href="#cb88-837" aria-hidden="true" tabindex="-1"></a>    &amp; = <span class="co">[</span><span class="ot">\widehat Y(PREK = 1, SES = 2) - \widehat Y(PREK = 0, SES = 2)</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb88-838"><a href="#cb88-838" aria-hidden="true" tabindex="-1"></a>    &amp; - <span class="co">[</span><span class="ot">\widehat Y(PREK = 1, SES = 1) - \widehat Y(PREK = 0, SES = 1)</span><span class="co">]</span></span>
<span id="cb88-839"><a href="#cb88-839" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb88-840"><a href="#cb88-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-841"><a href="#cb88-841" aria-hidden="true" tabindex="-1"></a>This looks quite complicated but it is just an extension of reference-group coding. This equation is saying that the "reference effect" or "baseline" for interpreting the interaction ($b_6$) is the effect of Pre-K in the first SES quintile (i.e., $b_1$). As noted above, all of the interaction terms have the same reference effect. </span>
<span id="cb88-842"><a href="#cb88-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-843"><a href="#cb88-843" aria-hidden="true" tabindex="-1"></a><span class="fu">### Back to the example</span></span>
<span id="cb88-844"><a href="#cb88-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-845"><a href="#cb88-845" aria-hidden="true" tabindex="-1"></a>That last section was a lot to take in, so let's put some numbers on the page to check our understanding. The output below shows the summary for a model that regresses Math Achievement on Pre-K, SES, and their interaction. **Please write down an interpretation of magnitude, direction, and statistical significance of each regression coefficient in this output (including the intercept), and be prepared to share your answers in class.** Remember that <span class="in">`wksesq5`</span> is the variable code for the SES quintiles -- the digit that follows the variable code indicates the level of variable. It may be helpful to refer to @fig-prek-by-ses-5 when interpreting the coefficients. </span>
<span id="cb88-846"><a href="#cb88-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-849"><a href="#cb88-849" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-850"><a href="#cb88-850" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb88-851"><a href="#cb88-851" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb88-852"><a href="#cb88-852" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-853"><a href="#cb88-853" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-854"><a href="#cb88-854" aria-hidden="true" tabindex="-1"></a><span class="fu">### The ANOVA approach </span></span>
<span id="cb88-855"><a href="#cb88-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-856"><a href="#cb88-856" aria-hidden="true" tabindex="-1"></a>The output in the previous section is detailed enough that it is not usually required to follow-up a significant interaction among categorical predictors using marginal effects. However, the summary output still omits some information we might be interested in. For example, the Pre-K indicator in the above output tells us the effect of Pre-K, but only for children in the first SES quintile. We might also want to know about the overall effect of Pre-K across levels of SES -- i.e., is there a significant difference in Math Achievement for students who attended Pre-K, after controlling for their level of SES? Similarly, what is the overall main effect of SES? </span>
<span id="cb88-857"><a href="#cb88-857" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-858"><a href="#cb88-858" aria-hidden="true" tabindex="-1"></a>One way to summarize the main effects of Pre-K and SES, as well as their interaction, by asking how much variance they explain after controlling for the other predictors in the model. This is the ANOVA approach we discussed last semester, but now applied to two categorical predictors. </span>
<span id="cb88-859"><a href="#cb88-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-860"><a href="#cb88-860" aria-hidden="true" tabindex="-1"></a>The ANOVA table for our example is below, and it is followed by the R-squared coefficients for each predictor, which are called "eta-squared" ($\eta^2$) in the context of ANOVA. These R-squared (eta-squared) coefficients tell us what proportion of the variance in Math Achievement is attributable to the main effects and the interaction. </span>
<span id="cb88-861"><a href="#cb88-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-862"><a href="#cb88-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-865"><a href="#cb88-865" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-866"><a href="#cb88-866" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA Table</span></span>
<span id="cb88-867"><a href="#cb88-867" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span>
<span id="cb88-868"><a href="#cb88-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-869"><a href="#cb88-869" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared (eta-squared)</span></span>
<span id="cb88-870"><a href="#cb88-870" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("effectsize")</span></span>
<span id="cb88-871"><a href="#cb88-871" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span>
<span id="cb88-872"><a href="#cb88-872" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-873"><a href="#cb88-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-874"><a href="#cb88-874" aria-hidden="true" tabindex="-1"></a>**Please write down your interpretation of the ANOVA table and R-squared (eta-squared) coefficients and be prepared to share you thoughts in class.** Note that the ANOVA output leads to different conclusions than the regression output above. We will discuss the discrepancies between the ANOVA and regression output in class. </span>
<span id="cb88-875"><a href="#cb88-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-876"><a href="#cb88-876" aria-hidden="true" tabindex="-1"></a>Let's end this discussion of ANOVA with two qualifications. </span>
<span id="cb88-877"><a href="#cb88-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-878"><a href="#cb88-878" aria-hidden="true" tabindex="-1"></a>First, I should clarify that the term "main effect" has a somewhat different meaning in ANOVA as compared to regression. In the regression examples, we talked about the effect of a predictor, *conditional on* the other predictor being zero. In ANOVA stuff above, we instead talked about the average or overall effect of a predictor, while holding the other predictor constant. These two interpretations are related but not the same, and in the ANOVA literature, "main effect" usually means the average or overall effect. </span>
<span id="cb88-879"><a href="#cb88-879" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-880"><a href="#cb88-880" aria-hidden="true" tabindex="-1"></a>Second, some people claim that it is bad practice to interpret main effects *qua* average effects in the presence of an interaction. The basic argument is that we shouldn't report the average effect when the "real message" of the interaction is that the effect changes as a function of the other predictor. I think that main effects and interactions aren't really incompatible concepts, especially if we are talking about conditional main effects rather than average main effects. But, you should be aware that this topic is debated and you are free to make up your own mind (as always!).</span>
<span id="cb88-881"><a href="#cb88-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-882"><a href="#cb88-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-883"><a href="#cb88-883" aria-hidden="true" tabindex="-1"></a><span class="fu">## Workbook </span></span>
<span id="cb88-884"><a href="#cb88-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-885"><a href="#cb88-885" aria-hidden="true" tabindex="-1"></a>This section collects the questions asked in this chapter. The lessons for this chapter will focus on discussing these questions and then working on the exercises in @sec-exercises-5. The lesson will **not** be a lecture that reviews all of the material in the chapter! So, if you haven't written down / thought about the answers to these questions before class, the lesson will not be very useful for you. Please engage with each question by writing down one or more answers, asking clarifying questions about related material, posing follow up questions, etc. </span>
<span id="cb88-886"><a href="#cb88-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-887"><a href="#cb88-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-888"><a href="#cb88-888" aria-hidden="true" tabindex="-1"></a>@sec-example-5</span>
<span id="cb88-889"><a href="#cb88-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-890"><a href="#cb88-890" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>What does the following plot is telling us about the relationships among the three variables. In particular: </span>
<span id="cb88-891"><a href="#cb88-891" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Does the gender gap in Math Achievement change as a function of Reading Achievement? </span>
<span id="cb88-892"><a href="#cb88-892" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Is the relationship between Math Achievement and Reading Achievement the the same for males and females?</span>
<span id="cb88-893"><a href="#cb88-893" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>What do the results mean for gender equality in Math and STEM education?</span>
<span id="cb88-894"><a href="#cb88-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-895"><a href="#cb88-895" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.align = 'center'}</span></span>
<span id="cb88-896"><a href="#cb88-896" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[females] <span class="sc">~</span> achrdg12[females])</span>
<span id="cb88-897"><a href="#cb88-897" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12[males] <span class="sc">~</span> achrdg12[males])</span>
<span id="cb88-898"><a href="#cb88-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-899"><a href="#cb88-899" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot reading and math for females</span></span>
<span id="cb88-900"><a href="#cb88-900" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(achrdg12[females], </span>
<span id="cb88-901"><a href="#cb88-901" aria-hidden="true" tabindex="-1"></a>     achmat12[females], </span>
<span id="cb88-902"><a href="#cb88-902" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Reading"</span>, </span>
<span id="cb88-903"><a href="#cb88-903" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Math"</span>)</span>
<span id="cb88-904"><a href="#cb88-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-905"><a href="#cb88-905" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod1, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-906"><a href="#cb88-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-907"><a href="#cb88-907" aria-hidden="true" tabindex="-1"></a><span class="co"># Add points and line for males</span></span>
<span id="cb88-908"><a href="#cb88-908" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(achrdg12[males], </span>
<span id="cb88-909"><a href="#cb88-909" aria-hidden="true" tabindex="-1"></a>       achmat12[males], </span>
<span id="cb88-910"><a href="#cb88-910" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">pch =</span> <span class="dv">2</span>)</span>
<span id="cb88-911"><a href="#cb88-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-912"><a href="#cb88-912" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb88-913"><a href="#cb88-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-914"><a href="#cb88-914" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend</span></span>
<span id="cb88-915"><a href="#cb88-915" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="at">x =</span> <span class="st">"topleft"</span>, </span>
<span id="cb88-916"><a href="#cb88-916" aria-hidden="true" tabindex="-1"></a>       <span class="at">legend =</span> <span class="fu">levels</span>(gender),</span>
<span id="cb88-917"><a href="#cb88-917" aria-hidden="true" tabindex="-1"></a>       <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), </span>
<span id="cb88-918"><a href="#cb88-918" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">"#4B9CD3"</span>))</span>
<span id="cb88-919"><a href="#cb88-919" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-920"><a href="#cb88-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-921"><a href="#cb88-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-922"><a href="#cb88-922" aria-hidden="true" tabindex="-1"></a>@sec-binary-continuous-5</span>
<span id="cb88-923"><a href="#cb88-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-924"><a href="#cb88-924" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>No interaction model: The regression coefficients for the example data are shown below. Please use these numbers to provide an interpretation of the simple trends and the gender gap in Math Achievement for the NELS example. Don't worry about statistical significance, just focus on the meaning of the coefficients.</span>
<span id="cb88-925"><a href="#cb88-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-928"><a href="#cb88-928" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-929"><a href="#cb88-929" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender, <span class="at">data =</span> NELS)</span>
<span id="cb88-930"><a href="#cb88-930" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span>
<span id="cb88-931"><a href="#cb88-931" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-932"><a href="#cb88-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-933"><a href="#cb88-933" aria-hidden="true" tabindex="-1"></a>Here is an example to help you get started: </span>
<span id="cb88-934"><a href="#cb88-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-935"><a href="#cb88-935" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simply for females, the regression of Math Achievement on Reading Achievement has an intercept equal to 19.98 and a slope equal to 0.64. The intercept tells us that a female student with Reading Achievement score of 0% is expected to have a Math Achievement score of 19.98% (the units of the two tests are percent correct). Since the lowest value of Reading Achievement in our example is about 35%, the intercept is not very meaningful for these data. The regression slope tells us that, for females, a 1 unit increase in Reading Achievement is associated with a .64 unit increase in Math Achievement. </span>
<span id="cb88-936"><a href="#cb88-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-937"><a href="#cb88-937" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simply for males, .... </span>
<span id="cb88-938"><a href="#cb88-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-939"><a href="#cb88-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-940"><a href="#cb88-940" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The gender gap in Math Achievement was equal to ... </span>
<span id="cb88-941"><a href="#cb88-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-942"><a href="#cb88-942" aria-hidden="true" tabindex="-1"></a>@sec-binary-continuous-interaction-5</span>
<span id="cb88-943"><a href="#cb88-943" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-944"><a href="#cb88-944" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Interaction model: The regression coefficients for the example data are shown below. Please use these numbers to provide an interpretation of the interaction between Gender and Reading. Don't worry about statistical significance, just focus on the meaning of the coefficients.</span>
<span id="cb88-945"><a href="#cb88-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-948"><a href="#cb88-948" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-949"><a href="#cb88-949" aria-hidden="true" tabindex="-1"></a><span class="co"># hard code the interaction term</span></span>
<span id="cb88-950"><a href="#cb88-950" aria-hidden="true" tabindex="-1"></a>genderXachrdg12 <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb88-951"><a href="#cb88-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-952"><a href="#cb88-952" aria-hidden="true" tabindex="-1"></a><span class="co"># Rund the model with the interaction included</span></span>
<span id="cb88-953"><a href="#cb88-953" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXachrdg12)</span>
<span id="cb88-954"><a href="#cb88-954" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span>
<span id="cb88-955"><a href="#cb88-955" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-956"><a href="#cb88-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-957"><a href="#cb88-957" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Interaction model using the centered continuous predictor: Please write down your interpretation of the intercept and the regression coefficient for Gender in the regression output below. </span>
<span id="cb88-958"><a href="#cb88-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-961"><a href="#cb88-961" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-962"><a href="#cb88-962" aria-hidden="true" tabindex="-1"></a><span class="co"># compute the deviation scores for reading</span></span>
<span id="cb88-963"><a href="#cb88-963" aria-hidden="true" tabindex="-1"></a>reading_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12, <span class="at">na.rm =</span> T) </span>
<span id="cb88-964"><a href="#cb88-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-965"><a href="#cb88-965" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the interaction model as above</span></span>
<span id="cb88-966"><a href="#cb88-966" aria-hidden="true" tabindex="-1"></a>genderXreading_dev <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> reading_dev</span>
<span id="cb88-967"><a href="#cb88-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-968"><a href="#cb88-968" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> reading_dev <span class="sc">+</span> gender <span class="sc">+</span> genderXreading_dev)</span>
<span id="cb88-969"><a href="#cb88-969" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod5)</span>
<span id="cb88-970"><a href="#cb88-970" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-971"><a href="#cb88-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-972"><a href="#cb88-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-973"><a href="#cb88-973" aria-hidden="true" tabindex="-1"></a>@sec-inference-for-interactions-5</span>
<span id="cb88-974"><a href="#cb88-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-975"><a href="#cb88-975" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The output shows the gender gap in Math Achievement for 5 values of Reading Achievement. The values of Reading Achievement are its 5 quartiles. You can think of the output as a tabular summary of @fig-visreg-1. Please use the output to make a conclusion about the levels of Reading Achievement for which the gender gap was significant. Please be prepared to share your answer in class</span>
<span id="cb88-976"><a href="#cb88-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-977"><a href="#cb88-977" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-980"><a href="#cb88-980" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-981"><a href="#cb88-981" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the emmeans package if you haven't already done so</span></span>
<span id="cb88-982"><a href="#cb88-982" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("emmeans")</span></span>
<span id="cb88-983"><a href="#cb88-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-984"><a href="#cb88-984" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb88-985"><a href="#cb88-985" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb88-986"><a href="#cb88-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-987"><a href="#cb88-987" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using R's formula syntax for interaction '*'</span></span>
<span id="cb88-988"><a href="#cb88-988" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> gender<span class="sc">*</span>achrdg12, <span class="at">data =</span> NELS)</span>
<span id="cb88-989"><a href="#cb88-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-990"><a href="#cb88-990" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb88-991"><a href="#cb88-991" aria-hidden="true" tabindex="-1"></a>gap <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod6, </span>
<span id="cb88-992"><a href="#cb88-992" aria-hidden="true" tabindex="-1"></a>               <span class="at">specs =</span> <span class="st">"gender"</span>,</span>
<span id="cb88-993"><a href="#cb88-993" aria-hidden="true" tabindex="-1"></a>               <span class="at">by =</span> <span class="st">"achrdg12"</span>, </span>
<span id="cb88-994"><a href="#cb88-994" aria-hidden="true" tabindex="-1"></a>               <span class="at">cov.reduce =</span> quantile)</span>
<span id="cb88-995"><a href="#cb88-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-996"><a href="#cb88-996" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the differences are significant</span></span>
<span id="cb88-997"><a href="#cb88-997" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span>
<span id="cb88-998"><a href="#cb88-998" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-999"><a href="#cb88-999" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb88-1000"><a href="#cb88-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1001"><a href="#cb88-1001" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The test of the slopes of the simple trends for the example are reported below. As previously stated, these aren't super interesting in the context of our example, but you should check your understanding of simple trends by writing down an interpretation of the output below. </span>
<span id="cb88-1002"><a href="#cb88-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1005"><a href="#cb88-1005" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1006"><a href="#cb88-1006" aria-hidden="true" tabindex="-1"></a><span class="co"># The regression coefficients on reading, broken down by gender</span></span>
<span id="cb88-1007"><a href="#cb88-1007" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod6, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb88-1008"><a href="#cb88-1008" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span>
<span id="cb88-1009"><a href="#cb88-1009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1010"><a href="#cb88-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1011"><a href="#cb88-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1012"><a href="#cb88-1012" aria-hidden="true" tabindex="-1"></a>@sec-two-continuous-predictors-5</span>
<span id="cb88-1013"><a href="#cb88-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1014"><a href="#cb88-1014" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Please provide an interpretation of all four regression coefficients in the centered model. Your interpretations should make reference to the situation where one or both predictors are equal to zero (see @eq-simple-5 above) and should also mentioned the interpretation of the value of zero for the centered variables.</span>
<span id="cb88-1015"><a href="#cb88-1015" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1016"><a href="#cb88-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1019"><a href="#cb88-1019" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1020"><a href="#cb88-1020" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb88-1021"><a href="#cb88-1021" aria-hidden="true" tabindex="-1"></a>mod8 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb88-1022"><a href="#cb88-1022" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod8)</span>
<span id="cb88-1023"><a href="#cb88-1023" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1024"><a href="#cb88-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1025"><a href="#cb88-1025" aria-hidden="true" tabindex="-1"></a>@sec-two-categorical-predictors-5</span>
<span id="cb88-1026"><a href="#cb88-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1027"><a href="#cb88-1027" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Please take a moment to write down your interpretation of the figure below, focussing on how it illustrates an interaction between SES and Pre-K. Additionally, please describe how the figure would be different if there was no interaction between Pre-K and SES. </span>
<span id="cb88-1028"><a href="#cb88-1028" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1029"><a href="#cb88-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1030"><a href="#cb88-1030" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.align = 'center'}</span></span>
<span id="cb88-1031"><a href="#cb88-1031" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb88-1032"><a href="#cb88-1032" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb88-1033"><a href="#cb88-1033" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb88-1034"><a href="#cb88-1034" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb88-1035"><a href="#cb88-1035" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb88-1036"><a href="#cb88-1036" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb88-1037"><a href="#cb88-1037" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb88-1038"><a href="#cb88-1038" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb88-1039"><a href="#cb88-1039" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span>
<span id="cb88-1040"><a href="#cb88-1040" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1041"><a href="#cb88-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1042"><a href="#cb88-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1043"><a href="#cb88-1043" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The output below shows the summary for a model that regresses Math Achievement on Pre-K, SES, and their interaction. Please write down an interpretation of magnitude, direction, and statistical significance of each regression coefficient in this output (including the intercept), and be prepared to share your answers in class. Remember that <span class="in">`wksesq5`</span> is the variable code for the SES quintiles -- the digit that follows the variable code indicates the level of variable. It may be helpful to refer to the previous figure in your interpretations. </span>
<span id="cb88-1044"><a href="#cb88-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1047"><a href="#cb88-1047" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1048"><a href="#cb88-1048" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb88-1049"><a href="#cb88-1049" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb88-1050"><a href="#cb88-1050" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1051"><a href="#cb88-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1052"><a href="#cb88-1052" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Please write down your interpretation of the ANOVA table and R-squared (eta-squared) coefficients below and be prepared to share you thoughts in class. Note that the ANOVA output leads to different conclusions than the regression output above. We will discuss the discrepancies between the ANOVA and regression output in class. </span>
<span id="cb88-1053"><a href="#cb88-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1054"><a href="#cb88-1054" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1057"><a href="#cb88-1057" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1058"><a href="#cb88-1058" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA Table</span></span>
<span id="cb88-1059"><a href="#cb88-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span>
<span id="cb88-1060"><a href="#cb88-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1061"><a href="#cb88-1061" aria-hidden="true" tabindex="-1"></a><span class="co"># R-squared (eta-squared)</span></span>
<span id="cb88-1062"><a href="#cb88-1062" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("effectsize")</span></span>
<span id="cb88-1063"><a href="#cb88-1063" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span>
<span id="cb88-1064"><a href="#cb88-1064" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1065"><a href="#cb88-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1066"><a href="#cb88-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1067"><a href="#cb88-1067" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises {#sec-exercises-5}</span></span>
<span id="cb88-1068"><a href="#cb88-1068" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1069"><a href="#cb88-1069" aria-hidden="true" tabindex="-1"></a>These exercises provide an overview of how to compute interactions using the <span class="in">`lm`</span> function, how to center continuous predictors, and how to follow-up significant interactions with the <span class="in">`emmeans`</span> package. We will go through this material in class together, so you don't need to work on it before class (but you can if you want.) </span>
<span id="cb88-1070"><a href="#cb88-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1071"><a href="#cb88-1071" aria-hidden="true" tabindex="-1"></a>Before staring this section, you may find it useful to scroll to the top of the page, click on the "&lt;/&gt; Code" menu, and select "Show All Code."</span>
<span id="cb88-1072"><a href="#cb88-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1073"><a href="#cb88-1073" aria-hidden="true" tabindex="-1"></a><span class="fu">### Binary + continuous + interaction</span></span>
<span id="cb88-1074"><a href="#cb88-1074" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1075"><a href="#cb88-1075" aria-hidden="true" tabindex="-1"></a>There are multiple ways of implementing interactions in R. </span>
<span id="cb88-1076"><a href="#cb88-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1077"><a href="#cb88-1077" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We can "hard code" new variables into our data (e.g., the product of a binary gender variable and reading)</span>
<span id="cb88-1078"><a href="#cb88-1078" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-1079"><a href="#cb88-1079" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We can use R's formula notation for single term interactions (<span class="in">`:`</span>)</span>
<span id="cb88-1080"><a href="#cb88-1080" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-1081"><a href="#cb88-1081" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>We can use R's formula notation for factorial interactions (<span class="in">`*`</span>)</span>
<span id="cb88-1082"><a href="#cb88-1082" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-1083"><a href="#cb88-1083" aria-hidden="true" tabindex="-1"></a>The following code illustrates the three approaches and shows that they all producing the same output. In general, the <span class="in">`*`</span> syntax is the easiest to use, so we will stick with that one going forward. The variables used in the example are from the NELS data: </span>
<span id="cb88-1084"><a href="#cb88-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1085"><a href="#cb88-1085" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`achmat12`</span> is Mat Achievement (percent correct on a math test) in grade 12. </span>
<span id="cb88-1086"><a href="#cb88-1086" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`achrdg12`</span> is Reading Achievement (percent correct on a reading test) in grade 12. </span>
<span id="cb88-1087"><a href="#cb88-1087" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`gender`</span> is dichotomous encoding of gender with values <span class="in">`Male`</span> and <span class="in">`Female`</span> (it is not a binary variable, but a factor, as discussed in @sec-exercises-4. </span>
<span id="cb88-1088"><a href="#cb88-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1091"><a href="#cb88-1091" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1092"><a href="#cb88-1092" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via hard coding</span></span>
<span id="cb88-1093"><a href="#cb88-1093" aria-hidden="true" tabindex="-1"></a>genderXreading <span class="ot">&lt;-</span> (<span class="fu">as.numeric</span>(gender) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> achrdg12</span>
<span id="cb88-1094"><a href="#cb88-1094" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> genderXreading)</span>
<span id="cb88-1095"><a href="#cb88-1095" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1)</span>
<span id="cb88-1096"><a href="#cb88-1096" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1097"><a href="#cb88-1097" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via `:` operator</span></span>
<span id="cb88-1098"><a href="#cb88-1098" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12 <span class="sc">+</span> gender <span class="sc">+</span> achrdg12<span class="sc">:</span>gender)</span>
<span id="cb88-1099"><a href="#cb88-1099" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod2)</span>
<span id="cb88-1100"><a href="#cb88-1100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1101"><a href="#cb88-1101" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction via `*` operator</span></span>
<span id="cb88-1102"><a href="#cb88-1102" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>gender)</span>
<span id="cb88-1103"><a href="#cb88-1103" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod3)</span>
<span id="cb88-1104"><a href="#cb88-1104" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1105"><a href="#cb88-1105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1106"><a href="#cb88-1106" aria-hidden="true" tabindex="-1"></a>Before moving on, check your interpretation of the coefficients in the models. In particular, what does the regression coefficient on the interaction term mean?</span>
<span id="cb88-1107"><a href="#cb88-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1108"><a href="#cb88-1108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Centering continuous predictors</span></span>
<span id="cb88-1109"><a href="#cb88-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1110"><a href="#cb88-1110" aria-hidden="true" tabindex="-1"></a>As noted in @sec-binary-continuous-interaction-5, the regression coefficient on Gender is not very interpretable when there is an interaction in the model. In the above output, the coefficient on gender tells us the gender gap in Math Achievement when <span class="in">`achrdg12 = 0`</span>. We can fix this issue by re-scaling <span class="in">`achrdg12`</span> so that zero has a meaningful value. One widely used approach is to center <span class="in">`achrdg12`</span> at its mean. When a variable is centered at its mean it is called a *deviation score.*</span>
<span id="cb88-1111"><a href="#cb88-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1112"><a href="#cb88-1112" aria-hidden="true" tabindex="-1"></a>Let's see what happens to our regression output when we use deviation scores for <span class="in">`achrdg12`</span> instead of the "raw" score</span>
<span id="cb88-1113"><a href="#cb88-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1116"><a href="#cb88-1116" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1117"><a href="#cb88-1117" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-run the model with reading centered at its mean</span></span>
<span id="cb88-1118"><a href="#cb88-1118" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb88-1119"><a href="#cb88-1119" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>gender)</span>
<span id="cb88-1120"><a href="#cb88-1120" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span>
<span id="cb88-1121"><a href="#cb88-1121" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1122"><a href="#cb88-1122" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-1123"><a href="#cb88-1123" aria-hidden="true" tabindex="-1"></a>Note that the intercept and the regression coefficient on Gender have changed values compared to <span class="in">`mod3`</span>. What is the interpretation of these coefficients in the new model? </span>
<span id="cb88-1124"><a href="#cb88-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1125"><a href="#cb88-1125" aria-hidden="true" tabindex="-1"></a><span class="fu">### Breaking down a significant interaction</span></span>
<span id="cb88-1126"><a href="#cb88-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1127"><a href="#cb88-1127" aria-hidden="true" tabindex="-1"></a>Next, let's plot our model with the interaction term.  One advantage of having everything in a single model is that we can level-up our plotting! The following code uses the <span class="in">`visreg`</span> package.  Note that the error bands in the plot are produced using the standard errors from <span class="in">`emmeans`</span>, which is discussed below. If you want to know more about how visreg works, type <span class="in">`help(visreg)`</span>.</span>
<span id="cb88-1128"><a href="#cb88-1128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1131"><a href="#cb88-1131" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1132"><a href="#cb88-1132" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package if you haven't already done so</span></span>
<span id="cb88-1133"><a href="#cb88-1133" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("visreg")</span></span>
<span id="cb88-1134"><a href="#cb88-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1135"><a href="#cb88-1135" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb88-1136"><a href="#cb88-1136" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visreg)</span>
<span id="cb88-1137"><a href="#cb88-1137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1138"><a href="#cb88-1138" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod3, <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, <span class="at">by =</span> <span class="st">"gender"</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>)</span>
<span id="cb88-1139"><a href="#cb88-1139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1140"><a href="#cb88-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1141"><a href="#cb88-1141" aria-hidden="true" tabindex="-1"></a>If the interaction is significant, then we usually want to report a bit more information about how the focal relationship changes as a function of the moderators. There are two main ways to do this: </span>
<span id="cb88-1142"><a href="#cb88-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1143"><a href="#cb88-1143" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Marginal effects (aka marginal means, least squares means, adjusted means): This approach is used when the focal predictor is categorical and we want to compare means across the categories, conditional on levels of the moderator. </span>
<span id="cb88-1144"><a href="#cb88-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1145"><a href="#cb88-1145" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Simple trends (aka simple slopes): This approach is used when the focal predictor is continuous and we want to examine the slopes of the simple trends, conditional on the moderator. </span>
<span id="cb88-1146"><a href="#cb88-1146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1147"><a href="#cb88-1147" aria-hidden="true" tabindex="-1"></a>Usually, the researcher will chose one or the other approach, whichever is best suited to address the research questions of interest. Our example was motivated by consideration of the gender gap in STEM (i.e., the relationship between a STEM and a categorical predictor), so the marginal effects approach is better suited. We will also illustrate simple trends, just to show how that approach works. </span>
<span id="cb88-1148"><a href="#cb88-1148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1149"><a href="#cb88-1149" aria-hidden="true" tabindex="-1"></a><span class="fu">### Marginal effects</span></span>
<span id="cb88-1150"><a href="#cb88-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1151"><a href="#cb88-1151" aria-hidden="true" tabindex="-1"></a>Let's breakdown the interaction by asking how the relationship between Math and Gender (i.e., the gender achievement gap in Math) changes as a function of Reading. This can be done using <span class="in">`emmeans`</span> package, and the main function in that pacakge  is also called <span class="in">`emmeans`</span>.</span>
<span id="cb88-1152"><a href="#cb88-1152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1153"><a href="#cb88-1153" aria-hidden="true" tabindex="-1"></a>The three main arguments for the <span class="in">`emmeans`</span> function: </span>
<span id="cb88-1154"><a href="#cb88-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1155"><a href="#cb88-1155" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`object`</span> -- the output of <span class="in">`lm`</span>. This is the first argument</span>
<span id="cb88-1156"><a href="#cb88-1156" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`specs`</span> -- which factors in the model we want the means of (i.e., the focal predictor)</span>
<span id="cb88-1157"><a href="#cb88-1157" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`by`</span> -- which predictor(s) we want to use to breakdown the means (i.e., the moderator(s))</span>
<span id="cb88-1158"><a href="#cb88-1158" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb88-1159"><a href="#cb88-1159" aria-hidden="true" tabindex="-1"></a>We can use <span class="in">`emmeans`</span> to compute the marginal effect at the mean (MEM) as follows: </span>
<span id="cb88-1160"><a href="#cb88-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1163"><a href="#cb88-1163" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1164"><a href="#cb88-1164" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the package if you haven't already done so</span></span>
<span id="cb88-1165"><a href="#cb88-1165" aria-hidden="true" tabindex="-1"></a>  <span class="co"># install.packages("emmeans")</span></span>
<span id="cb88-1166"><a href="#cb88-1166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1167"><a href="#cb88-1167" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the package into memory</span></span>
<span id="cb88-1168"><a href="#cb88-1168" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb88-1169"><a href="#cb88-1169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1170"><a href="#cb88-1170" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emmeans function to get the gender means on math, broken down by reading</span></span>
<span id="cb88-1171"><a href="#cb88-1171" aria-hidden="true" tabindex="-1"></a>gap <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod3, <span class="at">specs =</span> <span class="st">"gender"</span>, <span class="at">by =</span> <span class="st">"achrdg12"</span>)</span>
<span id="cb88-1172"><a href="#cb88-1172" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gap)</span>
<span id="cb88-1173"><a href="#cb88-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1174"><a href="#cb88-1174" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the difference is significant</span></span>
<span id="cb88-1175"><a href="#cb88-1175" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span>
<span id="cb88-1176"><a href="#cb88-1176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1177"><a href="#cb88-1177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1178"><a href="#cb88-1178" aria-hidden="true" tabindex="-1"></a>In the above output, we only get one Gender difference in Math, and that is computed for the value of <span class="in">`achrdg12 = 55.6`</span>, which is the mean value of Reading. As noted, this is called the marginal effect at the mean (MEM).   </span>
<span id="cb88-1179"><a href="#cb88-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1180"><a href="#cb88-1180" aria-hidden="true" tabindex="-1"></a>It is often more helpful to report Gender difference for multiple different values of <span class="in">`achrdg12`</span>, which is called MERV (marginal effects at representative values). While there are many ways to  chose the representative values, one convenient approach approach is to use the quartiles of <span class="in">`achrdg12`</span>. This is accomplished using the <span class="in">`cov.reduce`</span> argument of <span class="in">`emmeans`</span> as follows.   </span>
<span id="cb88-1181"><a href="#cb88-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1184"><a href="#cb88-1184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1185"><a href="#cb88-1185" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the the covarate reduce option of emmeans with the quantile function</span></span>
<span id="cb88-1186"><a href="#cb88-1186" aria-hidden="true" tabindex="-1"></a>gap_quartiles <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod3, <span class="at">specs =</span> <span class="st">"gender"</span>, <span class="at">by =</span> <span class="st">"achrdg12"</span>, <span class="at">cov.reduce =</span> quantile)</span>
<span id="cb88-1187"><a href="#cb88-1187" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gap_quartiles)</span>
<span id="cb88-1188"><a href="#cb88-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1189"><a href="#cb88-1189" aria-hidden="true" tabindex="-1"></a><span class="co"># Test whether the gender difference in math achievement is significant at each quartile of reading achievement</span></span>
<span id="cb88-1190"><a href="#cb88-1190" aria-hidden="true" tabindex="-1"></a><span class="fu">contrast</span>(gap_quartiles, <span class="at">method =</span> <span class="st">"pairwise"</span>)</span>
<span id="cb88-1191"><a href="#cb88-1191" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1192"><a href="#cb88-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1193"><a href="#cb88-1193" aria-hidden="true" tabindex="-1"></a>At this point, you should be able to summarize your conclusions about the gender gap in Math and how it depends on Reading.  </span>
<span id="cb88-1194"><a href="#cb88-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1195"><a href="#cb88-1195" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simple trends</span></span>
<span id="cb88-1196"><a href="#cb88-1196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1197"><a href="#cb88-1197" aria-hidden="true" tabindex="-1"></a>Next we will show how to use  <span class="in">`emtrends`</span> to test the conditional or "simple" slopes of Math on Reading, given Gender. As mentioned, this approach is not very well suited to the example, but we are going through it here just to illustrate how to do this type of analysis. </span>
<span id="cb88-1198"><a href="#cb88-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1199"><a href="#cb88-1199" aria-hidden="true" tabindex="-1"></a>The three main arguments for <span class="in">`emtrends`</span> are</span>
<span id="cb88-1200"><a href="#cb88-1200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1201"><a href="#cb88-1201" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`object`</span> -- the output of <span class="in">`lm`</span>. This is the first argument</span>
<span id="cb88-1202"><a href="#cb88-1202" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`var`</span> -- which continuous predictor in the model we want the slopes of</span>
<span id="cb88-1203"><a href="#cb88-1203" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span><span class="in">`specs`</span> -- which factor predictor(s)  in the model to break the trend down by</span>
<span id="cb88-1204"><a href="#cb88-1204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1205"><a href="#cb88-1205" aria-hidden="true" tabindex="-1"></a>Let's see how it works.</span>
<span id="cb88-1206"><a href="#cb88-1206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1209"><a href="#cb88-1209" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1210"><a href="#cb88-1210" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the emtrends function to get the regression coefficients on reading, broken down by gender</span></span>
<span id="cb88-1211"><a href="#cb88-1211" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span> <span class="fu">emtrends</span>(mod3, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"gender"</span>)</span>
<span id="cb88-1212"><a href="#cb88-1212" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_slopes)</span>
<span id="cb88-1213"><a href="#cb88-1213" aria-hidden="true" tabindex="-1"></a><span class="fu">test</span>(simple_slopes)</span>
<span id="cb88-1214"><a href="#cb88-1214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1215"><a href="#cb88-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1216"><a href="#cb88-1216" aria-hidden="true" tabindex="-1"></a>The foregoing analysis tells us how the relationship between reading and math changes as a function of gender, and, in particular, whether the simple slopes are significant for males and females. Recall that the simple slope for females (the group coded zero) is just the regression coefficient on reading in the original <span class="in">`lm`</span> output. So, the only new thing this output gives us is the simple slope for males. </span>
<span id="cb88-1217"><a href="#cb88-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1218"><a href="#cb88-1218" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two continuous predictors</span></span>
<span id="cb88-1219"><a href="#cb88-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1220"><a href="#cb88-1220" aria-hidden="true" tabindex="-1"></a>Interactions with continuous predictors are basically the same as for continuous and categorical. One main issue is that we should always center the predictors, not only to facilitate interpretation of the regression coefficients, but also to reduce the correlation between the main effects and the interaction. </span>
<span id="cb88-1221"><a href="#cb88-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1222"><a href="#cb88-1222" aria-hidden="true" tabindex="-1"></a>For an example, let's replace gender with SES from our previous analysis. Apologies that this new example is mainly for convenience and doesn't represent a great research question about, e.g., about why the relationships between math and reading might change as a function of SES!</span>
<span id="cb88-1223"><a href="#cb88-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1224"><a href="#cb88-1224" aria-hidden="true" tabindex="-1"></a>Here we will focus on how centering affects the results of a regression with interactions among continuous predictors.</span>
<span id="cb88-1225"><a href="#cb88-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1228"><a href="#cb88-1228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1229"><a href="#cb88-1229" aria-hidden="true" tabindex="-1"></a><span class="co"># Without centering</span></span>
<span id="cb88-1230"><a href="#cb88-1230" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12<span class="sc">*</span>ses)</span>
<span id="cb88-1231"><a href="#cb88-1231" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1)</span>
<span id="cb88-1232"><a href="#cb88-1232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1233"><a href="#cb88-1233" aria-hidden="true" tabindex="-1"></a><span class="co"># With centering</span></span>
<span id="cb88-1234"><a href="#cb88-1234" aria-hidden="true" tabindex="-1"></a>achrdg12_dev <span class="ot">&lt;-</span> achrdg12 <span class="sc">-</span> <span class="fu">mean</span>(achrdg12)</span>
<span id="cb88-1235"><a href="#cb88-1235" aria-hidden="true" tabindex="-1"></a>ses_dev <span class="ot">&lt;-</span> ses <span class="sc">-</span> <span class="fu">mean</span>(ses)</span>
<span id="cb88-1236"><a href="#cb88-1236" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(achmat12 <span class="sc">~</span> achrdg12_dev<span class="sc">*</span>ses_dev)</span>
<span id="cb88-1237"><a href="#cb88-1237" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod2)</span>
<span id="cb88-1238"><a href="#cb88-1238" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1239"><a href="#cb88-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1240"><a href="#cb88-1240" aria-hidden="true" tabindex="-1"></a>We can see that, while both models account for the same overall variation in math, SES is significant in the centered model. This has to do both with changing the interpretation of the coefficient (it now represents the relationship between math and reading for students with average reading) and because it is no longer so highly redundant with the interaction term. </span>
<span id="cb88-1241"><a href="#cb88-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1242"><a href="#cb88-1242" aria-hidden="true" tabindex="-1"></a>Although the interaction with SES was not significant in either model, let's break down the interaction with <span class="in">`emtrends`</span> just to see how it works. This time we will use the <span class="in">`at`</span> option rather than the 'cov.reduce<span class="in">` option to break down the interaction. The values 9, 19, and 28 are the 10th, 50th, and 90th percentile of SES, which is the same approach `</span>visreg<span class="in">` uses (You can overwrite the defaults using the `</span>breaks<span class="in">` argument -- see `</span>help(visreg)`).</span>
<span id="cb88-1243"><a href="#cb88-1243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1246"><a href="#cb88-1246" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1247"><a href="#cb88-1247" aria-hidden="true" tabindex="-1"></a><span class="co"># Break down interaction with SES as moderator</span></span>
<span id="cb88-1248"><a href="#cb88-1248" aria-hidden="true" tabindex="-1"></a>simple_slopes <span class="ot">&lt;-</span><span class="fu">emtrends</span>(mod5, <span class="at">var =</span> <span class="st">"achrdg12"</span>, <span class="at">specs =</span> <span class="st">"ses"</span>, <span class="at">at =</span> <span class="fu">list</span>(<span class="at">ses =</span> <span class="fu">c</span>(<span class="dv">9</span>, <span class="dv">19</span>, <span class="dv">28</span>)))</span>
<span id="cb88-1249"><a href="#cb88-1249" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_slopes)</span>
<span id="cb88-1250"><a href="#cb88-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1251"><a href="#cb88-1251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1252"><a href="#cb88-1252" aria-hidden="true" tabindex="-1"></a>Finally let's summarize our (non significant) interaction with a nice plot. </span>
<span id="cb88-1253"><a href="#cb88-1253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1256"><a href="#cb88-1256" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1257"><a href="#cb88-1257" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that band = F removes the confidence intervals</span></span>
<span id="cb88-1258"><a href="#cb88-1258" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(mod5, <span class="at">xvar =</span> <span class="st">"achrdg12"</span>, <span class="at">by =</span> <span class="st">"ses"</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>, <span class="at">band =</span> F)</span>
<span id="cb88-1259"><a href="#cb88-1259" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1260"><a href="#cb88-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1261"><a href="#cb88-1261" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two categorical predictors</span></span>
<span id="cb88-1262"><a href="#cb88-1262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1263"><a href="#cb88-1263" aria-hidden="true" tabindex="-1"></a>For this topic we will switch over to the ECLS data and examine how SES and Pre-K attendance interact to predict Math Achievement at the beginning of Kindergarten. The variables we will examine are</span>
<span id="cb88-1264"><a href="#cb88-1264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1265"><a href="#cb88-1265" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Math Achievement at the beginning of K (<span class="in">`c1rmscal`</span>). This is the number of correct questions on a test with approximately 70 items. </span>
<span id="cb88-1266"><a href="#cb88-1266" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Whether the child attended Pre-K (<span class="in">`p1center`</span>). This is a binary variable that indicates pre-K attendance. </span>
<span id="cb88-1267"><a href="#cb88-1267" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>SES, coded as quintiles (<span class="in">`wksesq5`</span>). We will denote this variable as SES, but keep in mind it is quintiles in this example (e.g., SES = 1 are the respondents with SES between the minimum and the first quintile). </span>
<span id="cb88-1268"><a href="#cb88-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1269"><a href="#cb88-1269" aria-hidden="true" tabindex="-1"></a>The regression model is as follows. Note that both variables need to be converted to factors in R, so that R will treat them as categorical variables. Also recall that in R the default contrast coding for categorical predictors is reference-group coding. </span>
<span id="cb88-1270"><a href="#cb88-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1273"><a href="#cb88-1273" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1274"><a href="#cb88-1274" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS2577.Rdata"</span>)</span>
<span id="cb88-1275"><a href="#cb88-1275" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>prek <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="dv">2</span> <span class="sc">-</span> ecls<span class="sc">$</span>p1center)</span>
<span id="cb88-1276"><a href="#cb88-1276" aria-hidden="true" tabindex="-1"></a>ecls<span class="sc">$</span>wksesq5 <span class="ot">&lt;-</span> <span class="fu">factor</span>(ecls<span class="sc">$</span>wksesq5)</span>
<span id="cb88-1277"><a href="#cb88-1277" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> prek<span class="sc">*</span>wksesq5, <span class="at">data =</span> ecls)</span>
<span id="cb88-1278"><a href="#cb88-1278" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb88-1279"><a href="#cb88-1279" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1280"><a href="#cb88-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1281"><a href="#cb88-1281" aria-hidden="true" tabindex="-1"></a>To facilitate interpretation of the ouput, you can refer to the plot below. Each regression coefficient in the output corresponds to a feature of this plot. </span>
<span id="cb88-1282"><a href="#cb88-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1285"><a href="#cb88-1285" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1286"><a href="#cb88-1286" aria-hidden="true" tabindex="-1"></a>visreg<span class="sc">::</span><span class="fu">visreg</span>(mod, <span class="at">xvar =</span> <span class="st">"wksesq5"</span>, <span class="at">by =</span> <span class="st">"prek"</span>, </span>
<span id="cb88-1287"><a href="#cb88-1287" aria-hidden="true" tabindex="-1"></a>               <span class="at">partial =</span> F, <span class="at">rug =</span> F, <span class="at">overlay =</span> T, </span>
<span id="cb88-1288"><a href="#cb88-1288" aria-hidden="true" tabindex="-1"></a>               <span class="at">strip.names =</span> T, <span class="at">xlab =</span> <span class="st">"SES"</span>, </span>
<span id="cb88-1289"><a href="#cb88-1289" aria-hidden="true" tabindex="-1"></a>               <span class="at">ylab =</span> <span class="st">"Math Achievement in K"</span>)</span>
<span id="cb88-1290"><a href="#cb88-1290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1291"><a href="#cb88-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1292"><a href="#cb88-1292" aria-hidden="true" tabindex="-1"></a>In order to summarize the model as an ANOVA table, we can use the following code. Note that the ANOVA output tests the variance explained (i.e., R-squared) of the original variables, and does not include dummy variables. </span>
<span id="cb88-1293"><a href="#cb88-1293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1296"><a href="#cb88-1296" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1297"><a href="#cb88-1297" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod)</span>
<span id="cb88-1298"><a href="#cb88-1298" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1299"><a href="#cb88-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1300"><a href="#cb88-1300" aria-hidden="true" tabindex="-1"></a>In an ANOVA context, the R-squared statistics are called  eta-squared. They are reported below: </span>
<span id="cb88-1301"><a href="#cb88-1301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1304"><a href="#cb88-1304" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb88-1305"><a href="#cb88-1305" aria-hidden="true" tabindex="-1"></a>effectsize<span class="sc">::</span><span class="fu">eta_squared</span>(mod, <span class="at">partial =</span> F)</span>
<span id="cb88-1306"><a href="#cb88-1306" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb88-1307"><a href="#cb88-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-1308"><a href="#cb88-1308" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo = F}</span></span>
<span id="cb88-1309"><a href="#cb88-1309" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb88-1310"><a href="#cb88-1310" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(NELS)</span>
<span id="cb88-1311"><a href="#cb88-1311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>
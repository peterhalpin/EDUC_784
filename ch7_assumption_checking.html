<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EDUC 784 - 7&nbsp; Assumption checking</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ch8_loglinear.html" rel="next">
<link href="./ch6_model_building.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ch7_assumption_checking.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assumption checking</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">EDUC 784</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch1_review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch2_simple_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Simple regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch3_two_predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Two predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch4_categorical_predictors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Categorical predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch5_interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Interactions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch6_model_building.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model building</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch7_assumption_checking.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assumption checking</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ch8_loglinear.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Log-linear regression</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-recap-7" id="toc-sec-recap-7" class="nav-link active" data-scroll-target="#sec-recap-7"><span class="header-section-number">7.1</span> Recap of population model</a></li>
  <li><a href="#sec-linearity-7" id="toc-sec-linearity-7" class="nav-link" data-scroll-target="#sec-linearity-7"><span class="header-section-number">7.2</span> Linearity</a>
  <ul class="collapse">
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">7.2.1</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-homoskedasticity-7" id="toc-sec-homoskedasticity-7" class="nav-link" data-scroll-target="#sec-homoskedasticity-7"><span class="header-section-number">7.3</span> Homoskedasticity</a>
  <ul class="collapse">
  <li><a href="#sec-heteroskedasticity-7" id="toc-sec-heteroskedasticity-7" class="nav-link" data-scroll-target="#sec-heteroskedasticity-7"><span class="header-section-number">7.3.1</span> Dealing with Heteroskedasticity</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1"><span class="header-section-number">7.3.2</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-normality-7" id="toc-sec-normality-7" class="nav-link" data-scroll-target="#sec-normality-7"><span class="header-section-number">7.4</span> Normality</a>
  <ul class="collapse">
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2"><span class="header-section-number">7.4.1</span> Summary</a></li>
  </ul></li>
  <li><a href="#sec-worked-example-7" id="toc-sec-worked-example-7" class="nav-link" data-scroll-target="#sec-worked-example-7"><span class="header-section-number">7.5</span> A worked example</a></li>
  <li><a href="#sec-diagnostics-7" id="toc-sec-diagnostics-7" class="nav-link" data-scroll-target="#sec-diagnostics-7"><span class="header-section-number">7.6</span> Diagnostics*</a>
  <ul class="collapse">
  <li><a href="#leverage" id="toc-leverage" class="nav-link" data-scroll-target="#leverage"><span class="header-section-number">7.6.1</span> Leverage</a></li>
  <li><a href="#distance-residuals" id="toc-distance-residuals" class="nav-link" data-scroll-target="#distance-residuals"><span class="header-section-number">7.6.2</span> Distance (residuals)</a></li>
  <li><a href="#influence" id="toc-influence" class="nav-link" data-scroll-target="#influence"><span class="header-section-number">7.6.3</span> Influence</a></li>
  <li><a href="#a-more-realistic-example" id="toc-a-more-realistic-example" class="nav-link" data-scroll-target="#a-more-realistic-example"><span class="header-section-number">7.6.4</span> A more realistic example</a></li>
  </ul></li>
  <li><a href="#sec-workbook-7" id="toc-sec-workbook-7" class="nav-link" data-scroll-target="#sec-workbook-7"><span class="header-section-number">7.7</span> Workbook</a></li>
  <li><a href="#sec-exercises-7" id="toc-sec-exercises-7" class="nav-link" data-scroll-target="#sec-exercises-7"><span class="header-section-number">7.8</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-chap-7" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Assumption checking</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In <a href="ch2_simple_regression.html#sec-population-model-2"><span>Section&nbsp;2.5</span></a> we introduced the population model for linear regression. But how do we know whether this model applies to our data? That is the question we address in this chapter. In particular, we discuss data analyses that can be used to better understand whether the assumptions made when defining the population model for linear regression are consistent with our data. This is referred to <em>assumption checking</em>.</p>
<p>The three assumptions are (don’t worry, we review them again in the next section):</p>
<ul>
<li>Normality of residuals</li>
<li>Homoskedasticity of residuals</li>
<li>Linearity of the conditional mean (regression) function</li>
</ul>
<p>Why do we care about these assumptions? Well, if all of the population assumptions of linear regression are not met, any of the following can happen:</p>
<ul>
<li>Regression coefficients and R-squared could be biased</li>
<li>Standard errors could be too small (or too large)</li>
<li>t- and F-tests could be too small (or too large)</li>
<li>p-values could be too small (or too large)</li>
<li>Confidence intervals could be too small (or too large)</li>
</ul>
<p>Basically, all of the numbers we get in R’s <code>summary(lm)</code> output could be wrong.</p>
<p>The interpretation of assumptions in regression is a bit subtle. Assumptions are conditions we need to be true in order for the results of analysis to be valid. But, we don’t really care about the assumptions in their own right. For example, we don’t really care if the regression residuals are normally distributed – we just care if there are any violations of this assumption that might be affecting the results our analysis. If there is no evidence that an assumption is problematic, we proceed with the main analysis as intended. If there is evidence that an assumption is violated, we can modify the analysis as required. This chapter focuses on checking assumptions, and the following two chapters talk about strategies for dealing with assumption violations.</p>
<p>Assumption checking usually involves plotting the residuals from a regression model and trying to interpret what the plots tell us about the population model. The main focus of this chapter is to introduce you to these plots and how to interpret them. Sometimes assumption checking can feel a bit like reading tea leaves, because interpreting plots can be pretty subjective. Honing your interpretation will happen gradually with experience.</p>
<p>In this chapter we also address how to deal with heteroskedasticity in regression models. The short version is that heteroskedasticity does not affect the OLS estimates of the regression coefficients, it only affects their standard errors (and, consequently, the t-values, p-values, and confidence intervals). There are corrections to the standard errors that can be used to address heteroskedasticity. In particular, we will focus on one widely used procedure called heteroskedasticity-consistent (HC) standard errors. These “corrected” standard errors are often larger then than the “uncorrected” standard errors, which is why we prefer to use the latter when homoskedasticity is viable.</p>
<p>A related topic, <em>regression diagnostics</em>, is also introduced in this chapter. Diagnostics are procedures for detecting outliers. Unlike assumption checking, which focuses on the model <em>per se</em>, diagnostics focus on individual data points. We only cover the basics behind diagnostics in this chapter and the material is optional (i.e., it will not be assessed in this course, but you may find it useful for your research).</p>
<p>Regression diagnostics and outlier detection can be useful for identifying potentially problematic data points, but it is almost never the the case that data points should be omitted because they are outliers. Unless you can find something specifically wrong with a data point (e.g., a data entry error) you should not omit data. A better way to deal with outliers is by using statistical procedures that are specifically designed to deal with them, which is a field of study called <em>robust statistics</em>. Robust regression is an advanced topic that we won’t get to in this course, but check out this resource if you are interested and feel free to ask questions in class: <a href="https://cran.r-project.org/web/views/Robust.html">https://cran.r-project.org/web/views/Robust.html</a>.</p>
<section id="sec-recap-7" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="sec-recap-7"><span class="header-section-number">7.1</span> Recap of population model</h2>
<p>Let’s start with a recap of the population model for linear regression. This was introduced for simple linear regression in <a href="ch2_simple_regression.html#sec-population-model-2"><span>Section&nbsp;2.5</span></a>. To restate the assumptions for multiple linear regression, we will use the vector notation</p>
<p><span class="math display">\[\mathbf X = [X_1, X_2, \dots, X_K]\]</span></p>
<p>to represent the predictor variables. For our purposes, the vector <span class="math inline">\(\mathbf X\)</span> is just a list of all of the predictors in a model. The outcome variable is denoted as <span class="math inline">\(Y\)</span>, as usual.</p>
<ol type="1">
<li>Normality: The distribution of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(\mathbf X\)</span> is normal for all values of <span class="math inline">\(\mathbf X\)</span>.</li>
</ol>
<p><span class="math display">\[ Y | \mathbf X \sim  N(\mu_{Y | \mathbf X} , \sigma_{Y | \mathbf X}) \]</span></p>
<ol start="2" type="1">
<li>Homoskedasticity: The conditional distributions have equal variances (also called homogeneity of variance, or just equal variances).</li>
</ol>
<p><span class="math display">\[ \sigma_{Y| \mathbf X} = \sigma \]</span></p>
<ol start="3" type="1">
<li>Linearity: The means of the conditional distributions are a linear function of <span class="math inline">\(\mathbf X\)</span>.</li>
</ol>
<p><span class="math display">\[ \mu_{Y| \mathbf X} = b_0 + \sum_{k = 1}^K b_k X_k \]</span></p>
<p>These three assumptions can also be summarized in term of the regression residuals. Recall that residuals are computed as <span class="math inline">\(\epsilon = Y - \mu_{Y|\mathbf X}\)</span>. If the three assumptions of linear regression hold, then the regression residuals should be normally distributed with mean zero and constant variance, for every value of the predictors:</p>
<p><span class="math display">\[\epsilon \mid \mathbf {X} \sim N(0, \sigma). \]</span></p>
<p><a href="#fig-pop-model-e">Figure&nbsp;<span>7.1</span></a> presents the population model in terms of the residuals. This plot is similar <a href="ch2_simple_regression.html#fig-pop-model">Figure&nbsp;<span>2.4</span></a>, but is modified for the multiple regression setting by using predicted values and residuals as the axes, rather than <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The plots we look at in the following sections are sample analogues to this population model – they plot residuals against predicted values.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-pop-model-e" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="files/images/pop_model_e.png" class="img-fluid figure-img" width="424"></p>
<figcaption class="figure-caption">Figure&nbsp;7.1: The Multiple Regression Population Model.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="sec-linearity-7" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-linearity-7"><span class="header-section-number">7.2</span> Linearity</h2>
<p>This assumption is about whether the regression function is “really” a line or if it could be better represented as some other relationship. A classic example is shown below. We address this example, which is taken from “Anscombe’s quartet”, in more detail in <a href="#sec-diagnostics-7"><span>Section&nbsp;7.6</span></a> (which is optional).</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-linearity in Anscombe's second example</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(anscombe)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> x2)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the raw data</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x2, y2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlab =</span> <span class="st">"X"</span>, <span class="at">ylab =</span> <span class="st">"Y"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to the residual vs fitted plot</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(anscombe)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-linearity1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-linearity1-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.2: Anscombe’s second dataset</figcaption>
</figure>
</div>
</div>
</div>
<p>The left hand panel of <a href="#fig-linearity1">Figure&nbsp;<span>7.2</span></a> shows the scatter plot of the example data. It should hopefully be obvious that the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> is not linear.</p>
<p>The right hand panel shows the residuals versus the predicted (“fitted”) values from the regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span>. It plots the residuals on the vertical axis and the fitted values (<span class="math inline">\(\hat Y\)</span>) on the horizontal axis. This is the sample analogue of the population model in <a href="#fig-pop-model-e">Figure&nbsp;<span>7.1</span></a>.</p>
<p>It is important to note the following about residual vs fitted plot:</p>
<ul>
<li><p>The key idea is that deviations from the regression line in the left hand panel correspond to deviations from the horizontal line at Residuals = 0 in the right hand panel. Recall that the residuals should all be centered around this horizontal line if the population model is true (see <a href="#fig-pop-model-e">Figure&nbsp;<span>7.1</span></a>). The non-linear trend is apparent in the in both panels, but in the residual vs fitted plot the nonlinearity is with reference to Residuals = 0.</p></li>
<li><p>The red line in the right hand panel is a locally weighted smoothed (“lowess”) regression line – it follows whatever trend is in the residuals without assuming the trend is linear.</p></li>
<li><p>The overall interpretation of the residual vs fitted plot is as follows:</p>
<ul>
<li>If the red line is roughly horizontal at Residuals = 0, we conclude that the assumption of linearity is not problematic for the data.</li>
<li>If the red line deviates systematically from a horizontal line at Residuals = 0, this is evidence that the assumption of linearity is problematic.</li>
</ul></li>
</ul>
<p>In <a href="#fig-linearity1">Figure&nbsp;<span>7.2</span></a>, the assumption of linearity is clearly not met. In fact, this is so obvious that we could see it in the regular scatter plot! So, you might be asking, why do we need the residual vs fitted plot? Well, the regular scatter plot is only useful for diagnosing linearity with a single predictor, whereas the residual vs fitted plots works any number of predictors. So, in general, it is much easier to check the assumption using the residual versus fitted plot, even if the patterns are a bit harder to interpret.</p>
<p><a href="#fig-linearity2">Figure&nbsp;<span>7.3</span></a> illustrates the residual vs fitted plot using a model with 2 predictors. <strong>Please write down whether you think the linearity assumption is problematic for the example below, and be sure to explain why with reference to the figure.</strong> Keep in mind that interpreting plots takes a bit of practice and in general there is no “right” answer. Rather, what I am looking for is an explanation of <em>why</em> you think the assumption is problematic or not. Your explanation should refer to the interpretation of residual vs fitted plots, as outlined above.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS250.RData"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(ecls)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model for example</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> ses_orig <span class="sc">+</span> t1learn, <span class="at">data =</span> ecls)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot resid vs fitted</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-linearity2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-linearity2-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.3: An example from ECLS.</figcaption>
</figure>
</div>
</div>
</div>
<p>Before moving on, let’s take a look at a few more examples. For each of the examples in <a href="#fig-linearity3">Figure&nbsp;<span>7.4</span></a>, <strong>please write down whether you think the linearity assumption is problematic and explain why with reference to the plots.</strong>. Hint: be careful not to over-interpret the lowess line in the tails of the plots, where only a few data points can have a big impact on the local trend. Focus your interpretation on the bulk of the data, and whether it shows a systemic trend away from a horizontal line at 0.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>}  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-linearity3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-linearity3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7.4: More examples.</figcaption>
</figure>
</div>
</div>
</div>
<section id="summary" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">7.2.1</span> Summary</h3>
<p>To check the assumption of linearity, we can use a residual vs predicted (fitted) plot.</p>
<ul>
<li><p>If the plot does not show a systematic trend other than a horizontal line at Residuals = 0, then there is no evidence against the assumption.</p></li>
<li><p>If the residuals do show a trend away from Residuals = 0, then we should worry about the assumption.</p></li>
<li><p>Don’t over interpret the tails of the lowess (red) lines in the R plots.</p></li>
<li><p>If the assumption is violated: consider a non-linear transformations of the <span class="math inline">\(Y\)</span> variable (<a href="ch8_loglinear.html"><span>Chapter&nbsp;8</span></a>) or adding quadratic or other non-linear terms to the model (<span class="quarto-unresolved-ref">?sec-chap-9</span>).</p></li>
</ul>
</section>
</section>
<section id="sec-homoskedasticity-7" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="sec-homoskedasticity-7"><span class="header-section-number">7.3</span> Homoskedasticity</h2>
<p>This assumption means that the variance of the residuals should not change as a function of the predicted values. Because we are again concerned with residuals and predicted values, we can re-use the same plot we used to check linearity. However, we are no longer interested in whether the lowess trend (red line) systematically deviates from zero – now we are interested in whether the range of the residuals (on the vertical axis) changes over the predicted values (on the horizontal axis).</p>
<p><a href="#fig-homo1">Figure&nbsp;<span>7.5</span></a> illustrates two data sets in which the assumption of linearity is met, but the right hand panel shows evidence of heteroskedasticity. This is apparent by observing the range of the residuals over values of <span class="math inline">\(\widehat Y\)</span>.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># homoskedastic example</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">rnorm</span>(<span class="dv">250</span>))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">250</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x <span class="sc">+</span> e</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod3, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Heteroskedastic example</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> y</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>y2[x <span class="sc">&gt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> x[x <span class="sc">&gt;</span> <span class="dv">0</span>] <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span> e[x <span class="sc">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>y2[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>] <span class="ot">&lt;-</span> x[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>] <span class="sc">+</span> .<span class="dv">3</span><span class="sc">*</span> e[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2<span class="sc">~</span>x)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-homo1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-homo1-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.5: Illustration of homo- and heteroskedasicity.</figcaption>
</figure>
</div>
</div>
</div>
<p>To make it clearer what aspect of these plots is relevant for evaluating the assumption of homoskedasticity, the same figures are replicated below, but this time with blue lines represented my own “eye-balling” of the range of the residuals. In the left plot, the two lines are parallel, meaning the range is constant. In the right plot, the two lines form a cone, meaning the the range of the residuals increases for larger values of <span class="math inline">\(\widehat Y\)</span>.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># homoskedastic example with ref lines</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod3, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="dv">2</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Heteroskedastic example</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="dv">1</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="dv">8</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="sc">-</span><span class="dv">8</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># remove y2 from memory to avoid naming conflicts later on</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(y2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-homo2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-homo2-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.6: Illustration of Homo- and Heteroskedasicity, with Reference Lines</figcaption>
</figure>
</div>
</div>
</div>
<p>Note that I didn’t draw any lines in the tail ends of the plots – this is because there are fewer observations in the tails, so it is harder to make a judgment about the range of values. To avoid “reading the tea leaves” I focus on the values of <span class="math inline">\(\widehat Y\)</span> for which there are sufficient observations to judge the range of the residuals.</p>
<p>To repeat, <em>the blue lines are just there for your reference</em>, to highlight the relevant information in the plot. You wouldn’t generally include these lines in the plot.</p>
<p>Let’s take another look at the plots in <a href="#fig-linearity3">Figure&nbsp;<span>7.4</span></a>. <strong>Please write down whether you think the homoskedasticity assumption is problematic and explain why with reference to the plots</strong>.</p>
<section id="sec-heteroskedasticity-7" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="sec-heteroskedasticity-7"><span class="header-section-number">7.3.1</span> Dealing with Heteroskedasticity</h3>
<p>Heteroskedasticity in linear regression, and corrections thereof, is a pretty big topic in the methodological literature (see <span class="citation" data-cites="cite-fox">(<a href="#ref-cite-fox" role="doc-biblioref"><strong>cite-fox?</strong></a>)</span>, section 12.2). In this section we are just going to discuss one widely used solution, and how to implement it in <code>R</code>.</p>
<p>As mentioned previously, heteroskedasticity affects the standard errors of the regression coefficients, and consequently their t-tests, p-values, and confidence intervals. In particular, the p-values for the regression coefficients will usually be too small if the data are heteroskedastic, but we mistakenly assume they are homoskedastic. Note that heteroskedasticity won’t affect the estimated values of the OLS regression coefficients (i.e., the <span class="math inline">\(\widehat{b}\)</span>’s), and it also doesn’t affect R-squared or its F-test.</p>
<p>If our data exhibit heteroskedasticity, one solution is to use heteroskedasticity-consistent (HC) standard errors. HC standard errors are also sometimes called heteroskedasticity-robust, or just robust. The are also informally referred to as “sandwich” estimates – see <span class="citation" data-cites="cite-fox">(<a href="#ref-cite-fox" role="doc-biblioref"><strong>cite-fox?</strong></a>)</span> section 12.2.3 for an explanation of this terminology.</p>
<p>Although there are many different version of HC standard errors, they are all equivalent with “large” samples. The simplest version is (see <span class="citation" data-cites="cite-fox">(<a href="#ref-cite-fox" role="doc-biblioref"><strong>cite-fox?</strong></a>)</span>, section 12.2.3)</p>
<p><span id="eq-se-10"><span class="math display">\[ \text{HC-SE}(\hat{b}_k) = \sqrt{\frac{\sum_{i=1}^N (X_{ik} - \widehat{X}_{ik})^2 (Y_i-\widehat{Y}_i)^2} {\sum_{i=1}^N (X_{ik} - \bar X_k)^2 (1 - R^2_k)}}
\tag{7.1}\]</span></span></p>
<p>In this equation, <span class="math inline">\(\widehat{X}_{ij}\)</span> is the predicted value that results from regressing <span class="math inline">\(X_k\)</span> on the remaining <span class="math inline">\(K-1\)</span> predictors. The equation is not very intuitive to look at, but the general idea is that it can be derived without assuming homoskedasticity.</p>
<p>In terms of implementation, the procedure for using HC standard errors in R has three steps.</p>
<ul>
<li>First, we estimate the model as usual, (e.g., using the <code>lm</code> function)</li>
<li>Second, we compute the HC standard errors (e.g., using the <code>hccm</code> function of the <code>car</code> package.)</li>
<li>Third, we use the HC standard errors to compute the correct t-tests / confidence intervals (e.g., using the <code>coeftest</code> function of the <code>lmtest</code> package. )</li>
</ul>
<p>You can find a more complete discussion of robust standard errors in R in the vignettes linked here: <a href="http://jepusto.github.io/clubSandwich/">http://jepusto.github.io/clubSandwich/</a></p>
<p>The following output shows the results for the heteroskedastic (cone-shaped) example data in <a href="#fig-homo2">Figure&nbsp;<span>7.6</span></a>, using both the regular standard errors and HC standard errors. We can see that both sets of output are pretty similar: while the “Estimates” don’t change, the “Std. Errors” are a bit different in the two sets of output. In this case, the HC standard errors don’t affect conclusions about statistical significance, but in other cases they can lead to more dramatic differences in interpretation. <strong>Please examine these two sets of output and write down any questions you have about their interpretation.</strong></p>
<ul>
<li>Regular OLS standard errors :</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Regular SE: </span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y2 ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.9985 -1.0402 -0.0504  0.9252 11.5002 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.002712   0.154430  -0.018    0.986    
x            0.968044   0.160719   6.023 6.13e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.441 on 248 degrees of freedom
Multiple R-squared:  0.1276,    Adjusted R-squared:  0.1241 
F-statistic: 36.28 on 1 and 248 DF,  p-value: 6.135e-09</code></pre>
</div>
</div>
<ul>
<li>HC standard errors:</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HC SE</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2. Use "hccm" to get the HC SEs for our model </span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod4)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod4, hcse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
t test of coefficients:

              Estimate Std. Error t value  Pr(&gt;|t|)    
(Intercept) -0.0027123  0.1520067 -0.0178    0.9858    
x            0.9680441  0.1908455  5.0724 7.701e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>One final note: HC standard errors do not assume the data are homoskedastic. So, they can be used regardless of whether the homoskedasticity assumption is met or not. But, when the data <em>are</em> homoskedastic, the regular OLS standard errors are usually more precise (i.e., smaller). So, we generally don’t want to use HC standard errors unless there is evidence of heteroskedasticity in the data. This is why we do graphical checks first!</p>
</section>
<section id="summary-1" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="summary-1"><span class="header-section-number">7.3.2</span> Summary</h3>
<ul>
<li><p>The assumption of homoskedasticity (or homogeneity variance, or just equal variances) means that the variance of the residuals should not change as a function of the predicted values.</p></li>
<li><p>Because we are again concerned with residuals and predicted values, we can re-use the same plot we used to check linearity. However, now we are interested in whether the range of the residuals (on the vertical axis) changes over the predicted values (on the horizontal axis).</p></li>
<li><p>If we suspect that heteroskedasticity is a problem, we can adjust how the standard errors of the regression coefficients are computed. These adjusted standard errors are variously referred to as heteroskedasticity-consistent, heteroskedasticity-robust, robust, or “sandwich” estimates.</p></li>
<li><p>To implement in HC standard errors in R, we can use a three step procedure:</p></li>
<li><p>First, we estimate the model as usual, (e.g., using the <code>lm</code> function)</p></li>
<li><p>Second, we compute the HC standard errors (e.g., using the <code>hccm</code> function of the <code>car</code> package.)</p></li>
<li><p>Third, we use the HC standard errors to compute the correct t-tests / confidence intervals (e.g., using the <code>coeftest</code> function of the <code>lmtest</code> package. )</p></li>
</ul>
<p>You can find a more complete discussion of robust standard errors in R in the vignettes linked here: <a href="http://jepusto.github.io/clubSandwich/">http://jepusto.github.io/clubSandwich/</a></p>
</section>
</section>
<section id="sec-normality-7" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="sec-normality-7"><span class="header-section-number">7.4</span> Normality</h2>
<p>The last assumption we need to check is normality of the residuals. There are many ways to compare the empirical distribution of a variable (e.g., the residuals in a regression analysis) to a theoretical distribution (e.g., the normal). One general-purpose technique is a qq plot (short for quantile-quantile plot). A qq plot compares the quantiles (e.g., percentiles) of two different distributions.</p>
<p>For our assumption, we want to compare the quantiles of our standardized residuals to the quantiles of a standard normal distribution. Standardizing means the residuals should have variance equal to one, and, combined with the other population assumptions of linear regression, this implies that the residuals should have a standard normal distribution (see <a href="#sec-recap-7"><span>Section&nbsp;7.1</span></a>).</p>
<p>Since qq plots might not be something you have seen before, we’ll take a look at a few examples. Each figure below pairs a histogram and qq plot. In the qq plot, data points should fall on the diagonal line if the data are normally distributed. It should be emphasized that the line in the qq plot is <em>not a regression line!</em> It is just the diagonal line <span class="math inline">\(Y = X\)</span>, and the bulk of the data points should fall on that line if the data were drawn from a normal distribution.</p>
<p>In the following examples, focus on how the pattern in the histogram shows up as deviations from the diagonal line in the qq plot. We will discuss the interpretation of these patterns together in class, but for now, <strong>please write down any questions you have about the interpretation of the qq plots.</strong></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing histograms and q-q plots</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>distributions <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"distributions.csv"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(distributions)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"normal"</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(distributions)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>dist_names <span class="ot">&lt;-</span> <span class="fu">names</span>(distributions)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal </span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(normal, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Normal"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(normal, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(normal)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Negative skew</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(neg_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Negative Skew"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(neg_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(neg_skew)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-3-2.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Positive skew</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pos_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Positive Skew"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(pos_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(pos_skew)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-3-3.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Leptokurtic</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lepto, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Lepotkurtosis"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(lepto, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(lepto)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-3-4.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Platykurtic</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(platy, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>,  <span class="at">main =</span> <span class="st">"Platykurtosis"</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(platy, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(platy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-3-5.png" class="img-fluid" width="672"></p>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(distributions)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Next, let’s consider a more realistic example using the default plotting from the <code>lm</code> function. <strong>Please write down whether you think the normality assumption is problematic for the data in <a href="#fig-normality1">Figure&nbsp;<span>7.7</span></a>, and be sure to explain why with reference to the plot.</strong> Hint: if you think the data are non-normal, you should be able to interpret the pattern of deviations with reference to the examples given above (e.g.&nbsp;skew, kurtosis).</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-normality1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-normality1-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;7.7: An example from ECLS.</figcaption>
</figure>
</div>
</div>
</div>
<p>Practice makes perfect, so lets work through a few more examples. In each of the examples in <a href="#fig-normality2">Figure&nbsp;<span>7.8</span></a>, <strong>please write down whether you think the normality assumption is problematic and explain why with reference to the plots.</strong></p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>}  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-normality2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/fig-normality2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7.8: More examples.</figcaption>
</figure>
</div>
</div>
</div>
<section id="summary-2" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="summary-2"><span class="header-section-number">7.4.1</span> Summary</h3>
<p>To check the assumption of normality, we can use a qq plot of the standardized residuals against the standard normal distribution.</p>
<ul>
<li><p>If the points from the qq plot follows the line Y = X, then there is no evidence against the assumption.</p></li>
<li><p>If the residuals do show a trend off of the diagonal line, then we should worry about the assumption.</p></li>
<li><p>If the assumption is violated, the central limit theorem implies that significance tests used in OLS regression will be robust to violations of normality when sample sizes are large.</p>
<ul>
<li>Practically this means we can often ignore mild violations of normality when <span class="math inline">\(N / K &gt; 30\)</span> (but other guidelines are used too).</li>
<li>For some specific types of violations, notably positive skew, it is also common to transform the Y variable (see <span class="quarto-unresolved-ref">?sec-chap-9</span>).</li>
<li>When we are worried that non-normality arises from a relatively small subset of the data that may be unduly influencing the results, this can be addressed through regression diagnostics (see <a href="#sec-diagnostics-7"><span>Section&nbsp;7.6</span></a>) and robust statistics (which is an advanced topic).</li>
</ul></li>
<li><p>Oh, and one last thing: The line in a qq plot is <em>not a regression line!</em></p></li>
</ul>
</section>
</section>
<section id="sec-worked-example-7" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="sec-worked-example-7"><span class="header-section-number">7.5</span> A worked example</h2>
<p>To illustrate the assumption checking procedures outlined above, let’s revisit the example from <a href="ch6_model_building.html#sec-worked-example-6"><span>Section&nbsp;6.2</span></a>. In that example, it was noted that there was evidence that one (or more) of the assumptions were problematic. Let’s take a look at why this was the case.</p>
<p>For this example, we will use the ECLS data to regress reading achievement at the beginning of Kindergarten (<code>c1rrscal</code>) on SES (<code>wksesl</code>), parental (mother’s and father’s) education (<code>wkmomed</code> and <code>wkdaded</code>, respectively), and attendance in center-based care before K (<code>p1center</code>). This is model 3 from <a href="ch6_model_building.html#sec-worked-example-6"><span>Section&nbsp;6.2</span></a> (i.e., we don’t consider the model with the interactions).</p>
<p>The workflow for assumption checking requires first running the model and then producing the residual vs fitted plot and a qq plot of the residuals. If the plots look OK, we go ahead and interpret the model results. If the plots don’t look OK, we give up and wonder why we ever bothered with regression in the first place. Just kidding :) – the next two chapters of these notes address how to deal with violations of the linearity and normality assumptions, and we already know how to deal with heteroskedasticity from <a href="#sec-heteroskedasticity-7"><span>Section&nbsp;7.3.1</span></a>.</p>
<p>After running the model, we obtain the following two plots from the regression output. <strong>For each of the three population assumptions of linear regression, please write down whether you think the assumption is problematic and explain why with reference to the plots.</strong> Again, the purpose of this exercise is for you to think about how to interpret the plots with respect to the assumptions. I am looking for you to be explicit about how you reason from the plots to your conclusions. I am less interested in the conclusions per se, as this is something that requires practice to get right.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up and load data</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># rm(list = ls())</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load("ECLS2577.RData")</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(ecls)</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">1</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>To foreshadow the next couple of chapters, here is what the plots looked like after dealing with positive skew of the residuals and the non-normality of the regression line:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>log_c1rrscal <span class="ot">&lt;-</span> <span class="fu">log</span>(c1rrscal <span class="sc">-</span> <span class="fu">min</span>(c1rrscal) <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>wksesl_sq <span class="ot">&lt;-</span> wksesl<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wksesl_sq <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod6, <span class="dv">1</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod6, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Neither assumption has been perfectly addressed, and, in particular, it looks like we may have over-corrected the positive skew and ended up with some negative skew. Also note that the data continue to exhibit heteroskedasticity, which is apparent from looking at the residual vs fitted plot in the range -1 to -3 of the residuals. Because heteroskedasticity is still an issue for these data, we can improve on the analysis reported in <a href="ch6_model_building.html#sec-worked-example-6"><span>Section&nbsp;6.2</span></a> by using HC standard errors rather than “regular” OLS standard errors. The difference between the two approaches is illustrated below. Remember, the estimates stay the same, but the SE’s change (and consequently the t-tests and p-values).</p>
<ul>
<li>Regular SE (same as Model 3 in <a href="ch6_model_building.html#sec-worked-example-6"><span>Section&nbsp;6.2</span></a>):</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod6)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log_c1rrscal ~ factor(p1center) + wksesl + wksesl_sq + 
    wkmomed + wkdaded)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.59699 -0.29882  0.04381  0.37969  1.86787 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)       -2.7941636  1.6307966  -1.713  0.08791 . 
factor(p1center)2 -0.1232061  0.1030926  -1.195  0.23321   
wksesl             0.1758849  0.0665763   2.642  0.00878 **
wksesl_sq         -0.0016162  0.0006514  -2.481  0.01378 * 
wkmomed            0.0698645  0.0388073   1.800  0.07305 . 
wkdaded            0.0506601  0.0364953   1.388  0.16636   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.6327 on 244 degrees of freedom
Multiple R-squared:  0.2252,    Adjusted R-squared:  0.2093 
F-statistic: 14.18 on 5 and 244 DF,  p-value: 3.474e-12</code></pre>
</div>
</div>
<ul>
<li>HC SE</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod6, car<span class="sc">::</span><span class="fu">hccm</span>(mod6))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
t test of coefficients:

                     Estimate  Std. Error t value Pr(&gt;|t|)  
(Intercept)       -2.79416359  1.69074543 -1.6526  0.09969 .
factor(p1center)2 -0.12320606  0.10855871 -1.1349  0.25752  
wksesl             0.17588489  0.06776405  2.5955  0.01002 *
wksesl_sq         -0.00161620  0.00065155 -2.4806  0.01379 *
wkmomed            0.06986450  0.03806165  1.8356  0.06764 .
wkdaded            0.05066012  0.03077238  1.6463  0.10099  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>In this example, the HC SE’s didn’t lead to substantively different inferences, but we should report the results with HC SE’s based on the assumption checking.</p>
</section>
<section id="sec-diagnostics-7" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="sec-diagnostics-7"><span class="header-section-number">7.6</span> Diagnostics*</h2>
<p>This section is optional and is currently under construction (i.e., many typos). It focuses on walking through the code so it is recommended to treat this like an Exercises section and scroll to the top of the page, click on the “&lt;/&gt; Code” menu, then select “Show All Code.”</p>
<p>Like assumption checking, regression diagnostics also make extensive use of regression residuals, but this time the objective is to identify individual data points that are “outliers” with respect to the model. To work through the basic concepts of regression diagnostics, let’s again use the Anscombe’s quartet.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting Anscombe's quartet</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(anscombe)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>ymax <span class="ot">&lt;-</span> <span class="fu">max</span>(anscombe[,<span class="dv">5</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>ymin <span class="ot">&lt;-</span> <span class="fu">min</span>(anscombe[,<span class="dv">5</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>xmax <span class="ot">&lt;-</span> <span class="fu">max</span>(anscombe[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>xmin <span class="ot">&lt;-</span> <span class="fu">min</span>(anscombe[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y1, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y1 <span class="sc">~</span> x1))</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x2, y2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y2 <span class="sc">~</span> x2))</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, y3, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y3 <span class="sc">~</span> x3))</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, y4, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y4 <span class="sc">~</span> x4))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The interesting thing about these four examples is that they all have the same univariate and bivariate summary statistics – e.g., the same mean, variance, covariance, correlation, and regression coefficients. But first example is the only one that would be suitable for analysis by using these statistics. The second example shows a non-linear relationship, which we addressed in Section @ref(linearity-8). In this section we will focus on the last two examples, since they have clear outliers.</p>
<section id="leverage" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="leverage"><span class="header-section-number">7.6.1</span> Leverage</h3>
<p>Leverage describes how “unusual” a data point is on the X variable(s) – i.e., how far from the mean it is on each predictor. The function <code>hatvalues</code> computes the leverage for each data point. Let’s check out the leverage for the 3rd and 4th examples from Anscombe’s quartet.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># leverage for Anscombe 3</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>anscombe3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3 <span class="sc">~</span> x3)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>leverage3 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(anscombe3)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the leverage values for each data point</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>leverage3</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>         1          2          3          4          5          6          7 
0.10000000 0.10000000 0.23636364 0.09090909 0.12727273 0.31818182 0.17272727 
         8          9         10         11 
0.31818182 0.17272727 0.12727273 0.23636364 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the leverage values in the scatter plot using the function "text"</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, y3, <span class="at">col =</span> <span class="st">"white"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax), <span class="at">main =</span> <span class="st">"Leverage for Anscombe 3"</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y3 <span class="sc">~</span> x3))</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(y3 <span class="sc">~</span> x3, <span class="at">labels =</span> <span class="fu">round</span>(leverage3, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># leverage for Anscombe 4</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>anscombe4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y4 <span class="sc">~</span> x4)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>leverage4 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(anscombe4)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the leverage values for each data point</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>leverage4</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  1   2   3   4   5   6   7   8   9  10  11 
0.1 0.1 0.1 0.1 0.1 0.1 0.1 1.0 0.1 0.1 0.1 </code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the leverage values in the scatter plot using the function "text"</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, y4, <span class="at">col =</span> <span class="st">"white"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),  <span class="at">main =</span> <span class="st">"Leverage for Anscombe 4"</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y4 <span class="sc">~</span> x4))</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(y4 <span class="sc">~</span> x4, <span class="at">labels =</span> <span class="fu">round</span>(leverage4, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Recall from the lesson that</p>
<ul>
<li><p>h should be smaller (closer to 0) for values closer to the mean of X</p></li>
<li><p>The maximum value of h is 1</p></li>
</ul>
<p>Based on the plots, we can see that the largest leverage is for the outlier in Anscombe 4.</p>
</section>
<section id="distance-residuals" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="distance-residuals"><span class="header-section-number">7.6.2</span> Distance (residuals)</h3>
<p>Distance is about the size of the residuals. In order to judge the size of a residual, it helps to use the (externally) studentized residuals rather than the “raw” residuals. Because the studentized residual have a t-distribution on <span class="math inline">\(N - K - 2\)</span> degrees of freedom, a rough ballpark for interpreting studentized residuals is that</p>
<ul>
<li><p>Values around +/- 2 are considered large.</p></li>
<li><p>Values beyond +/- 3 are considered very large.</p></li>
</ul>
<p>Let’s see what we have for our examples:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 3</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>distance3 <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(anscombe3)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, distance3, <span class="at">main =</span> <span class="st">"Leverage for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>distance4 <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(anscombe4)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, distance4, <span class="at">main =</span> <span class="st">"Leverage for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Clearly, the notion of distance is useful for describing what the problem is with Anscombe’s 3rd example. For the 4th example, the outlying data point is omitted because it has leverage of exactly 1, which means that the studentized residuals are undefined (divide by zero; R notes this in the console).</p>
</section>
<section id="influence" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="influence"><span class="header-section-number">7.6.3</span> Influence</h3>
<p>Influence describes how much the model results would change if a data point were omitted. Roughly, the conceptual relationships among influence, distance, and leverage are given by the following equation:</p>
<p>[ = ]</p>
<p>This equation tells us that, for a data point to have high influence, it must be a large distance from the regression line (have a large residual) <em>and</em> have high leverage (be far away from the mean on <span class="math inline">\(X\)</span>).</p>
<p>There are a number of ways of computing influence. Like externally studentized residuals, they are all deletion statistics, or statistics computed using a “leave-one-out” approach.</p>
<p>Influence statistics can also be classified into global versus local. Global approaches consider how a data point affects the predicted values. Local approaches consider how a data point affects the value of a specific regression coefficient.</p>
<p>Let’s start with DFFITS and Cook’s distance, two measures of global influence.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DFFITS for Anscombe 3</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>DFFITS3 <span class="ot">&lt;-</span> <span class="fu">dffits</span>(anscombe3)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, DFFITS3, <span class="at">main =</span> <span class="st">"DFFITS for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>DFFITS4 <span class="ot">&lt;-</span> <span class="fu">dffits</span>(anscombe4)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, DFFITS4, <span class="at">main =</span> <span class="st">"DFFITS for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cook's distance for Anscombe 3</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>Cooks3 <span class="ot">&lt;-</span> <span class="fu">cooks.distance</span>(anscombe3)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, Cooks3, <span class="at">main =</span> <span class="st">"Cook's D for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>Cooks4 <span class="ot">&lt;-</span> <span class="fu">cooks.distance</span>(anscombe4)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, Cooks4, <span class="at">main =</span> <span class="st">"Cook's D for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>These statistics are similar but Cook’s distance is more interpetable. Values greater than 1 are considered indicative of high influence. We can see that the outlier in the 3rd example is highly influence. The outlier in the 4th example is “NA” because h = 1 hence there is a divide by zero problem.</p>
<p>For local measures of influence, the interpretation is roughly the same as global measures with simple regression (i.e., a single predictor). For multiple regression, local measures can provided additional insight to consider which regression coefficients are most influenced by an outlier.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DFBETAs distance for Anscombe 3</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>DFBETA3 <span class="ot">&lt;-</span> <span class="fu">dfbetas</span>(anscombe3)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Take a look at the output: We get values for each coefficient, including the intercept</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>DFBETA3 </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     (Intercept)            x3
1  -4.625738e-03 -4.412673e-02
2  -3.713338e-02  1.864368e-02
3  -3.579096e+02  5.252677e+02
4  -3.289981e-02 -1.737209e-18
5   4.915510e-02 -1.172274e-01
6   4.897424e-01 -6.674064e-01
7   2.700082e-02 -2.088417e-02
8   2.409027e-01 -2.089150e-01
9   1.374342e-01 -2.313597e-01
10 -1.970229e-02  1.342485e-02
11  1.053656e-01 -8.740210e-02</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plots for the regression coefficients</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, DFBETA3[,<span class="st">"x3"</span>], <span class="at">main =</span> <span class="st">"DFBETA for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>DFBETA4 <span class="ot">&lt;-</span> <span class="fu">dfbetas</span>(anscombe4)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, DFBETA4[,<span class="st">"x4"</span>], <span class="at">main =</span> <span class="st">"DFBETA for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The output for DFBETA3 looks a lot like DFFITS3 (because we only have one predictor).</p>
<p>For DFBETA4, it is strange that our unusual data point (x4 = 18) was not identified as problematic – keep in mind that when this data point is removed, the variance of X is zero and so the regression coefficient for the leave-one-out model is not defined. Still, it is not clear why R reports the value as zero, rather than omitted.</p>
</section>
<section id="a-more-realistic-example" class="level3" data-number="7.6.4">
<h3 data-number="7.6.4" class="anchored" data-anchor-id="a-more-realistic-example"><span class="header-section-number">7.6.4</span> A more realistic example</h3>
<p>As a more realistic example, let’s consider Question 3 from Assignment 1 using the graphical output from <code>lm</code>. Note that the graphical output uses the internally studentized residuals, and refers to these as “standardized residuals”.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(c4rmscal <span class="sc">~</span> wksesl <span class="sc">+</span> t1learn, <span class="at">data =</span> ecls)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Influence via Cook's distance</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="at">which =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see that, although R automatically labels the 3 data points with the highest values of Cook’s D, none of the data points are actually close to the cut off value of 1. In other words, none of the data points in this example have an undue influence on the results of the regression model.</p>
</section>
</section>
<section id="sec-workbook-7" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="sec-workbook-7"><span class="header-section-number">7.7</span> Workbook</h2>
<p>This section collects the questions asked in this chapter. The lesson for this chapter will focus on discussing these questions and then working on the exercises in <a href="#sec-exercises-7"><span>Section&nbsp;7.8</span></a>. The lesson will <strong>not</strong> be a lecture that reviews all of the material in the chapter! So, if you haven’t written down / thought about the answers to these questions before class, the lesson will not be very useful for you. Please engage with each question by writing down one or more answers, asking clarifying questions about related material, posing follow up questions, etc.</p>
<p><a href="#sec-linearity-7"><span>Section&nbsp;7.2</span></a></p>
<ul>
<li>Please write down whether you think the linearity assumption is problematic for the example below, and be sure to explain why with reference to the figure. Keep in mind that interpreting plots takes a bit of practice and in general there is no “right” answer. Rather, what I am looking for is an explanation of <em>why</em> you think the assumption is problematic or not. Your explanation should refer to the interpretation of residual vs fitted plots, as outlined above.</li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">An example from ECLS.</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>For each of the four examples below, please write down whether you think the linearity assumption is problematic and explain why with reference to the plots. Hint: be careful not to over-interpret the lowess line in the tails of the plots, where only a few data points can have a big impact on the local trend. Focus your interpretation on the bulk of the data, and whether it shows a systemic trend away from the horizontal line at 0.</li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>}  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">More examples.</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#sec-homoskedasticity-7"><span>Section&nbsp;7.3</span></a></p>
<ul>
<li><p>Let’s take another look at the four plots in the above figure. For each plot, please write down whether you think the homoskedasticity assumption is problematic and explain why with reference to the plot.</p></li>
<li><p>The following output shows the results for the heteroskedastic (cone-shaped) example data, using both the regular standard error and HC standard errors. Please note the differences between these two sets of output and write down any questions you have about their interpretation.</p></li>
</ul>
<p>Example:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Regular SE:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Regular SE: </span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y2 ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.9985 -1.0402 -0.0504  0.9252 11.5002 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.002712   0.154430  -0.018    0.986    
x            0.968044   0.160719   6.023 6.13e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.441 on 248 degrees of freedom
Multiple R-squared:  0.1276,    Adjusted R-squared:  0.1241 
F-statistic: 36.28 on 1 and 248 DF,  p-value: 6.135e-09</code></pre>
</div>
</div>
<p>HC SE:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># HC SE</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2. Use "hccm" to get the HC SEs for our piecewise model </span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod4)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod4, hcse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
t test of coefficients:

              Estimate Std. Error t value  Pr(&gt;|t|)    
(Intercept) -0.0027123  0.1520067 -0.0178    0.9858    
x            0.9680441  0.1908455  5.0724 7.701e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p><a href="#sec-normality-7"><span>Section&nbsp;7.4</span></a></p>
<ul>
<li>Please write down whether you think the normality assumption is problematic for the data in the figure below, and be sure to explain why with reference to the plot. Hint: if you think the data are non-normal, you should be able to interpret the pattern of deviations (e.g.&nbsp;skew, kurtosis).</li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">An example from ECLS.</figcaption>
</figure>
</div>
</div>
</div>
<ul>
<li>In each of the examples below, please write down whether you think the normality assumption is problematic and explain why with reference to the plots.</li>
</ul>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>}  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">More examples.</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#sec-worked-example-7"><span>Section&nbsp;7.5</span></a></p>
<ul>
<li>For each of the three population assumptions of linear regression, please write down whether you think the assumption is problematic and explain why with reference to the plots. Again, the purpose of this exercise is for you to think about how to interpret the plots with respect to the assumptions. I am looking for you to be explicit about how you reason from the plots to your conclusions. I am less interested in the conclusions per se, as this is something that requires practice to get right.</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up and load data</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># rm(list = ls())</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># load("ECLS2577.RData")</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(ecls)</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">1</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="sec-exercises-7" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="sec-exercises-7"><span class="header-section-number">7.8</span> Exercises</h2>
<p>These exercises collect all of the R input used in this chapter into a single step-by-step analysis. It explains how the R input works, and provides some additional exercises. We will go through this material in class together, so you don’t need to work on it before class (but you can if you want.)</p>
<p>Before staring this section, you may find it useful to scroll to the top of the page, click on the “&lt;/&gt; Code” menu, and select “Show All Code.”</p>
<p>There isn’t much new in terms of R code in this chapter. Once we run a model with <code>lm</code>, we just call the <code>plot</code> function on the <code>lm</code> output to produce the graphics requires for assumption checking. This section shows these steps for the worked example in <a href="ch6_model_building.html#sec-worked-example-6"><span>Section&nbsp;6.2</span></a> and <a href="#sec-worked-example-7"><span>Section&nbsp;7.5</span></a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clearn up env and load data </span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co">#rm(list = ls())</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co">#load("ECLS2577.RData")</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model 3 from the example (all predictors, but no interactions)</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Puts both plots in one figure</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)) </span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">1</span>)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="ch7_assumption_checking_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The next bit of code shows how to adjust the statistical tests for heteroskedasticity using HC standard errors. In the next two chapters, we show how to address the linearity and normality assumption violations.</p>
<ul>
<li>Regular SE:</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = c1rrscal ~ factor(p1center) + wksesl + wkmomed + 
    wkdaded, data = ecls)

Residuals:
    Min      1Q  Median      3Q     Max 
-13.943  -5.080  -1.531   3.049  54.466 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)         7.0118     5.3078   1.321    0.188
factor(p1center)2  -1.7608     1.3901  -1.267    0.206
wksesl              0.2828     0.1724   1.640    0.102
wkmomed             0.6685     0.5203   1.285    0.200
wkdaded             0.2352     0.4935   0.477    0.634

Residual standard error: 8.56 on 245 degrees of freedom
Multiple R-squared:  0.1553,    Adjusted R-squared:  0.1415 
F-statistic: 11.26 on 4 and 245 DF,  p-value: 2.109e-08</code></pre>
</div>
</div>
<ul>
<li>HC SE</li>
</ul>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: fit the model (see above)</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Use "hccm" to get the HC SEs </span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod, hcse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
t test of coefficients:

                  Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)        7.01177    5.82938  1.2028   0.2302
factor(p1center)2 -1.76083    1.11866 -1.5740   0.1168
wksesl             0.28282    0.20506  1.3792   0.1691
wkmomed            0.66853    0.66797  1.0008   0.3179
wkdaded            0.23520    0.46189  0.5092   0.6111</code></pre>
</div>
</div>
<p>As discussed above, the interpretation for both sets of output is essentially the same, but by using the HC SEs we can be sure that our inferences are not unduly affected by the assumption of homoskedasticity.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ch6_model_building.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model building</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ch8_loglinear.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Log-linear regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb52" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="an">fold:</span><span class="co"> true</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: 72</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="fu"># Assumption checking {#sec-chap-7}</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>In @sec-population-model-2 we introduced the population model for linear regression. But how do we know whether this model applies to our data? That is the question we address in this chapter. In particular, we discuss data analyses that can be used to better understand whether the assumptions made when defining the population model for linear regression are consistent with our data. This is referred to *assumption checking*. </span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>The three assumptions are (don't worry, we review them again in the next section):   </span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Normality of residuals</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Homoskedasticity of residuals</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Linearity of the conditional mean (regression) function</span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>Why do we care about these assumptions? Well, if all of the population assumptions of linear regression are not met, any of the following can happen: </span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Regression coefficients and R-squared could be biased</span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Standard errors could be too small (or too large)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>t- and F-tests could be too small (or too large)</span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>p-values could be too small (or too large)</span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Confidence intervals could be too small (or too large)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>Basically, all of the numbers we get in R's <span class="in">`summary(lm)`</span> output could be wrong. </span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>The interpretation of assumptions in regression is a bit subtle. Assumptions are conditions we need to be true in order for the results of analysis to be valid. But, we don't really care about the assumptions in their own right. For example, we don’t really care if the regression residuals are normally distributed – we just care if there are any violations of this assumption that might be affecting the results our analysis. If there is no evidence that an assumption is problematic, we proceed with the main analysis as intended. If there is evidence that an assumption is violated, we can modify the analysis as required. This chapter focuses on checking assumptions, and the following two chapters talk about strategies for dealing with assumption violations.</span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>Assumption checking usually involves plotting the residuals from a regression model and trying to interpret what the plots tell us about the population model. The main focus of this chapter is to introduce you to these plots and how to interpret them. Sometimes assumption checking can feel a bit like reading tea leaves, because interpreting plots can be pretty subjective. Honing your interpretation will happen gradually with experience. </span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a>In this chapter we also address how to deal with heteroskedasticity in regression models. The short version is that heteroskedasticity does not affect the OLS estimates of the regression coefficients, it only affects their standard errors (and, consequently, the t-values, p-values, and confidence intervals). There are corrections to the standard errors that can be used to address heteroskedasticity. In particular, we will focus on one widely used procedure called heteroskedasticity-consistent (HC) standard errors. These "corrected"</span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a>standard errors are often larger then than the "uncorrected" standard errors, which is why we prefer to use the latter when homoskedasticity is viable. </span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a>A related topic, *regression diagnostics*, is also introduced in this chapter. Diagnostics are procedures for detecting outliers. Unlike assumption checking, which focuses on the model *per se*, diagnostics focus on individual data points. We only cover the basics behind diagnostics in this chapter and the material is optional (i.e., it will not be assessed in this course, but you may find it useful for your research). </span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a>Regression diagnostics and outlier detection can be useful for identifying potentially problematic data points, but it is almost never the the case that data points should be omitted because they are outliers. Unless you can find something specifically wrong with a data point (e.g., a data entry error) you should not omit data. A better way to deal with outliers is by using statistical procedures that are specifically designed to deal with them, which is a field of study called *robust statistics*. Robust regression is an advanced topic that we won't get to in this course, but check out this resource if you are interested and feel free to ask questions in class: <span class="co">[</span><span class="ot">https://cran.r-project.org/web/views/Robust.html</span><span class="co">](https://cran.r-project.org/web/views/Robust.html)</span>. </span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## Recap of population model {#sec-recap-7} </span></span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a>Let's start with a recap of the population model for linear regression. This was introduced for simple linear regression in @sec-population-model-2. To restate the assumptions for multiple linear regression, we will use the vector notation </span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a>$$\mathbf X = <span class="co">[</span><span class="ot">X_1, X_2, \dots, X_K</span><span class="co">]</span>$$</span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a>to represent the predictor variables. For our purposes, the vector $\mathbf X$ is just a list of all of the predictors in a model. The outcome variable is denoted as $Y$, as usual. </span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Normality: The distribution of $Y$ conditional on $\mathbf X$ is normal for all values of $\mathbf X$. </span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a>$$ Y | \mathbf X \sim  N(\mu_{Y | \mathbf X} , \sigma_{Y | \mathbf X}) $$</span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Homoskedasticity: The conditional distributions have equal variances (also called homogeneity of variance, or just equal variances).</span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a>$$ \sigma_{Y| \mathbf X} = \sigma $$</span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-55"><a href="#cb52-55" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Linearity: The means of the conditional distributions are a linear function of $\mathbf X$.</span>
<span id="cb52-56"><a href="#cb52-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-57"><a href="#cb52-57" aria-hidden="true" tabindex="-1"></a>$$ \mu_{Y| \mathbf X} = b_0 + \sum_{k = 1}^K b_k X_k $$</span>
<span id="cb52-58"><a href="#cb52-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-59"><a href="#cb52-59" aria-hidden="true" tabindex="-1"></a>These three assumptions can also be summarized in term of the regression residuals. Recall that residuals are computed as  $\epsilon = Y - \mu_{Y|\mathbf X}$. If the three assumptions of linear regression hold, then the regression residuals should be normally distributed with mean zero and constant variance, for every value of the predictors: </span>
<span id="cb52-60"><a href="#cb52-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-61"><a href="#cb52-61" aria-hidden="true" tabindex="-1"></a>$$\epsilon \mid \mathbf {X} \sim N(0, \sigma). $$</span>
<span id="cb52-62"><a href="#cb52-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-63"><a href="#cb52-63" aria-hidden="true" tabindex="-1"></a>@fig-pop-model-e presents the population model in terms of the residuals. This plot is similar @fig-pop-model, but is modified for the multiple regression setting by using predicted values and residuals as the axes, rather than $X$ and $Y$. The plots we look at in the following sections are sample analogues to this population model -- they plot residuals against predicted values.</span>
<span id="cb52-64"><a href="#cb52-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-65"><a href="#cb52-65" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig-pop-model-e, echo = F, fig.cap = "The Multiple Regression Population Model.", fig.align = 'center'}</span></span>
<span id="cb52-66"><a href="#cb52-66" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"files/images/pop_model_e.png"</span>)</span>
<span id="cb52-67"><a href="#cb52-67" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-68"><a href="#cb52-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-69"><a href="#cb52-69" aria-hidden="true" tabindex="-1"></a><span class="fu">## Linearity {#sec-linearity-7}</span></span>
<span id="cb52-70"><a href="#cb52-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-71"><a href="#cb52-71" aria-hidden="true" tabindex="-1"></a>This assumption is about whether the regression function is “really” a line or if it could be better represented as some other relationship. A classic example is shown below. We address this example, which is taken from "Anscombe's quartet", in more detail in @sec-diagnostics-7 (which is optional). </span>
<span id="cb52-72"><a href="#cb52-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-73"><a href="#cb52-73" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-linearity1, fig.width = 8, fig.cap = "Anscombe's second dataset", fig.align = 'center'}</span></span>
<span id="cb52-74"><a href="#cb52-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-75"><a href="#cb52-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Non-linearity in Anscombe's second example</span></span>
<span id="cb52-76"><a href="#cb52-76" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(anscombe)</span>
<span id="cb52-77"><a href="#cb52-77" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2 <span class="sc">~</span> x2)</span>
<span id="cb52-78"><a href="#cb52-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-79"><a href="#cb52-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the raw data</span></span>
<span id="cb52-80"><a href="#cb52-80" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-81"><a href="#cb52-81" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x2, y2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlab =</span> <span class="st">"X"</span>, <span class="at">ylab =</span> <span class="st">"Y"</span>)</span>
<span id="cb52-82"><a href="#cb52-82" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(mod)</span>
<span id="cb52-83"><a href="#cb52-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-84"><a href="#cb52-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to the residual vs fitted plot</span></span>
<span id="cb52-85"><a href="#cb52-85" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-86"><a href="#cb52-86" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(anscombe)</span>
<span id="cb52-87"><a href="#cb52-87" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-88"><a href="#cb52-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-89"><a href="#cb52-89" aria-hidden="true" tabindex="-1"></a>The left hand panel of @fig-linearity1 shows the scatter plot of the example data. It should hopefully be obvious that the relationship between $Y$ and $X$ is not linear. </span>
<span id="cb52-90"><a href="#cb52-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-91"><a href="#cb52-91" aria-hidden="true" tabindex="-1"></a>The right hand panel shows the residuals versus the predicted ("fitted") values from the regression of $Y$ on $X$. It plots the residuals on the vertical axis and the fitted values ($\hat Y$) on the horizontal axis. This is the sample analogue of the population model in @fig-pop-model-e.  </span>
<span id="cb52-92"><a href="#cb52-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-93"><a href="#cb52-93" aria-hidden="true" tabindex="-1"></a>It is important to note the following about residual vs fitted plot:</span>
<span id="cb52-94"><a href="#cb52-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-95"><a href="#cb52-95" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The key idea is that deviations from the regression line in the left hand panel correspond to deviations from the horizontal line at Residuals = 0 in the right hand panel. Recall that the residuals should all be centered around this horizontal line if the population model is true (see @fig-pop-model-e). The non-linear trend is apparent in the in both panels, but in the residual vs fitted plot the nonlinearity is with reference to Residuals = 0. </span>
<span id="cb52-96"><a href="#cb52-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-97"><a href="#cb52-97" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The red line in the right hand panel is a locally weighted smoothed ("lowess") regression line -- it follows whatever trend is in the residuals without assuming the trend is linear. </span>
<span id="cb52-98"><a href="#cb52-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-99"><a href="#cb52-99" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The overall interpretation of the residual vs fitted plot is as follows: </span>
<span id="cb52-100"><a href="#cb52-100" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>If the red line is roughly horizontal at Residuals = 0, we conclude that the assumption of linearity is not problematic for the data. </span>
<span id="cb52-101"><a href="#cb52-101" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>If the red line deviates systematically from a horizontal line at Residuals = 0, this is evidence that the assumption of linearity is problematic. </span>
<span id="cb52-102"><a href="#cb52-102" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-103"><a href="#cb52-103" aria-hidden="true" tabindex="-1"></a>In @fig-linearity1, the assumption of linearity is clearly not met. In fact, this is so obvious that we could see it in the regular scatter plot! So, you might be asking, why do we need the residual vs fitted plot? Well, the regular scatter plot is only useful for diagnosing linearity with a single predictor, whereas the residual vs fitted plots works any number of predictors. So, in general, it is much easier to check the assumption using the residual versus fitted plot, even if the patterns are a bit harder to interpret. </span>
<span id="cb52-104"><a href="#cb52-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-105"><a href="#cb52-105" aria-hidden="true" tabindex="-1"></a>@fig-linearity2 illustrates the residual vs fitted plot using a model with 2 predictors. **Please write down whether you think the linearity assumption is problematic for the example below, and be sure to explain why with reference to the figure.** Keep in mind that interpreting plots takes a bit of practice and in general there is no "right" answer. Rather, what I am looking for is an explanation of *why* you think the assumption is problematic or not. Your explanation should refer to the interpretation of residual vs fitted plots, as outlined above. </span>
<span id="cb52-106"><a href="#cb52-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-107"><a href="#cb52-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-108"><a href="#cb52-108" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-linearity2, fig.width = 8, fig.cap = "An example from ECLS.", fig.align = 'center'}</span></span>
<span id="cb52-109"><a href="#cb52-109" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"ECLS250.RData"</span>)</span>
<span id="cb52-110"><a href="#cb52-110" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(ecls)</span>
<span id="cb52-111"><a href="#cb52-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-112"><a href="#cb52-112" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model for example</span></span>
<span id="cb52-113"><a href="#cb52-113" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rmscal <span class="sc">~</span> ses_orig <span class="sc">+</span> t1learn, <span class="at">data =</span> ecls)</span>
<span id="cb52-114"><a href="#cb52-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-115"><a href="#cb52-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot resid vs fitted</span></span>
<span id="cb52-116"><a href="#cb52-116" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-117"><a href="#cb52-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-118"><a href="#cb52-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-119"><a href="#cb52-119" aria-hidden="true" tabindex="-1"></a>Before moving on, let's take a look at a few more examples. For each of the examples in @fig-linearity3, **please write down whether you think the linearity assumption is problematic and explain why with reference to the plots.**. Hint: be careful not to over-interpret the lowess line in the tails of the plots, where only a few data points can have a big impact on the local trend. Focus your interpretation on the bulk of the data, and whether it shows a systemic trend away from a horizontal line at 0. </span>
<span id="cb52-120"><a href="#cb52-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-121"><a href="#cb52-121" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-linearity3, fig.height = 10, fig.cap = "More examples.", fig.align = 'center'}</span></span>
<span id="cb52-122"><a href="#cb52-122" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-123"><a href="#cb52-123" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb52-124"><a href="#cb52-124" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb52-125"><a href="#cb52-125" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb52-126"><a href="#cb52-126" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-127"><a href="#cb52-127" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-128"><a href="#cb52-128" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb52-129"><a href="#cb52-129" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-130"><a href="#cb52-130" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb52-131"><a href="#cb52-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-132"><a href="#cb52-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-133"><a href="#cb52-133" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary </span></span>
<span id="cb52-134"><a href="#cb52-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-135"><a href="#cb52-135" aria-hidden="true" tabindex="-1"></a>To check the assumption of linearity, we can use a residual vs predicted (fitted) plot. </span>
<span id="cb52-136"><a href="#cb52-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-137"><a href="#cb52-137" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>If the plot does not show a systematic trend other than a horizontal line at Residuals = 0, then there is no evidence against the assumption.</span>
<span id="cb52-138"><a href="#cb52-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-139"><a href="#cb52-139" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the residuals do show a trend away from Residuals = 0, then we should worry about the assumption.</span>
<span id="cb52-140"><a href="#cb52-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-141"><a href="#cb52-141" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Don't over interpret the tails of the lowess (red) lines in the R plots. </span>
<span id="cb52-142"><a href="#cb52-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-143"><a href="#cb52-143" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the assumption is violated: consider a non-linear transformations of the $Y$ variable (@sec-chap-8) or adding quadratic or other non-linear terms to the model (@sec-chap-9).</span>
<span id="cb52-144"><a href="#cb52-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-145"><a href="#cb52-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-146"><a href="#cb52-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-147"><a href="#cb52-147" aria-hidden="true" tabindex="-1"></a><span class="fu">## Homoskedasticity {#sec-homoskedasticity-7}</span></span>
<span id="cb52-148"><a href="#cb52-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-149"><a href="#cb52-149" aria-hidden="true" tabindex="-1"></a>This assumption means that the variance of the residuals should not change as a function of the predicted values. Because we are again concerned with residuals and predicted values, we can re-use the same plot we used to check linearity. However, we are no longer interested in whether the lowess trend (red line) systematically deviates from zero – now we are interested in whether the range of the residuals (on the vertical axis) changes over the predicted values (on the horizontal axis). </span>
<span id="cb52-150"><a href="#cb52-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-151"><a href="#cb52-151" aria-hidden="true" tabindex="-1"></a>@fig-homo1 illustrates two data sets in which the assumption of linearity is met, but the right hand panel shows evidence of heteroskedasticity. This is apparent by observing the range of the residuals over values of $\widehat Y$. </span>
<span id="cb52-152"><a href="#cb52-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-153"><a href="#cb52-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-homo1, fig.width = 8, fig.cap = "Illustration of homo- and heteroskedasicity.", fig.align = 'center'}</span></span>
<span id="cb52-154"><a href="#cb52-154" aria-hidden="true" tabindex="-1"></a><span class="co"># homoskedastic example</span></span>
<span id="cb52-155"><a href="#cb52-155" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb52-156"><a href="#cb52-156" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">rnorm</span>(<span class="dv">250</span>))</span>
<span id="cb52-157"><a href="#cb52-157" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">250</span>)</span>
<span id="cb52-158"><a href="#cb52-158" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> x <span class="sc">+</span> e</span>
<span id="cb52-159"><a href="#cb52-159" aria-hidden="true" tabindex="-1"></a>mod3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb52-160"><a href="#cb52-160" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-161"><a href="#cb52-161" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod3, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-162"><a href="#cb52-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-163"><a href="#cb52-163" aria-hidden="true" tabindex="-1"></a><span class="co"># Heteroskedastic example</span></span>
<span id="cb52-164"><a href="#cb52-164" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> y</span>
<span id="cb52-165"><a href="#cb52-165" aria-hidden="true" tabindex="-1"></a>y2[x <span class="sc">&gt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> x[x <span class="sc">&gt;</span> <span class="dv">0</span>] <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span> e[x <span class="sc">&gt;</span> <span class="dv">0</span>]</span>
<span id="cb52-166"><a href="#cb52-166" aria-hidden="true" tabindex="-1"></a>y2[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>] <span class="ot">&lt;-</span> x[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>] <span class="sc">+</span> .<span class="dv">3</span><span class="sc">*</span> e[x <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb52-167"><a href="#cb52-167" aria-hidden="true" tabindex="-1"></a>mod4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y2<span class="sc">~</span>x)</span>
<span id="cb52-168"><a href="#cb52-168" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-169"><a href="#cb52-169" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-170"><a href="#cb52-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-171"><a href="#cb52-171" aria-hidden="true" tabindex="-1"></a>To make it clearer what aspect of these plots is relevant for evaluating the assumption of homoskedasticity, the same figures are replicated below, but this time with blue lines represented my own "eye-balling" of the range of the residuals. In the left plot, the two lines are parallel, meaning the range is constant. In the right plot, the two lines form a cone, meaning the the range of the residuals increases for larger values of $\widehat Y$. </span>
<span id="cb52-172"><a href="#cb52-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-173"><a href="#cb52-173" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb52-174"><a href="#cb52-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-175"><a href="#cb52-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-homo2, fig.width = 8, fig.cap = "Illustration of Homo- and Heteroskedasicity, with Reference Lines", fig.align = 'center'}</span></span>
<span id="cb52-176"><a href="#cb52-176" aria-hidden="true" tabindex="-1"></a><span class="co"># homoskedastic example with ref lines</span></span>
<span id="cb52-177"><a href="#cb52-177" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-178"><a href="#cb52-178" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod3, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-179"><a href="#cb52-179" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="dv">2</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb52-180"><a href="#cb52-180" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb52-181"><a href="#cb52-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-182"><a href="#cb52-182" aria-hidden="true" tabindex="-1"></a><span class="co"># Heteroskedastic example</span></span>
<span id="cb52-183"><a href="#cb52-183" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-184"><a href="#cb52-184" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="dv">1</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="dv">8</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb52-185"><a href="#cb52-185" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="at">x0 =</span> <span class="sc">-</span><span class="fl">1.5</span>, <span class="at">y0 =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">x1 =</span> <span class="fl">1.5</span>, <span class="at">y1 =</span> <span class="sc">-</span><span class="dv">8</span>, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">3</span>)</span>
<span id="cb52-186"><a href="#cb52-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-187"><a href="#cb52-187" aria-hidden="true" tabindex="-1"></a><span class="co"># remove y2 from memory to avoid naming conflicts later on</span></span>
<span id="cb52-188"><a href="#cb52-188" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(y2)</span>
<span id="cb52-189"><a href="#cb52-189" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-190"><a href="#cb52-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-191"><a href="#cb52-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-192"><a href="#cb52-192" aria-hidden="true" tabindex="-1"></a>Note that I didn't draw any lines in the tail ends of the plots -- this is because there are fewer observations in the tails, so it is harder to make a judgment about the range of values. To avoid "reading the tea leaves" I focus on the values of $\widehat Y$ for which there are sufficient observations to judge the range of the residuals. </span>
<span id="cb52-193"><a href="#cb52-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-194"><a href="#cb52-194" aria-hidden="true" tabindex="-1"></a>To repeat, *the blue lines are just there for your reference*, to highlight the relevant information in the plot. You wouldn't generally include these lines in the plot.</span>
<span id="cb52-195"><a href="#cb52-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-196"><a href="#cb52-196" aria-hidden="true" tabindex="-1"></a>Let's take another look at the plots in @fig-linearity3. **Please write down whether you think the homoskedasticity assumption is problematic and  explain why with reference to the plots**.  </span>
<span id="cb52-197"><a href="#cb52-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-198"><a href="#cb52-198" aria-hidden="true" tabindex="-1"></a><span class="fu">### Dealing with Heteroskedasticity {#sec-heteroskedasticity-7}</span></span>
<span id="cb52-199"><a href="#cb52-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-200"><a href="#cb52-200" aria-hidden="true" tabindex="-1"></a>Heteroskedasticity in linear regression, and corrections thereof, is a pretty big topic in the methodological literature (see @cite-fox, section 12.2).  In this section we are just going to discuss one widely used solution, and how to implement it in <span class="in">`R`</span>. </span>
<span id="cb52-201"><a href="#cb52-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-202"><a href="#cb52-202" aria-hidden="true" tabindex="-1"></a>As mentioned previously, heteroskedasticity affects the standard errors of the regression coefficients, and consequently their t-tests, p-values, and confidence intervals. In particular, the p-values for the regression coefficients will usually be too small if the data are heteroskedastic, but we mistakenly assume they are homoskedastic. Note that heteroskedasticity won't affect the estimated values of the OLS regression coefficients (i.e., the $\widehat{b}$'s), and it also doesn't affect R-squared or its F-test.</span>
<span id="cb52-203"><a href="#cb52-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-204"><a href="#cb52-204" aria-hidden="true" tabindex="-1"></a>If our data exhibit heteroskedasticity, one solution is to use  heteroskedasticity-consistent (HC) standard errors. HC standard errors are also sometimes called heteroskedasticity-robust, or just robust. The are also informally referred to as "sandwich" estimates -- see @cite-fox section 12.2.3 for an explanation of this terminology. </span>
<span id="cb52-205"><a href="#cb52-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-206"><a href="#cb52-206" aria-hidden="true" tabindex="-1"></a>Although there are many different version of HC standard errors, they are all equivalent with "large" samples. The simplest version is (see @cite-fox, section 12.2.3)</span>
<span id="cb52-207"><a href="#cb52-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-208"><a href="#cb52-208" aria-hidden="true" tabindex="-1"></a>$$ \text{HC-SE}(\hat{b}_k) = \sqrt{\frac{\sum_{i=1}^N (X_{ik} - \widehat{X}_{ik})^2 (Y_i-\widehat{Y}_i)^2} {\sum_{i=1}^N (X_{ik} - \bar X_k)^2 (1 - R^2_k)}}</span>
<span id="cb52-209"><a href="#cb52-209" aria-hidden="true" tabindex="-1"></a>$$ <span class="sc">\{</span>#eq-se-10}</span>
<span id="cb52-210"><a href="#cb52-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-211"><a href="#cb52-211" aria-hidden="true" tabindex="-1"></a>In this equation, $\widehat{X}_{ij}$ is the predicted value that results from regressing $X_k$ on the remaining $K-1$ predictors. The equation is not very intuitive to look at, but the general idea is that it can be derived without assuming homoskedasticity. </span>
<span id="cb52-212"><a href="#cb52-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-213"><a href="#cb52-213" aria-hidden="true" tabindex="-1"></a>In terms of implementation, the procedure for using HC standard errors in R has three steps. </span>
<span id="cb52-214"><a href="#cb52-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-215"><a href="#cb52-215" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>First, we estimate the model as usual, (e.g., using the <span class="in">`lm`</span> function)</span>
<span id="cb52-216"><a href="#cb52-216" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Second, we compute the HC standard errors (e.g., using the <span class="in">`hccm`</span> function of the <span class="in">`car`</span> package.)</span>
<span id="cb52-217"><a href="#cb52-217" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Third, we use the HC standard errors to compute the correct t-tests / confidence intervals (e.g., using the <span class="in">`coeftest`</span> function of the <span class="in">`lmtest`</span> package. )</span>
<span id="cb52-218"><a href="#cb52-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-219"><a href="#cb52-219" aria-hidden="true" tabindex="-1"></a>You can find a more complete discussion of robust standard errors in R in the vignettes linked here: <span class="co">[</span><span class="ot">http://jepusto.github.io/clubSandwich/</span><span class="co">](http://jepusto.github.io/clubSandwich/)</span></span>
<span id="cb52-220"><a href="#cb52-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-221"><a href="#cb52-221" aria-hidden="true" tabindex="-1"></a>The following output shows the results for the heteroskedastic (cone-shaped) example data in @fig-homo2, using both the regular standard errors and HC standard errors. We can see that both sets of output are pretty similar: while the "Estimates" don't change, the "Std. Errors" are a bit different in the two sets of output. In this case, the HC standard errors don't affect conclusions about statistical significance, but in other cases they can lead to more dramatic differences in interpretation. **Please examine these two sets of output and write down any questions you have about their interpretation.** </span>
<span id="cb52-222"><a href="#cb52-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-223"><a href="#cb52-223" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Regular OLS standard errors : </span>
<span id="cb52-226"><a href="#cb52-226" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-227"><a href="#cb52-227" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb52-228"><a href="#cb52-228" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb52-229"><a href="#cb52-229" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb52-230"><a href="#cb52-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-231"><a href="#cb52-231" aria-hidden="true" tabindex="-1"></a><span class="co"># Regular SE: </span></span>
<span id="cb52-232"><a href="#cb52-232" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span>
<span id="cb52-233"><a href="#cb52-233" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-234"><a href="#cb52-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-235"><a href="#cb52-235" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>HC standard errors: </span>
<span id="cb52-236"><a href="#cb52-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-239"><a href="#cb52-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-240"><a href="#cb52-240" aria-hidden="true" tabindex="-1"></a><span class="co"># HC SE</span></span>
<span id="cb52-241"><a href="#cb52-241" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2. Use "hccm" to get the HC SEs for our model </span></span>
<span id="cb52-242"><a href="#cb52-242" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod4)</span>
<span id="cb52-243"><a href="#cb52-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-244"><a href="#cb52-244" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb52-245"><a href="#cb52-245" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod4, hcse)</span>
<span id="cb52-246"><a href="#cb52-246" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-247"><a href="#cb52-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-248"><a href="#cb52-248" aria-hidden="true" tabindex="-1"></a>One final note: HC standard errors do not assume the data are homoskedastic. So, they can be used regardless of whether the homoskedasticity assumption is met or not. But, when the data *are* homoskedastic, the regular OLS standard errors are usually more precise (i.e., smaller). So, we generally don't want to use HC standard errors unless there is evidence of heteroskedasticity in the data. This is why we do graphical checks first!</span>
<span id="cb52-249"><a href="#cb52-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-250"><a href="#cb52-250" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb52-251"><a href="#cb52-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-252"><a href="#cb52-252" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The assumption of homoskedasticity (or homogeneity variance, or just equal variances) means that the variance of the residuals should not change as a function of the predicted values. </span>
<span id="cb52-253"><a href="#cb52-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-254"><a href="#cb52-254" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Because we are again concerned with residuals and predicted values, we can re-use the same plot we used to check linearity. However, now we are interested in whether the range of the residuals (on the vertical axis) changes over the predicted values (on the horizontal axis). </span>
<span id="cb52-255"><a href="#cb52-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-256"><a href="#cb52-256" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If we suspect that heteroskedasticity is a problem, we can adjust how the standard errors of the regression coefficients are computed. These adjusted standard errors are variously referred to as heteroskedasticity-consistent, heteroskedasticity-robust, robust, or "sandwich" estimates. </span>
<span id="cb52-257"><a href="#cb52-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-258"><a href="#cb52-258" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>To implement in HC standard errors in R, we can use a three step procedure: </span>
<span id="cb52-259"><a href="#cb52-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-260"><a href="#cb52-260" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>First, we estimate the model as usual, (e.g., using the <span class="in">`lm`</span> function)</span>
<span id="cb52-261"><a href="#cb52-261" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Second, we compute the HC standard errors (e.g., using the <span class="in">`hccm`</span> function of the <span class="in">`car`</span> package.)</span>
<span id="cb52-262"><a href="#cb52-262" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Third, we use the HC standard errors to compute the correct t-tests / confidence intervals (e.g., using the <span class="in">`coeftest`</span> function of the <span class="in">`lmtest`</span> package. )</span>
<span id="cb52-263"><a href="#cb52-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-264"><a href="#cb52-264" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-265"><a href="#cb52-265" aria-hidden="true" tabindex="-1"></a>You can find a more complete discussion of robust standard errors in R in the vignettes linked here: <span class="co">[</span><span class="ot">http://jepusto.github.io/clubSandwich/</span><span class="co">](http://jepusto.github.io/clubSandwich/)</span></span>
<span id="cb52-266"><a href="#cb52-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-267"><a href="#cb52-267" aria-hidden="true" tabindex="-1"></a><span class="fu">## Normality {#sec-normality-7}</span></span>
<span id="cb52-268"><a href="#cb52-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-269"><a href="#cb52-269" aria-hidden="true" tabindex="-1"></a>The last assumption we need to check is normality of the residuals. There are many ways to compare the empirical distribution of a variable (e.g., the residuals in a regression analysis) to a theoretical distribution (e.g., the normal). One general-purpose technique is a qq plot (short for quantile-quantile plot). A qq plot compares the quantiles (e.g., percentiles) of two different distributions. </span>
<span id="cb52-270"><a href="#cb52-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-271"><a href="#cb52-271" aria-hidden="true" tabindex="-1"></a>For our assumption, we want to compare the quantiles of our standardized residuals to the quantiles of a standard normal distribution. Standardizing means the residuals should have variance equal to one, and, combined with the other population assumptions of linear regression, this implies that the residuals should have a standard normal distribution (see @sec-recap-7).</span>
<span id="cb52-272"><a href="#cb52-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-273"><a href="#cb52-273" aria-hidden="true" tabindex="-1"></a>Since qq plots might not be something you have seen before, we'll take a look at a few examples. Each figure below pairs a histogram and qq plot. In the qq plot, data points should fall on the diagonal line if the data are normally distributed. It should be emphasized that the line in the qq plot is *not a regression line!* It is just the diagonal line $Y = X$, and the bulk of the data points should fall on that line if the data were drawn from a normal distribution. </span>
<span id="cb52-274"><a href="#cb52-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-275"><a href="#cb52-275" aria-hidden="true" tabindex="-1"></a>In the following examples, focus on how the pattern in the histogram shows up as deviations from the diagonal line in the qq plot. We will discuss the interpretation of these patterns together in class, but for now, **please write down any questions you have about the interpretation of the qq plots.**</span>
<span id="cb52-276"><a href="#cb52-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-277"><a href="#cb52-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-280"><a href="#cb52-280" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-281"><a href="#cb52-281" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing histograms and q-q plots</span></span>
<span id="cb52-282"><a href="#cb52-282" aria-hidden="true" tabindex="-1"></a>distributions <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"distributions.csv"</span>)</span>
<span id="cb52-283"><a href="#cb52-283" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(distributions)[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="st">"normal"</span></span>
<span id="cb52-284"><a href="#cb52-284" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(distributions)</span>
<span id="cb52-285"><a href="#cb52-285" aria-hidden="true" tabindex="-1"></a>dist_names <span class="ot">&lt;-</span> <span class="fu">names</span>(distributions)</span>
<span id="cb52-286"><a href="#cb52-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-287"><a href="#cb52-287" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal </span></span>
<span id="cb52-288"><a href="#cb52-288" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-289"><a href="#cb52-289" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(normal, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Normal"</span>)</span>
<span id="cb52-290"><a href="#cb52-290" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(normal, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-291"><a href="#cb52-291" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(normal)</span>
<span id="cb52-292"><a href="#cb52-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-293"><a href="#cb52-293" aria-hidden="true" tabindex="-1"></a><span class="co"># Negative skew</span></span>
<span id="cb52-294"><a href="#cb52-294" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-295"><a href="#cb52-295" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(neg_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Negative Skew"</span>)</span>
<span id="cb52-296"><a href="#cb52-296" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(neg_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-297"><a href="#cb52-297" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(neg_skew)</span>
<span id="cb52-298"><a href="#cb52-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-299"><a href="#cb52-299" aria-hidden="true" tabindex="-1"></a><span class="co"># Positive skew</span></span>
<span id="cb52-300"><a href="#cb52-300" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-301"><a href="#cb52-301" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(pos_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Positive Skew"</span>)</span>
<span id="cb52-302"><a href="#cb52-302" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(pos_skew, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-303"><a href="#cb52-303" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(pos_skew)</span>
<span id="cb52-304"><a href="#cb52-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-305"><a href="#cb52-305" aria-hidden="true" tabindex="-1"></a><span class="co"># Leptokurtic</span></span>
<span id="cb52-306"><a href="#cb52-306" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-307"><a href="#cb52-307" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(lepto, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">main =</span> <span class="st">"Lepotkurtosis"</span>)</span>
<span id="cb52-308"><a href="#cb52-308" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(lepto, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-309"><a href="#cb52-309" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(lepto)</span>
<span id="cb52-310"><a href="#cb52-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-311"><a href="#cb52-311" aria-hidden="true" tabindex="-1"></a><span class="co"># Platykurtic</span></span>
<span id="cb52-312"><a href="#cb52-312" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb52-313"><a href="#cb52-313" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(platy, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>,  <span class="at">main =</span> <span class="st">"Platykurtosis"</span>)</span>
<span id="cb52-314"><a href="#cb52-314" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(platy, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-315"><a href="#cb52-315" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(platy)</span>
<span id="cb52-316"><a href="#cb52-316" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(distributions)</span>
<span id="cb52-317"><a href="#cb52-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-318"><a href="#cb52-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-319"><a href="#cb52-319" aria-hidden="true" tabindex="-1"></a>Next, let's consider a more realistic example using the default plotting from the <span class="in">`lm`</span> function. **Please write down whether you think the normality assumption is problematic for the data in @fig-normality1, and be sure to explain why with reference to the plot.** Hint: if you think the data are non-normal, you should be able to interpret the pattern of deviations with reference to the examples given above (e.g. skew, kurtosis). </span>
<span id="cb52-320"><a href="#cb52-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-321"><a href="#cb52-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-normality1, fig.width = 8, fig.cap = "An example from ECLS.", fig.align = 'center'}</span></span>
<span id="cb52-322"><a href="#cb52-322" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-323"><a href="#cb52-323" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb52-324"><a href="#cb52-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-325"><a href="#cb52-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-326"><a href="#cb52-326" aria-hidden="true" tabindex="-1"></a>Practice makes perfect, so lets work through a few more examples. In each of the examples in @fig-normality2, **please write down whether you think the normality assumption is problematic and explain why with reference to the plots.**</span>
<span id="cb52-327"><a href="#cb52-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-328"><a href="#cb52-328" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-normality2, fig.height = 10, fig.cap = "More examples.", fig.align = 'center'}</span></span>
<span id="cb52-329"><a href="#cb52-329" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-330"><a href="#cb52-330" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb52-331"><a href="#cb52-331" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb52-332"><a href="#cb52-332" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb52-333"><a href="#cb52-333" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-334"><a href="#cb52-334" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-335"><a href="#cb52-335" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb52-336"><a href="#cb52-336" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb52-337"><a href="#cb52-337" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb52-338"><a href="#cb52-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-339"><a href="#cb52-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-340"><a href="#cb52-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-341"><a href="#cb52-341" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary </span></span>
<span id="cb52-342"><a href="#cb52-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-343"><a href="#cb52-343" aria-hidden="true" tabindex="-1"></a>To check the assumption of normality, we can use a qq plot of the standardized residuals against the standard normal distribution. </span>
<span id="cb52-344"><a href="#cb52-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-345"><a href="#cb52-345" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the points from the qq plot follows the line Y = X, then there is no evidence against the assumption.</span>
<span id="cb52-346"><a href="#cb52-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-347"><a href="#cb52-347" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the residuals do show a trend off of the diagonal line, then we should worry about the assumption.</span>
<span id="cb52-348"><a href="#cb52-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-349"><a href="#cb52-349" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>If the assumption is violated, the central limit theorem implies that significance tests used in OLS regression will be robust to violations of normality when sample sizes are large.  </span>
<span id="cb52-350"><a href="#cb52-350" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb52-351"><a href="#cb52-351" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Practically this means we can often ignore mild violations of normality when $N / K &gt; 30$ (but other guidelines are used too).</span>
<span id="cb52-352"><a href="#cb52-352" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>For some specific types of violations, notably positive skew, it is also common to transform the Y variable (see @sec-chap-9).</span>
<span id="cb52-353"><a href="#cb52-353" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>When we are worried that non-normality arises from a relatively small subset of the data that may be unduly influencing the results, this can be addressed through regression diagnostics (see @sec-diagnostics-7) and robust statistics (which is an advanced topic). </span>
<span id="cb52-354"><a href="#cb52-354" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-355"><a href="#cb52-355" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Oh, and one last thing: The line in a qq plot is *not a regression line!*</span>
<span id="cb52-356"><a href="#cb52-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-357"><a href="#cb52-357" aria-hidden="true" tabindex="-1"></a><span class="fu">## A worked example {#sec-worked-example-7}</span></span>
<span id="cb52-358"><a href="#cb52-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-359"><a href="#cb52-359" aria-hidden="true" tabindex="-1"></a>To illustrate the assumption checking procedures outlined above, let's revisit the example from @sec-worked-example-6. In that example, it was noted that there was evidence that one (or more) of the assumptions were problematic. Let's take a look at why this was the case. </span>
<span id="cb52-360"><a href="#cb52-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-361"><a href="#cb52-361" aria-hidden="true" tabindex="-1"></a>For this example, we will use the ECLS data to regress reading achievement at the beginning of Kindergarten (<span class="in">`c1rrscal`</span>) on SES (<span class="in">`wksesl`</span>), parental (mother's and father's) education (<span class="in">`wkmomed`</span> and <span class="in">`wkdaded`</span>, respectively), and attendance in center-based care before K (<span class="in">`p1center`</span>). This is model 3 from @sec-worked-example-6 (i.e., we don't consider the model with the interactions). </span>
<span id="cb52-362"><a href="#cb52-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-363"><a href="#cb52-363" aria-hidden="true" tabindex="-1"></a>The workflow for assumption checking requires first running the model and then producing the residual vs fitted plot and a qq plot of the residuals. If the plots look OK, we go ahead and interpret the model results. If the plots don't look OK, we give up and wonder why we ever bothered with regression in the first place. Just kidding :)  -- the next two chapters of these notes address how to deal with violations of the linearity and normality assumptions, and we already know how to deal with heteroskedasticity from @sec-heteroskedasticity-7. </span>
<span id="cb52-364"><a href="#cb52-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-365"><a href="#cb52-365" aria-hidden="true" tabindex="-1"></a>After running the model, we obtain the following two plots from the regression output. **For each of the three population assumptions of linear regression, please write down whether you think the assumption is problematic and explain why with reference to the plots.** Again, the purpose of this exercise is for you to think about how to interpret the plots with respect to the assumptions. I am looking for you to be explicit about how you reason from the plots to your conclusions. I am less interested in the conclusions per se, as this is something that requires practice to get right.  </span>
<span id="cb52-366"><a href="#cb52-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-369"><a href="#cb52-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-370"><a href="#cb52-370" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up and load data</span></span>
<span id="cb52-371"><a href="#cb52-371" aria-hidden="true" tabindex="-1"></a><span class="co"># rm(list = ls())</span></span>
<span id="cb52-372"><a href="#cb52-372" aria-hidden="true" tabindex="-1"></a><span class="co"># load("ECLS2577.RData")</span></span>
<span id="cb52-373"><a href="#cb52-373" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(ecls)</span></span>
<span id="cb52-374"><a href="#cb52-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-375"><a href="#cb52-375" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb52-376"><a href="#cb52-376" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb52-377"><a href="#cb52-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-378"><a href="#cb52-378" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb52-379"><a href="#cb52-379" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-380"><a href="#cb52-380" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">1</span>)</span>
<span id="cb52-381"><a href="#cb52-381" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">2</span>)</span>
<span id="cb52-382"><a href="#cb52-382" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-383"><a href="#cb52-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-384"><a href="#cb52-384" aria-hidden="true" tabindex="-1"></a>To foreshadow the next couple of chapters, here is what the plots looked like after dealing with positive skew of the residuals and the non-normality of the regression line: </span>
<span id="cb52-385"><a href="#cb52-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-388"><a href="#cb52-388" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-389"><a href="#cb52-389" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb52-390"><a href="#cb52-390" aria-hidden="true" tabindex="-1"></a>log_c1rrscal <span class="ot">&lt;-</span> <span class="fu">log</span>(c1rrscal <span class="sc">-</span> <span class="fu">min</span>(c1rrscal) <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb52-391"><a href="#cb52-391" aria-hidden="true" tabindex="-1"></a>wksesl_sq <span class="ot">&lt;-</span> wksesl<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb52-392"><a href="#cb52-392" aria-hidden="true" tabindex="-1"></a>mod6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log_c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wksesl_sq <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded)</span>
<span id="cb52-393"><a href="#cb52-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-394"><a href="#cb52-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb52-395"><a href="#cb52-395" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-396"><a href="#cb52-396" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod6, <span class="dv">1</span>)</span>
<span id="cb52-397"><a href="#cb52-397" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod6, <span class="dv">2</span>)</span>
<span id="cb52-398"><a href="#cb52-398" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-399"><a href="#cb52-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-400"><a href="#cb52-400" aria-hidden="true" tabindex="-1"></a>Neither assumption has been perfectly addressed, and, in particular, it looks like we may have over-corrected the positive skew and ended up with some negative skew. Also note that the data continue to exhibit heteroskedasticity, which is apparent from looking at the residual vs fitted plot in the range -1 to -3 of the residuals. Because heteroskedasticity is still an issue for these data, we can improve on the analysis reported in @sec-worked-example-6 by using HC standard errors rather than "regular" OLS standard errors. The difference between the two approaches is illustrated below. Remember, the estimates stay the same, but the SE's change (and consequently the t-tests and p-values). </span>
<span id="cb52-401"><a href="#cb52-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-402"><a href="#cb52-402" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Regular SE (same as Model 3 in @sec-worked-example-6):  </span>
<span id="cb52-403"><a href="#cb52-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-406"><a href="#cb52-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-407"><a href="#cb52-407" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod6)</span>
<span id="cb52-408"><a href="#cb52-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-409"><a href="#cb52-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-410"><a href="#cb52-410" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>HC SE</span>
<span id="cb52-411"><a href="#cb52-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-414"><a href="#cb52-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-415"><a href="#cb52-415" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod6, car<span class="sc">::</span><span class="fu">hccm</span>(mod6))</span>
<span id="cb52-416"><a href="#cb52-416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-417"><a href="#cb52-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-418"><a href="#cb52-418" aria-hidden="true" tabindex="-1"></a>In this example, the HC SE's didn't lead to substantively different inferences, but we should report the results with HC SE's based on the assumption checking.</span>
<span id="cb52-419"><a href="#cb52-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-420"><a href="#cb52-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-421"><a href="#cb52-421" aria-hidden="true" tabindex="-1"></a><span class="fu">## Diagnostics* {#sec-diagnostics-7}</span></span>
<span id="cb52-422"><a href="#cb52-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-423"><a href="#cb52-423" aria-hidden="true" tabindex="-1"></a>This section is optional and is currently under construction (i.e., many typos). It focuses on walking through the code so it is recommended to treat this like an Exercises section and scroll to the top of the page, click on the "&lt;/&gt; Code" menu, then select "Show All Code." </span>
<span id="cb52-424"><a href="#cb52-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-425"><a href="#cb52-425" aria-hidden="true" tabindex="-1"></a>Like assumption checking, regression diagnostics also make extensive use of regression residuals, but this time the objective is to identify individual data points that are "outliers" with respect to the model. To work through the basic concepts of regression diagnostics, let's again use the Anscombe's quartet.</span>
<span id="cb52-426"><a href="#cb52-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-427"><a href="#cb52-427" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.height= 8}</span></span>
<span id="cb52-428"><a href="#cb52-428" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting Anscombe's quartet</span></span>
<span id="cb52-429"><a href="#cb52-429" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(anscombe)</span>
<span id="cb52-430"><a href="#cb52-430" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb52-431"><a href="#cb52-431" aria-hidden="true" tabindex="-1"></a>ymax <span class="ot">&lt;-</span> <span class="fu">max</span>(anscombe[,<span class="dv">5</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb52-432"><a href="#cb52-432" aria-hidden="true" tabindex="-1"></a>ymin <span class="ot">&lt;-</span> <span class="fu">min</span>(anscombe[,<span class="dv">5</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb52-433"><a href="#cb52-433" aria-hidden="true" tabindex="-1"></a>xmax <span class="ot">&lt;-</span> <span class="fu">max</span>(anscombe[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb52-434"><a href="#cb52-434" aria-hidden="true" tabindex="-1"></a>xmin <span class="ot">&lt;-</span> <span class="fu">min</span>(anscombe[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb52-435"><a href="#cb52-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-436"><a href="#cb52-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-437"><a href="#cb52-437" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y1, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb52-438"><a href="#cb52-438" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y1 <span class="sc">~</span> x1))</span>
<span id="cb52-439"><a href="#cb52-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-440"><a href="#cb52-440" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x2, y2, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb52-441"><a href="#cb52-441" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y2 <span class="sc">~</span> x2))</span>
<span id="cb52-442"><a href="#cb52-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-443"><a href="#cb52-443" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, y3, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb52-444"><a href="#cb52-444" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y3 <span class="sc">~</span> x3))</span>
<span id="cb52-445"><a href="#cb52-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-446"><a href="#cb52-446" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, y4, <span class="at">col =</span> <span class="st">"#4B9CD3"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax))</span>
<span id="cb52-447"><a href="#cb52-447" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y4 <span class="sc">~</span> x4))</span>
<span id="cb52-448"><a href="#cb52-448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-449"><a href="#cb52-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-450"><a href="#cb52-450" aria-hidden="true" tabindex="-1"></a>The interesting thing about these four examples is that they all have the same univariate and bivariate summary statistics -- e.g., the same mean, variance, covariance, correlation, and regression coefficients. </span>
<span id="cb52-451"><a href="#cb52-451" aria-hidden="true" tabindex="-1"></a>But first example is the only one that would be suitable for analysis by using these statistics. The second example shows a non-linear relationship, which we addressed in Section \@ref(linearity-8). In this section we will focus on the last two examples, since they have clear outliers.</span>
<span id="cb52-452"><a href="#cb52-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-453"><a href="#cb52-453" aria-hidden="true" tabindex="-1"></a><span class="fu">### Leverage</span></span>
<span id="cb52-454"><a href="#cb52-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-455"><a href="#cb52-455" aria-hidden="true" tabindex="-1"></a>Leverage describes how "unusual" a data point is on the X variable(s) -- i.e., how far from the mean it is on each predictor. The function <span class="in">`hatvalues`</span> computes the leverage for each data point. Let's check out the leverage for the 3rd and 4th examples from Anscombe's quartet.</span>
<span id="cb52-456"><a href="#cb52-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-459"><a href="#cb52-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-460"><a href="#cb52-460" aria-hidden="true" tabindex="-1"></a><span class="co"># leverage for Anscombe 3</span></span>
<span id="cb52-461"><a href="#cb52-461" aria-hidden="true" tabindex="-1"></a>anscombe3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y3 <span class="sc">~</span> x3)</span>
<span id="cb52-462"><a href="#cb52-462" aria-hidden="true" tabindex="-1"></a>leverage3 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(anscombe3)</span>
<span id="cb52-463"><a href="#cb52-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-464"><a href="#cb52-464" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the leverage values for each data point</span></span>
<span id="cb52-465"><a href="#cb52-465" aria-hidden="true" tabindex="-1"></a>leverage3</span>
<span id="cb52-466"><a href="#cb52-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-467"><a href="#cb52-467" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the leverage values in the scatter plot using the function "text"</span></span>
<span id="cb52-468"><a href="#cb52-468" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-469"><a href="#cb52-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-470"><a href="#cb52-470" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, y3, <span class="at">col =</span> <span class="st">"white"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax), <span class="at">main =</span> <span class="st">"Leverage for Anscombe 3"</span>)</span>
<span id="cb52-471"><a href="#cb52-471" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y3 <span class="sc">~</span> x3))</span>
<span id="cb52-472"><a href="#cb52-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-473"><a href="#cb52-473" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(y3 <span class="sc">~</span> x3, <span class="at">labels =</span> <span class="fu">round</span>(leverage3, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-474"><a href="#cb52-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-475"><a href="#cb52-475" aria-hidden="true" tabindex="-1"></a><span class="co"># leverage for Anscombe 4</span></span>
<span id="cb52-476"><a href="#cb52-476" aria-hidden="true" tabindex="-1"></a>anscombe4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y4 <span class="sc">~</span> x4)</span>
<span id="cb52-477"><a href="#cb52-477" aria-hidden="true" tabindex="-1"></a>leverage4 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(anscombe4)</span>
<span id="cb52-478"><a href="#cb52-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-479"><a href="#cb52-479" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a look at the leverage values for each data point</span></span>
<span id="cb52-480"><a href="#cb52-480" aria-hidden="true" tabindex="-1"></a>leverage4</span>
<span id="cb52-481"><a href="#cb52-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-482"><a href="#cb52-482" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the leverage values in the scatter plot using the function "text"</span></span>
<span id="cb52-483"><a href="#cb52-483" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, y4, <span class="at">col =</span> <span class="st">"white"</span>, <span class="at">xlim =</span> <span class="fu">c</span>(xmin, xmax), <span class="at">ylim =</span> <span class="fu">c</span>(ymin, ymax),  <span class="at">main =</span> <span class="st">"Leverage for Anscombe 4"</span>)</span>
<span id="cb52-484"><a href="#cb52-484" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y4 <span class="sc">~</span> x4))</span>
<span id="cb52-485"><a href="#cb52-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-486"><a href="#cb52-486" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(y4 <span class="sc">~</span> x4, <span class="at">labels =</span> <span class="fu">round</span>(leverage4, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-487"><a href="#cb52-487" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-488"><a href="#cb52-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-489"><a href="#cb52-489" aria-hidden="true" tabindex="-1"></a>Recall from the lesson that </span>
<span id="cb52-490"><a href="#cb52-490" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-491"><a href="#cb52-491" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>h should be smaller (closer to 0) for values closer to the mean of X</span>
<span id="cb52-492"><a href="#cb52-492" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-493"><a href="#cb52-493" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>The maximum value of h is 1</span>
<span id="cb52-494"><a href="#cb52-494" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-495"><a href="#cb52-495" aria-hidden="true" tabindex="-1"></a>Based on the plots, we can see that the largest leverage is for the outlier in Anscombe 4. </span>
<span id="cb52-496"><a href="#cb52-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-497"><a href="#cb52-497" aria-hidden="true" tabindex="-1"></a><span class="fu">### Distance (residuals)</span></span>
<span id="cb52-498"><a href="#cb52-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-499"><a href="#cb52-499" aria-hidden="true" tabindex="-1"></a>Distance is about the size of the residuals. In order to judge the size of a residual, it helps to use the (externally) studentized residuals rather than the "raw" residuals. Because the studentized residual have a t-distribution on $N - K - 2$ degrees of freedom, a rough ballpark for interpreting studentized residuals is that </span>
<span id="cb52-500"><a href="#cb52-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-501"><a href="#cb52-501" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Values around +/- 2 are considered large.</span>
<span id="cb52-502"><a href="#cb52-502" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-503"><a href="#cb52-503" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Values beyond +/- 3 are considered very large. </span>
<span id="cb52-504"><a href="#cb52-504" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb52-505"><a href="#cb52-505" aria-hidden="true" tabindex="-1"></a>Let's see what we have for our examples:</span>
<span id="cb52-506"><a href="#cb52-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-509"><a href="#cb52-509" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-510"><a href="#cb52-510" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 3</span></span>
<span id="cb52-511"><a href="#cb52-511" aria-hidden="true" tabindex="-1"></a>distance3 <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(anscombe3)</span>
<span id="cb52-512"><a href="#cb52-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-513"><a href="#cb52-513" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-514"><a href="#cb52-514" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, distance3, <span class="at">main =</span> <span class="st">"Leverage for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-515"><a href="#cb52-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-516"><a href="#cb52-516" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb52-517"><a href="#cb52-517" aria-hidden="true" tabindex="-1"></a>distance4 <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(anscombe4)</span>
<span id="cb52-518"><a href="#cb52-518" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, distance4, <span class="at">main =</span> <span class="st">"Leverage for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-519"><a href="#cb52-519" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-520"><a href="#cb52-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-521"><a href="#cb52-521" aria-hidden="true" tabindex="-1"></a>Clearly, the notion of distance is useful for describing what the problem is with Anscombe's 3rd example. For the 4th example, the outlying data point is omitted because it has leverage of exactly 1, which means that the studentized residuals are undefined (divide by zero; R notes this in the console). </span>
<span id="cb52-522"><a href="#cb52-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-523"><a href="#cb52-523" aria-hidden="true" tabindex="-1"></a><span class="fu">### Influence </span></span>
<span id="cb52-524"><a href="#cb52-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-525"><a href="#cb52-525" aria-hidden="true" tabindex="-1"></a>Influence describes how much the model results would change if a data point were omitted. Roughly, the conceptual relationships among influence, distance, and leverage are given by the following equation:</span>
<span id="cb52-526"><a href="#cb52-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-527"><a href="#cb52-527" aria-hidden="true" tabindex="-1"></a><span class="sc">\[</span> \text{Influence} = \text{Distance} \times \text{Leverage}  <span class="sc">\]</span></span>
<span id="cb52-528"><a href="#cb52-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-529"><a href="#cb52-529" aria-hidden="true" tabindex="-1"></a>This equation tells us that, for a data point to have high influence, it must be a large distance from the regression line (have a large residual) *and* have high leverage (be far away from the mean on $X$). </span>
<span id="cb52-530"><a href="#cb52-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-531"><a href="#cb52-531" aria-hidden="true" tabindex="-1"></a>There are a number of ways of computing influence. Like externally studentized residuals, they are all deletion statistics, or statistics computed using a “leave-one-out” approach. </span>
<span id="cb52-532"><a href="#cb52-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-533"><a href="#cb52-533" aria-hidden="true" tabindex="-1"></a>Influence statistics can also be classified into global versus local. Global approaches consider how a data point affects the predicted values. Local approaches consider how a data point affects the value of a specific regression coefficient.</span>
<span id="cb52-534"><a href="#cb52-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-535"><a href="#cb52-535" aria-hidden="true" tabindex="-1"></a>Let's start with DFFITS and Cook's distance, two measures of global influence.</span>
<span id="cb52-536"><a href="#cb52-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-539"><a href="#cb52-539" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-540"><a href="#cb52-540" aria-hidden="true" tabindex="-1"></a><span class="co"># DFFITS for Anscombe 3</span></span>
<span id="cb52-541"><a href="#cb52-541" aria-hidden="true" tabindex="-1"></a>DFFITS3 <span class="ot">&lt;-</span> <span class="fu">dffits</span>(anscombe3)</span>
<span id="cb52-542"><a href="#cb52-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-543"><a href="#cb52-543" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-544"><a href="#cb52-544" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, DFFITS3, <span class="at">main =</span> <span class="st">"DFFITS for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-545"><a href="#cb52-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-546"><a href="#cb52-546" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb52-547"><a href="#cb52-547" aria-hidden="true" tabindex="-1"></a>DFFITS4 <span class="ot">&lt;-</span> <span class="fu">dffits</span>(anscombe4)</span>
<span id="cb52-548"><a href="#cb52-548" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, DFFITS4, <span class="at">main =</span> <span class="st">"DFFITS for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-549"><a href="#cb52-549" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-550"><a href="#cb52-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-553"><a href="#cb52-553" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-554"><a href="#cb52-554" aria-hidden="true" tabindex="-1"></a><span class="co"># Cook's distance for Anscombe 3</span></span>
<span id="cb52-555"><a href="#cb52-555" aria-hidden="true" tabindex="-1"></a>Cooks3 <span class="ot">&lt;-</span> <span class="fu">cooks.distance</span>(anscombe3)</span>
<span id="cb52-556"><a href="#cb52-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-557"><a href="#cb52-557" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-558"><a href="#cb52-558" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, Cooks3, <span class="at">main =</span> <span class="st">"Cook's D for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-559"><a href="#cb52-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-560"><a href="#cb52-560" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb52-561"><a href="#cb52-561" aria-hidden="true" tabindex="-1"></a>Cooks4 <span class="ot">&lt;-</span> <span class="fu">cooks.distance</span>(anscombe4)</span>
<span id="cb52-562"><a href="#cb52-562" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, Cooks4, <span class="at">main =</span> <span class="st">"Cook's D for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-563"><a href="#cb52-563" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-564"><a href="#cb52-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-565"><a href="#cb52-565" aria-hidden="true" tabindex="-1"></a>These statistics are similar but Cook's distance is more interpetable. Values greater than 1 are considered indicative of high influence. We can see that the outlier in the 3rd example is highly influence. The outlier in the 4th example is "NA" because h = 1 hence there is a divide by zero problem. </span>
<span id="cb52-566"><a href="#cb52-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-567"><a href="#cb52-567" aria-hidden="true" tabindex="-1"></a>For local measures of influence, the interpretation is roughly the same as global measures with simple regression (i.e., a  single predictor). For multiple regression, local measures can provided additional insight to consider which regression coefficients are most influenced by an outlier. </span>
<span id="cb52-568"><a href="#cb52-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-571"><a href="#cb52-571" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-572"><a href="#cb52-572" aria-hidden="true" tabindex="-1"></a><span class="co"># DFBETAs distance for Anscombe 3</span></span>
<span id="cb52-573"><a href="#cb52-573" aria-hidden="true" tabindex="-1"></a>DFBETA3 <span class="ot">&lt;-</span> <span class="fu">dfbetas</span>(anscombe3)</span>
<span id="cb52-574"><a href="#cb52-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-575"><a href="#cb52-575" aria-hidden="true" tabindex="-1"></a><span class="co">#Take a look at the output: We get values for each coefficient, including the intercept</span></span>
<span id="cb52-576"><a href="#cb52-576" aria-hidden="true" tabindex="-1"></a>DFBETA3 </span>
<span id="cb52-577"><a href="#cb52-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-578"><a href="#cb52-578" aria-hidden="true" tabindex="-1"></a><span class="co"># Plots for the regression coefficients</span></span>
<span id="cb52-579"><a href="#cb52-579" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-580"><a href="#cb52-580" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, DFBETA3[,<span class="st">"x3"</span>], <span class="at">main =</span> <span class="st">"DFBETA for Anscombe 3"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-581"><a href="#cb52-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-582"><a href="#cb52-582" aria-hidden="true" tabindex="-1"></a><span class="co"># Distance for Anscombe 4</span></span>
<span id="cb52-583"><a href="#cb52-583" aria-hidden="true" tabindex="-1"></a>DFBETA4 <span class="ot">&lt;-</span> <span class="fu">dfbetas</span>(anscombe4)</span>
<span id="cb52-584"><a href="#cb52-584" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, DFBETA4[,<span class="st">"x4"</span>], <span class="at">main =</span> <span class="st">"DFBETA for Anscombe 4"</span>,  <span class="at">col =</span> <span class="st">"#4B9CD3"</span>)</span>
<span id="cb52-585"><a href="#cb52-585" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-586"><a href="#cb52-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-587"><a href="#cb52-587" aria-hidden="true" tabindex="-1"></a>The output for DFBETA3 looks a lot like DFFITS3 (because we only have one predictor). </span>
<span id="cb52-588"><a href="#cb52-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-589"><a href="#cb52-589" aria-hidden="true" tabindex="-1"></a>For DFBETA4, it is strange that our unusual data point (x4 = 18) was not identified as problematic -- keep in mind that when this data point is removed, the variance of X is zero and so the regression coefficient for the leave-one-out model is not defined. Still, it is not clear why R reports the value as zero, rather than omitted. </span>
<span id="cb52-590"><a href="#cb52-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-591"><a href="#cb52-591" aria-hidden="true" tabindex="-1"></a><span class="fu">### A more realistic example</span></span>
<span id="cb52-592"><a href="#cb52-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-593"><a href="#cb52-593" aria-hidden="true" tabindex="-1"></a>As a more realistic example, let's consider Question 3 from Assignment 1 using the graphical output from <span class="in">`lm`</span>. Note that the graphical output uses the internally studentized residuals, and refers to these as "standardized residuals". </span>
<span id="cb52-594"><a href="#cb52-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-597"><a href="#cb52-597" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-598"><a href="#cb52-598" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(c4rmscal <span class="sc">~</span> wksesl <span class="sc">+</span> t1learn, <span class="at">data =</span> ecls)</span>
<span id="cb52-599"><a href="#cb52-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-600"><a href="#cb52-600" aria-hidden="true" tabindex="-1"></a><span class="co"># Influence via Cook's distance</span></span>
<span id="cb52-601"><a href="#cb52-601" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model, <span class="at">which =</span> <span class="dv">4</span>)</span>
<span id="cb52-602"><a href="#cb52-602" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-603"><a href="#cb52-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-604"><a href="#cb52-604" aria-hidden="true" tabindex="-1"></a>We can see that, although R automatically labels the 3 data points with the highest values of Cook's D, none of the data points are actually close to the cut off value of 1. In other words, none of the data points in this example have an undue influence on the results of the regression model. </span>
<span id="cb52-605"><a href="#cb52-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-606"><a href="#cb52-606" aria-hidden="true" tabindex="-1"></a><span class="fu">## Workbook {#sec-workbook-7}</span></span>
<span id="cb52-607"><a href="#cb52-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-608"><a href="#cb52-608" aria-hidden="true" tabindex="-1"></a>This section collects the questions asked in this chapter. The lesson for this chapter will focus on discussing these questions and then working on the exercises in @sec-exercises-7. The lesson will **not** be a lecture that reviews all of the material in the chapter! So, if you haven't written down / thought about the answers to these questions before class, the lesson will not be very useful for you. Please engage with each question by writing down one or more answers, asking clarifying questions about related material, posing follow up questions, etc. </span>
<span id="cb52-609"><a href="#cb52-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-610"><a href="#cb52-610" aria-hidden="true" tabindex="-1"></a>@sec-linearity-7</span>
<span id="cb52-611"><a href="#cb52-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-612"><a href="#cb52-612" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>Please write down whether you think the linearity assumption is problematic for the example below, and be sure to explain why with reference to the figure. Keep in mind that interpreting plots takes a bit of practice and in general there is no "right" answer. Rather, what I am looking for is an explanation of *why* you think the assumption is problematic or not. Your explanation should refer to the interpretation of residual vs fitted plots, as outlined above. </span>
<span id="cb52-613"><a href="#cb52-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-614"><a href="#cb52-614" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.width = 8, fig.cap = "An example from ECLS.", fig.align = 'center'}</span></span>
<span id="cb52-615"><a href="#cb52-615" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-616"><a href="#cb52-616" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-617"><a href="#cb52-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-618"><a href="#cb52-618" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>For each of the four examples below, please write down whether you think the linearity assumption is problematic and explain why with reference to the plots. Hint: be careful not to over-interpret the lowess line in the tails of the plots, where only a few data points can have a big impact on the local trend. Focus your interpretation on the bulk of the data, and whether it shows a systemic trend away from the horizontal line at 0. </span>
<span id="cb52-619"><a href="#cb52-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-620"><a href="#cb52-620" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig.height = 10, fig.cap = "More examples.", fig.align = 'center'}</span></span>
<span id="cb52-621"><a href="#cb52-621" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-622"><a href="#cb52-622" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb52-623"><a href="#cb52-623" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb52-624"><a href="#cb52-624" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb52-625"><a href="#cb52-625" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-626"><a href="#cb52-626" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-627"><a href="#cb52-627" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb52-628"><a href="#cb52-628" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-629"><a href="#cb52-629" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb52-630"><a href="#cb52-630" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-631"><a href="#cb52-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-632"><a href="#cb52-632" aria-hidden="true" tabindex="-1"></a>@sec-homoskedasticity-7</span>
<span id="cb52-633"><a href="#cb52-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-634"><a href="#cb52-634" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Let's take another look at the four plots in the above figure. For each plot, please write down whether you think the homoskedasticity assumption is problematic and explain why with reference to the plot. </span>
<span id="cb52-635"><a href="#cb52-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-636"><a href="#cb52-636" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The following output shows the results for the heteroskedastic (cone-shaped) example data, using both the regular standard error and HC standard errors. Please note the differences between these two sets of output and write down any questions you have about their interpretation.</span>
<span id="cb52-637"><a href="#cb52-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-638"><a href="#cb52-638" aria-hidden="true" tabindex="-1"></a>Example: </span>
<span id="cb52-641"><a href="#cb52-641" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-642"><a href="#cb52-642" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod4, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb52-643"><a href="#cb52-643" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-644"><a href="#cb52-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-645"><a href="#cb52-645" aria-hidden="true" tabindex="-1"></a>Regular SE: </span>
<span id="cb52-648"><a href="#cb52-648" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-649"><a href="#cb52-649" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb52-650"><a href="#cb52-650" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb52-651"><a href="#cb52-651" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb52-652"><a href="#cb52-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-653"><a href="#cb52-653" aria-hidden="true" tabindex="-1"></a><span class="co"># Regular SE: </span></span>
<span id="cb52-654"><a href="#cb52-654" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod4)</span>
<span id="cb52-655"><a href="#cb52-655" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-656"><a href="#cb52-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-657"><a href="#cb52-657" aria-hidden="true" tabindex="-1"></a>HC SE: </span>
<span id="cb52-658"><a href="#cb52-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-661"><a href="#cb52-661" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-662"><a href="#cb52-662" aria-hidden="true" tabindex="-1"></a><span class="co"># HC SE</span></span>
<span id="cb52-663"><a href="#cb52-663" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2. Use "hccm" to get the HC SEs for our piecewise model </span></span>
<span id="cb52-664"><a href="#cb52-664" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod4)</span>
<span id="cb52-665"><a href="#cb52-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-666"><a href="#cb52-666" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb52-667"><a href="#cb52-667" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod4, hcse)</span>
<span id="cb52-668"><a href="#cb52-668" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-669"><a href="#cb52-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-670"><a href="#cb52-670" aria-hidden="true" tabindex="-1"></a>@sec-normality-7</span>
<span id="cb52-671"><a href="#cb52-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-672"><a href="#cb52-672" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Please write down whether you think the normality assumption is problematic for the data in the figure below, and be sure to explain why with reference to the plot. Hint: if you think the data are non-normal, you should be able to interpret the pattern of deviations (e.g. skew, kurtosis). </span>
<span id="cb52-673"><a href="#cb52-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-674"><a href="#cb52-674" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig.width = 8, fig.cap = "An example from ECLS.", fig.align = 'center'}</span></span>
<span id="cb52-675"><a href="#cb52-675" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-676"><a href="#cb52-676" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod2, <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb52-677"><a href="#cb52-677" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-678"><a href="#cb52-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-679"><a href="#cb52-679" aria-hidden="true" tabindex="-1"></a><span class="ss"> *  </span>In each of the examples below, please write down whether you think the normality assumption is problematic and explain why with reference to the plots.</span>
<span id="cb52-680"><a href="#cb52-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-681"><a href="#cb52-681" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, fig.height = 10, fig.cap = "More examples.", fig.align = 'center'}</span></span>
<span id="cb52-682"><a href="#cb52-682" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: regression c1rmscal on ses_orig and t1learn</span></span>
<span id="cb52-683"><a href="#cb52-683" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb52-684"><a href="#cb52-684" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb52-685"><a href="#cb52-685" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>) {</span>
<span id="cb52-686"><a href="#cb52-686" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-687"><a href="#cb52-687" aria-hidden="true" tabindex="-1"></a>  e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb52-688"><a href="#cb52-688" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> x <span class="sc">+</span> e </span>
<span id="cb52-689"><a href="#cb52-689" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x), <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb52-690"><a href="#cb52-690" aria-hidden="true" tabindex="-1"></a>}  </span>
<span id="cb52-691"><a href="#cb52-691" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-692"><a href="#cb52-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-693"><a href="#cb52-693" aria-hidden="true" tabindex="-1"></a>@sec-worked-example-7</span>
<span id="cb52-694"><a href="#cb52-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-695"><a href="#cb52-695" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>For each of the three population assumptions of linear regression, please write down whether you think the assumption is problematic and explain why with reference to the plots. Again, the purpose of this exercise is for you to think about how to interpret the plots with respect to the assumptions. I am looking for you to be explicit about how you reason from the plots to your conclusions. I am less interested in the conclusions per se, as this is something that requires practice to get right.  </span>
<span id="cb52-696"><a href="#cb52-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-699"><a href="#cb52-699" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-700"><a href="#cb52-700" aria-hidden="true" tabindex="-1"></a><span class="co"># Clean up and load data</span></span>
<span id="cb52-701"><a href="#cb52-701" aria-hidden="true" tabindex="-1"></a><span class="co"># rm(list = ls())</span></span>
<span id="cb52-702"><a href="#cb52-702" aria-hidden="true" tabindex="-1"></a><span class="co"># load("ECLS2577.RData")</span></span>
<span id="cb52-703"><a href="#cb52-703" aria-hidden="true" tabindex="-1"></a><span class="co"># attach(ecls)</span></span>
<span id="cb52-704"><a href="#cb52-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-705"><a href="#cb52-705" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model</span></span>
<span id="cb52-706"><a href="#cb52-706" aria-hidden="true" tabindex="-1"></a>mod5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb52-707"><a href="#cb52-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-708"><a href="#cb52-708" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb52-709"><a href="#cb52-709" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb52-710"><a href="#cb52-710" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">1</span>)</span>
<span id="cb52-711"><a href="#cb52-711" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod5, <span class="dv">2</span>)</span>
<span id="cb52-712"><a href="#cb52-712" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-713"><a href="#cb52-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-714"><a href="#cb52-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-715"><a href="#cb52-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-716"><a href="#cb52-716" aria-hidden="true" tabindex="-1"></a><span class="fu">## Exercises {#sec-exercises-7}</span></span>
<span id="cb52-717"><a href="#cb52-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-718"><a href="#cb52-718" aria-hidden="true" tabindex="-1"></a>These exercises collect all of the R input used in this chapter into a single step-by-step analysis. It explains how the R input works, and provides some additional exercises. We will go through this material in class together, so you don't need to work on it before class (but you can if you want.) </span>
<span id="cb52-719"><a href="#cb52-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-720"><a href="#cb52-720" aria-hidden="true" tabindex="-1"></a>Before staring this section, you may find it useful to scroll to the top of the page, click on the "&lt;/&gt; Code" menu, and select "Show All Code."</span>
<span id="cb52-721"><a href="#cb52-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-722"><a href="#cb52-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-723"><a href="#cb52-723" aria-hidden="true" tabindex="-1"></a>There isn't much new in terms of R code in this chapter. Once we run a model with <span class="in">`lm`</span>, we just call the <span class="in">`plot`</span> function on the <span class="in">`lm`</span> output to produce the graphics requires for assumption checking. This section shows these steps for the worked example in @sec-worked-example-6 and @sec-worked-example-7. </span>
<span id="cb52-724"><a href="#cb52-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-725"><a href="#cb52-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-728"><a href="#cb52-728" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-729"><a href="#cb52-729" aria-hidden="true" tabindex="-1"></a><span class="co"># Clearn up env and load data </span></span>
<span id="cb52-730"><a href="#cb52-730" aria-hidden="true" tabindex="-1"></a><span class="co">#rm(list = ls())</span></span>
<span id="cb52-731"><a href="#cb52-731" aria-hidden="true" tabindex="-1"></a><span class="co">#load("ECLS2577.RData")</span></span>
<span id="cb52-732"><a href="#cb52-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-733"><a href="#cb52-733" aria-hidden="true" tabindex="-1"></a><span class="co"># Run model 3 from the example (all predictors, but no interactions)</span></span>
<span id="cb52-734"><a href="#cb52-734" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(c1rrscal <span class="sc">~</span> <span class="fu">factor</span>(p1center) <span class="sc">+</span> wksesl <span class="sc">+</span> wkmomed <span class="sc">+</span> wkdaded, <span class="at">data =</span> ecls)</span>
<span id="cb52-735"><a href="#cb52-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-736"><a href="#cb52-736" aria-hidden="true" tabindex="-1"></a><span class="co"># Puts both plots in one figure</span></span>
<span id="cb52-737"><a href="#cb52-737" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)) </span>
<span id="cb52-738"><a href="#cb52-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-739"><a href="#cb52-739" aria-hidden="true" tabindex="-1"></a><span class="co"># Check assumptions</span></span>
<span id="cb52-740"><a href="#cb52-740" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">1</span>)</span>
<span id="cb52-741"><a href="#cb52-741" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mod, <span class="dv">2</span>)</span>
<span id="cb52-742"><a href="#cb52-742" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-743"><a href="#cb52-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-744"><a href="#cb52-744" aria-hidden="true" tabindex="-1"></a>The next bit of code shows how to adjust the statistical tests for heteroskedasticity using HC standard errors. In the next two chapters, we show how to address the linearity and normality assumption violations. </span>
<span id="cb52-745"><a href="#cb52-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-746"><a href="#cb52-746" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Regular SE:  </span>
<span id="cb52-747"><a href="#cb52-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-750"><a href="#cb52-750" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-751"><a href="#cb52-751" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span>
<span id="cb52-752"><a href="#cb52-752" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-753"><a href="#cb52-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-754"><a href="#cb52-754" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>HC SE</span>
<span id="cb52-755"><a href="#cb52-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-758"><a href="#cb52-758" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb52-759"><a href="#cb52-759" aria-hidden="true" tabindex="-1"></a><span class="do">## Make sure the required packages are installed</span></span>
<span id="cb52-760"><a href="#cb52-760" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("car")</span></span>
<span id="cb52-761"><a href="#cb52-761" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("lmtest")</span></span>
<span id="cb52-762"><a href="#cb52-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-763"><a href="#cb52-763" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: fit the model (see above)</span></span>
<span id="cb52-764"><a href="#cb52-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-765"><a href="#cb52-765" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Use "hccm" to get the HC SEs </span></span>
<span id="cb52-766"><a href="#cb52-766" aria-hidden="true" tabindex="-1"></a>hcse <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(mod)</span>
<span id="cb52-767"><a href="#cb52-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-768"><a href="#cb52-768" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3. Use "coeftest" to compute t-tests with the HC SEs</span></span>
<span id="cb52-769"><a href="#cb52-769" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(mod, hcse)</span>
<span id="cb52-770"><a href="#cb52-770" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb52-771"><a href="#cb52-771" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-772"><a href="#cb52-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-773"><a href="#cb52-773" aria-hidden="true" tabindex="-1"></a>As discussed above, the interpretation for both sets of output is essentially the same, but by using the HC SEs  we can be sure that our inferences are not unduly affected by the assumption of homoskedasticity.</span>
<span id="cb52-774"><a href="#cb52-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-775"><a href="#cb52-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-776"><a href="#cb52-776" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo = F}</span></span>
<span id="cb52-777"><a href="#cb52-777" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>())</span>
<span id="cb52-778"><a href="#cb52-778" aria-hidden="true" tabindex="-1"></a><span class="fu">detach</span>(ecls)</span>
<span id="cb52-779"><a href="#cb52-779" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>